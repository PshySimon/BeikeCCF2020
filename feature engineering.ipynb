{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>0</td>\n",
       "      <td>杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>1</td>\n",
       "      <td>是的</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>2</td>\n",
       "      <td>这是5楼</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>因为公积金贷款贷的少</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>是呢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid        d1  rid                           d2  label\n",
       "0    0  采荷一小是分校吧    0  杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。      1\n",
       "1    0  采荷一小是分校吧    1                           是的      0\n",
       "2    0  采荷一小是分校吧    2                         这是5楼      0\n",
       "3    1      毛坯吗？    0                   因为公积金贷款贷的少      0\n",
       "4    1      毛坯吗？    1                           是呢      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征工程部分，大致思路为：统计特征、nlp特征和图特征\n",
    "# 首先通过做数据预处理，将数据划分为三个版本：原始版本、去掉停用词的版本、文本清洗的版本\n",
    "import pandas as pd\n",
    "\n",
    "train_query = pd.read_csv(\"./train/train.query.tsv\", sep=\"\\t\", header=None)\n",
    "train_reply = pd.read_csv(\"./train/train.reply.tsv\", sep=\"\\t\", header=None)\n",
    "test_query = pd.read_csv(\"./test/test.query.tsv\", sep=\"\\t\", header=None)\n",
    "test_reply = pd.read_csv(\"./test/test.reply.tsv\", sep=\"\\t\", header=None)\n",
    "train_query.columns = [\"cid\", \"d1\"]\n",
    "train_reply.columns = [\"cid\", \"rid\", \"d2\", \"label\"]\n",
    "train_df = pd.merge(train_query, train_reply, how=\"left\", on=\"cid\")\n",
    "test_query.columns = [\"cid\", \"d1\"]\n",
    "test_reply.columns = [\"cid\", \"rid\", \"d2\"]\n",
    "test_df = pd.merge(test_query, test_reply, how=\"left\", on=\"cid\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>604</td>\n",
       "      <td>您好，请问这个房子周边有哪些学校</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cid                d1  rid   d2  label\n",
       "2194  604  您好，请问这个房子周边有哪些学校    3  NaN      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['d2'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>604</td>\n",
       "      <td>您好，请问这个房子周边有哪些学校</td>\n",
       "      <td>0</td>\n",
       "      <td>中学附近有一初</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>604</td>\n",
       "      <td>您好，请问这个房子周边有哪些学校</td>\n",
       "      <td>1</td>\n",
       "      <td>一初是重点</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>604</td>\n",
       "      <td>您好，请问这个房子周边有哪些学校</td>\n",
       "      <td>2</td>\n",
       "      <td>有什么可以帮到您</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>604</td>\n",
       "      <td>您好，请问这个房子周边有哪些学校</td>\n",
       "      <td>3</td>\n",
       "      <td>好的</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>604</td>\n",
       "      <td>您好，请问这个房子周边有哪些学校</td>\n",
       "      <td>4</td>\n",
       "      <td>一初只能考</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cid                d1  rid        d2  label\n",
       "2191  604  您好，请问这个房子周边有哪些学校    0   中学附近有一初      1\n",
       "2192  604  您好，请问这个房子周边有哪些学校    1     一初是重点      1\n",
       "2193  604  您好，请问这个房子周边有哪些学校    2  有什么可以帮到您      0\n",
       "2194  604  您好，请问这个房子周边有哪些学校    3        好的      0\n",
       "2195  604  您好，请问这个房子周边有哪些学校    4     一初只能考      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['d2'] = train_df.d2.fillna(\"好的\")\n",
    "train_df[train_df['cid'] == 604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成不同版本的数据\n",
    "\n",
    "# 原始版本\n",
    "df = pd.concat([train_df, test_df])\n",
    "df[['d1', 'd2']].to_csv(\"df_raw.tsv\", index = None, sep=' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除停用词版本\n",
    "\n",
    "# 加载停用词（本来想考虑情感词的停用词，但是发现好像用不到，\n",
    "# 很多句子使用停用词之后变为空的了，这里停用了标点符号和感叹词）\n",
    "import string\n",
    "\n",
    "\n",
    "stopwords = [x for x in string.punctuation]\n",
    "with open(\"stopwords.txt\", encoding='utf-8') as fin:\n",
    "    for word in fin.readlines():\n",
    "        stopwords.append(word.strip())\n",
    "        \n",
    "def remove_sw(sen):\n",
    "    for w in stopwords:\n",
    "        sen = sen.replace(w, \"\")\n",
    "    return sen\n",
    "\n",
    "df_sw_removal = df.copy(deep=True)\n",
    "df_sw_removal['d1'] = df_sw_removal['d1'].apply(remove_sw)\n",
    "df_sw_removal['d2'] = df_sw_removal['d2'].apply(remove_sw)\n",
    "df_sw_removal.to_csv(\"df_rm_sw.tsv\", index = None, sep = '\\t',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🉐②😔💰⊙😊√｛😂😆【✪😜ⅤˊＲｖ∨㎡Ｐ×～😅ˋ😝😳👍ｒ＋﹉＆λ☀😲🏠】🏾️＃😖🔑➕😍Ｖω😫ù😌🎊Ｗ％🏻😃😓😁●㥪😘😄😰😋→🈶￼😏｝－❓👌▽'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本清洗过的数据\n",
    "\n",
    "# 数据并没有很脏，只不过有比较多的打错字的情况\n",
    "# 还有部分打成拼音的情况\n",
    "# 看看有哪些特殊字符\n",
    "import re\n",
    "\n",
    "def find_special_tokens(text):\n",
    "    # 过滤中文字符\n",
    "    result = re.findall(u'[^\\u4e00-\\u9fa5]', text)\n",
    "    # 过滤英文字符\n",
    "    result = re.findall(r'[^a-zA-Z]', ''.join(result))\n",
    "    # 过滤数字\n",
    "    result = re.findall(r'[^\\d]', ''.join(result))\n",
    "    # 过滤中英文标点符号\n",
    "    result = re.findall(r'[^ !\"#$%&\\'()*+,-./:;<=>?@\\[\\\\\\]^_`{}~·—‘“”…、。《》！（），：；？]', ''.join(result))\n",
    "    return result\n",
    "\n",
    "def get_special_tokens():\n",
    "    special_tokens = []\n",
    "    sentences = []\n",
    "    for i, row in df.iterrows():\n",
    "        res = find_special_tokens(str(row.d1) + str(row.d2))\n",
    "        special_tokens += res\n",
    "        if res != []:\n",
    "            sentences.append((row, res))\n",
    "    return \"\".join(set(special_tokens)), sentences\n",
    "\n",
    "special_tokens, sentences = get_special_tokens()\n",
    "with open(\"special_tokens_sentence.txt\", 'w', encoding='utf-8') as fin:\n",
    "    for s in sentences:\n",
    "        fin.write(str(s[0].cid)+\"\\t\" + str(s[0].rid)+\"\\t\"+str(s[0].d1)+\"\\t\" + str(s[0].d2) + \"\\t\" + \" \".join(s[1])+\"\\n\")\n",
    "# 好家伙，什么奇奇怪怪的符号都有，甚至还有全角的，保存到文件推测这些符号的含义，然后用文字替换\n",
    "special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清除特殊符号和打成拼音的汉字\n",
    "# 里面有全角的字符，好在不多，可以穷举完\n",
    "# 主要对立面的特殊字符进行标准化，便于训练\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_special_tokens(text):\n",
    "    text = text.replace(\"😂\", \"哈哈\")\n",
    "    text = text.replace(\"👌\", \"好\")\n",
    "    text = text.replace(\"😊\", \"好\")\n",
    "    text = text.replace(\"😓\", \"汗\")\n",
    "    text = text.replace(\"😁\", \"哈哈\")\n",
    "    text = text.replace(\"👌🏻\", \"好\")\n",
    "    text = text.replace(\" 🏻\", \"\")\n",
    "    text = text.replace(\"ù\", \"\")\n",
    "    text = text.replace(\"🈶️\", \"有\")\n",
    "    text = text.replace(\"🔑\", \"钥匙\")\n",
    "    text = text.replace(\"➕\", \"加\")\n",
    "    text = text.replace(\"🏠\", \"房子\")\n",
    "    text = text.replace(\"👍\", \"可以\")\n",
    "    text = text.replace(\"㎡\", \"平米\")\n",
    "    text = text.replace(\"🉐\", \"得\")\n",
    "    text = text.replace(\"Ｖ\", \"v\")\n",
    "    text = text.replace(\"Ｒ\", \"r\")\n",
    "    text = text.replace(\"❓\", \"？\")\n",
    "    text = text.replace(\"☀\", \"\")\n",
    "    text = text.replace(\"ｖ\", \"v\")\n",
    "    text = text.replace(\"ｒ\", \"r\")\n",
    "    text = text.replace(\"㥪\", \"楼\")\n",
    "    text = text.replace(\"￼\", \"\")\n",
    "    text = text.replace(\"＃\", \"#\")\n",
    "    text = text.replace(\"√\", \"对\")\n",
    "    text = text.replace(\"＋\", \"加\")\n",
    "    text = text.replace(\"﹉\", \"\")\n",
    "    text = text.replace(\"②\", \"二\")\n",
    "    text = text.replace(\"Ｗ\", \"万\")\n",
    "    text = text.replace(\"λ\", \"\")\n",
    "    text = text.replace(\"nh\", \"你好\")\n",
    "    text = text.replace(\"zaima\", \"在吗\")\n",
    "    text = text.replace(\"me\", \"么\")\n",
    "    text = text.replace(\"ceng\", \"层\")\n",
    "    text = text.replace(\"keyi\", \"可以\")\n",
    "    text = text.replace(\"taobao\", \"淘宝\")\n",
    "    text = text.replace(\"VR\", \"vr\")\n",
    "    text = text.replace(\"vR\", \"vr\")\n",
    "    text = text.replace(\"Vr\", \"vr\")\n",
    "    text = text.replace(\"NAMEPHONE\", \"NAME / PHONE\")\n",
    "    text = text.replace(\"l\", \"\")\n",
    "    text = text.replace(\"keyitan\", \"可以谈\")\n",
    "    text = text.replace(\"be\", \"\")\n",
    "    text = text.replace(\"ve\", \"vr\")\n",
    "    text = text.replace(\"key\", \"可以\")\n",
    "    text = text.replace(\"laile\", \"来了\")\n",
    "    text = text.replace(\"haole\", \"好了\")\n",
    "    text = text.replace(\"shaodeng\", \"稍等\")\n",
    "    text = text.replace(\"ninha\", \"您好\")\n",
    "    text = text.replace(\"nihao\", \"您好\")\n",
    "    text = text.replace(\"Ｐ\", \"P\")\n",
    "    text = text.replace(\"wan\", \"万\")\n",
    "    text = text.replace(\"DAU\", \"带\")\n",
    "    text = text.replace(\"lou\", \"楼\")\n",
    "    text = text.replace(\"kanfang\", \"看房\")\n",
    "    text = text.replace(\"is\", \"\")\n",
    "    text = text.replace(\"shenm\", \"\")\n",
    "    text = text.replace(\"＆\", \"&\")\n",
    "    text = text.replace(\"gaosunoi\", \"告诉你\")\n",
    "    text = text.replace(\"Va\", \"vr\")\n",
    "    text = text.replace(\"hao\", \"好\")\n",
    "    text = text.replace(\"ma\", \"\")\n",
    "    text = text.replace(\"zengzhi\", \"增值\")\n",
    "    # url直接清洗\n",
    "    html = re.compile(r'(https?://)([\\da-zA-Z=&\\?_\\.-]+)\\.([a-z=&\\?_\\.]{2,6})([/\\w =&\\?_\\.-]*)*/?')\n",
    "    text = re.sub(html, \"\", text)\n",
    "    return text\n",
    "\n",
    "df_cleaned = df.copy(deep=True)\n",
    "df_cleaned['d1'] = df_cleaned['d1'].apply(clean_special_tokens)\n",
    "df_cleaned['d2'] = df_cleaned['d2'].apply(clean_special_tokens)\n",
    "df_cleaned.to_csv(\"df_cleaned.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cleaned[:len(train_df)]\n",
    "test = df_cleaned[len(train_df):]\n",
    "unmatched = pd.read_csv(\"unmatched.tsv\", sep=\"\\t\")\n",
    "for i, row in unmatched.iterrows():\n",
    "    train.loc[int(row['id']), 'label'] = int(row['label'])\n",
    "train.to_csv(\"train.tsv\", sep='\\t', index=None)\n",
    "test.to_csv(\"test.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 生成某个句子的n-gram\n",
    "def n_gram(x, n=2):\n",
    "    if len(x) <= (n-1):\n",
    "        return x\n",
    "    result = []\n",
    "    # zip函数在达到最短长度时就停止迭代\n",
    "    n_grams = set(zip(*[x[i:] for i in range(n)]))\n",
    "    for n_gram in n_grams:\n",
    "        result.append(\"\".join(n_gram))\n",
    "    return result\n",
    "\n",
    "df_cleaned['d1_unigram'] = df_cleaned['d1'].apply(lambda x: list(str(x)))\n",
    "df_cleaned['d2_unigram'] = df_cleaned['d2'].apply(lambda x: list(str(x)))\n",
    "df_cleaned['d1_bigrams'] = df_cleaned['d1'].apply(lambda x: n_gram(list(str(x))))\n",
    "df_cleaned['d2_bigrams'] = df_cleaned['d2'].apply(lambda x: n_gram(list(str(x))))\n",
    "df_cleaned['shared_words_unigram'] = df_cleaned.apply(\n",
    "    lambda x: set(x['d1_unigram']).intersection(set(x['d2_unigram'])),\n",
    "    axis = 1\n",
    ")\n",
    "df_cleaned['shared_words_bigrams'] = df_cleaned.apply(\n",
    "    lambda x: set(x['d1_bigrams']).intersection(set(x['d2_bigrams'])),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"df_share_words.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 条件本来应该是：一元语法2个字及以上， 二元语法1个词及以上，就算作有share words\n",
    "def add_feature(x):\n",
    "    special_unigram = '是能有对'\n",
    "    \n",
    "    unigram = x['shared_words_unigram']\n",
    "    bigram = x['shared_words_bigrams']\n",
    "    \n",
    "    if len(unigram) == 1:\n",
    "        for _ in special_unigram:\n",
    "            if _ in unigram:\n",
    "                return True\n",
    "        \n",
    "    if len(unigram) >= 2 and len(bigram) >= 1:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "df_cleaned['add_feature'] = df_cleaned.apply(lambda x: add_feature(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_cleaned.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "      <th>d1_unigram</th>\n",
       "      <th>d2_unigram</th>\n",
       "      <th>d1_bigrams</th>\n",
       "      <th>d2_bigrams</th>\n",
       "      <th>shared_words_unigram</th>\n",
       "      <th>shared_words_bigrams</th>\n",
       "      <th>add_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校</td>\n",
       "      <td>0</td>\n",
       "      <td>杭州市采荷第一小学钱江苑校区杭州市钱江新城实验学校</td>\n",
       "      <td>1</td>\n",
       "      <td>[采, 荷, 一, 小, 是, 分, 校]</td>\n",
       "      <td>[杭, 州, 市, 采, 荷, 第, 一, 小, 学, 钱, 江, 苑, 校, 区, 杭, ...</td>\n",
       "      <td>[采荷, 小是, 荷一, 一小, 是分, 分校]</td>\n",
       "      <td>[第一, 采荷, 学校, 城实, 州市, 区杭, 苑校, 校区, 验学, 新城, 小学, 学...</td>\n",
       "      <td>{采, 一, 校, 小, 荷}</td>\n",
       "      <td>{一小, 采荷}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校</td>\n",
       "      <td>1</td>\n",
       "      <td>是</td>\n",
       "      <td>0</td>\n",
       "      <td>[采, 荷, 一, 小, 是, 分, 校]</td>\n",
       "      <td>[是]</td>\n",
       "      <td>[采荷, 小是, 荷一, 一小, 是分, 分校]</td>\n",
       "      <td>[是]</td>\n",
       "      <td>{是}</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校</td>\n",
       "      <td>2</td>\n",
       "      <td>这是5楼</td>\n",
       "      <td>0</td>\n",
       "      <td>[采, 荷, 一, 小, 是, 分, 校]</td>\n",
       "      <td>[这, 是, 5, 楼]</td>\n",
       "      <td>[采荷, 小是, 荷一, 一小, 是分, 分校]</td>\n",
       "      <td>[5楼, 这是, 是5]</td>\n",
       "      <td>{是}</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯</td>\n",
       "      <td>0</td>\n",
       "      <td>因为公积金贷款贷少</td>\n",
       "      <td>0</td>\n",
       "      <td>[毛, 坯]</td>\n",
       "      <td>[因, 为, 公, 积, 金, 贷, 款, 贷, 少]</td>\n",
       "      <td>[毛坯]</td>\n",
       "      <td>[公积, 因为, 为公, 贷少, 款贷, 积金, 金贷, 贷款]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯</td>\n",
       "      <td>1</td>\n",
       "      <td>是</td>\n",
       "      <td>0</td>\n",
       "      <td>[毛, 坯]</td>\n",
       "      <td>[是]</td>\n",
       "      <td>[毛坯]</td>\n",
       "      <td>[是]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21580</th>\n",
       "      <td>5998</td>\n",
       "      <td>您好我正在看尚林家园房子</td>\n",
       "      <td>1</td>\n",
       "      <td>有</td>\n",
       "      <td>0</td>\n",
       "      <td>[您, 好, 我, 正, 在, 看, 尚, 林, 家, 园, 房, 子]</td>\n",
       "      <td>[有]</td>\n",
       "      <td>[尚林, 家园, 房子, 看尚, 林家, 您好, 好我, 在看, 正在, 园房, 我正]</td>\n",
       "      <td>[有]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>5998</td>\n",
       "      <td>您好我正在看尚林家园房子</td>\n",
       "      <td>2</td>\n",
       "      <td>我带你看看</td>\n",
       "      <td>0</td>\n",
       "      <td>[您, 好, 我, 正, 在, 看, 尚, 林, 家, 园, 房, 子]</td>\n",
       "      <td>[我, 带, 你, 看, 看]</td>\n",
       "      <td>[尚林, 家园, 房子, 看尚, 林家, 您好, 好我, 在看, 正在, 园房, 我正]</td>\n",
       "      <td>[我带, 看看, 你看, 带你]</td>\n",
       "      <td>{看, 我}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>5999</td>\n",
       "      <td>今天可以安排看房子</td>\n",
       "      <td>0</td>\n",
       "      <td>我约下房东稍后回你</td>\n",
       "      <td>1</td>\n",
       "      <td>[今, 天, 可, 以, 安, 排, 看, 房, 子]</td>\n",
       "      <td>[我, 约, 下, 房, 东, 稍, 后, 回, 你]</td>\n",
       "      <td>[天可, 排看, 安排, 看房, 房子, 可以, 今天, 以安]</td>\n",
       "      <td>[下房, 房东, 回你, 后回, 东稍, 稍后, 约下, 我约]</td>\n",
       "      <td>{房}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>5999</td>\n",
       "      <td>今天可以安排看房子</td>\n",
       "      <td>1</td>\n",
       "      <td>可以看你几点有时间过</td>\n",
       "      <td>1</td>\n",
       "      <td>[今, 天, 可, 以, 安, 排, 看, 房, 子]</td>\n",
       "      <td>[可, 以, 看, 你, 几, 点, 有, 时, 间, 过]</td>\n",
       "      <td>[天可, 排看, 安排, 看房, 房子, 可以, 今天, 以安]</td>\n",
       "      <td>[点有, 几点, 看你, 可以, 间过, 有时, 时间, 你几, 以看]</td>\n",
       "      <td>{可, 以, 看}</td>\n",
       "      <td>{可以}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>5999</td>\n",
       "      <td>今天可以安排看房子</td>\n",
       "      <td>2</td>\n",
       "      <td>好那咱们在一号门口这碰头</td>\n",
       "      <td>0</td>\n",
       "      <td>[今, 天, 可, 以, 安, 排, 看, 房, 子]</td>\n",
       "      <td>[好, 那, 咱, 们, 在, 一, 号, 门, 口, 这, 碰, 头]</td>\n",
       "      <td>[天可, 排看, 安排, 看房, 房子, 可以, 今天, 以安]</td>\n",
       "      <td>[们在, 在一, 好那, 一号, 门口, 这碰, 号门, 碰头, 那咱, 口这, 咱们]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21585 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cid            d1  rid                         d2  label  \\\n",
       "0         0       采荷一小是分校    0  杭州市采荷第一小学钱江苑校区杭州市钱江新城实验学校      1   \n",
       "1         0       采荷一小是分校    1                          是      0   \n",
       "2         0       采荷一小是分校    2                       这是5楼      0   \n",
       "3         1            毛坯    0                  因为公积金贷款贷少      0   \n",
       "4         1            毛坯    1                          是      0   \n",
       "...     ...           ...  ...                        ...    ...   \n",
       "21580  5998  您好我正在看尚林家园房子    1                          有      0   \n",
       "21581  5998  您好我正在看尚林家园房子    2                      我带你看看      0   \n",
       "21582  5999     今天可以安排看房子    0                  我约下房东稍后回你      1   \n",
       "21583  5999     今天可以安排看房子    1                 可以看你几点有时间过      1   \n",
       "21584  5999     今天可以安排看房子    2               好那咱们在一号门口这碰头      0   \n",
       "\n",
       "                                 d1_unigram  \\\n",
       "0                     [采, 荷, 一, 小, 是, 分, 校]   \n",
       "1                     [采, 荷, 一, 小, 是, 分, 校]   \n",
       "2                     [采, 荷, 一, 小, 是, 分, 校]   \n",
       "3                                    [毛, 坯]   \n",
       "4                                    [毛, 坯]   \n",
       "...                                     ...   \n",
       "21580  [您, 好, 我, 正, 在, 看, 尚, 林, 家, 园, 房, 子]   \n",
       "21581  [您, 好, 我, 正, 在, 看, 尚, 林, 家, 园, 房, 子]   \n",
       "21582           [今, 天, 可, 以, 安, 排, 看, 房, 子]   \n",
       "21583           [今, 天, 可, 以, 安, 排, 看, 房, 子]   \n",
       "21584           [今, 天, 可, 以, 安, 排, 看, 房, 子]   \n",
       "\n",
       "                                              d2_unigram  \\\n",
       "0      [杭, 州, 市, 采, 荷, 第, 一, 小, 学, 钱, 江, 苑, 校, 区, 杭, ...   \n",
       "1                                                    [是]   \n",
       "2                                           [这, 是, 5, 楼]   \n",
       "3                            [因, 为, 公, 积, 金, 贷, 款, 贷, 少]   \n",
       "4                                                    [是]   \n",
       "...                                                  ...   \n",
       "21580                                                [有]   \n",
       "21581                                    [我, 带, 你, 看, 看]   \n",
       "21582                        [我, 约, 下, 房, 东, 稍, 后, 回, 你]   \n",
       "21583                     [可, 以, 看, 你, 几, 点, 有, 时, 间, 过]   \n",
       "21584               [好, 那, 咱, 们, 在, 一, 号, 门, 口, 这, 碰, 头]   \n",
       "\n",
       "                                         d1_bigrams  \\\n",
       "0                          [采荷, 小是, 荷一, 一小, 是分, 分校]   \n",
       "1                          [采荷, 小是, 荷一, 一小, 是分, 分校]   \n",
       "2                          [采荷, 小是, 荷一, 一小, 是分, 分校]   \n",
       "3                                              [毛坯]   \n",
       "4                                              [毛坯]   \n",
       "...                                             ...   \n",
       "21580  [尚林, 家园, 房子, 看尚, 林家, 您好, 好我, 在看, 正在, 园房, 我正]   \n",
       "21581  [尚林, 家园, 房子, 看尚, 林家, 您好, 好我, 在看, 正在, 园房, 我正]   \n",
       "21582              [天可, 排看, 安排, 看房, 房子, 可以, 今天, 以安]   \n",
       "21583              [天可, 排看, 安排, 看房, 房子, 可以, 今天, 以安]   \n",
       "21584              [天可, 排看, 安排, 看房, 房子, 可以, 今天, 以安]   \n",
       "\n",
       "                                              d2_bigrams shared_words_unigram  \\\n",
       "0      [第一, 采荷, 学校, 城实, 州市, 区杭, 苑校, 校区, 验学, 新城, 小学, 学...      {采, 一, 校, 小, 荷}   \n",
       "1                                                    [是]                  {是}   \n",
       "2                                           [5楼, 这是, 是5]                  {是}   \n",
       "3                       [公积, 因为, 为公, 贷少, 款贷, 积金, 金贷, 贷款]                   {}   \n",
       "4                                                    [是]                   {}   \n",
       "...                                                  ...                  ...   \n",
       "21580                                                [有]                   {}   \n",
       "21581                                   [我带, 看看, 你看, 带你]               {看, 我}   \n",
       "21582                   [下房, 房东, 回你, 后回, 东稍, 稍后, 约下, 我约]                  {房}   \n",
       "21583               [点有, 几点, 看你, 可以, 间过, 有时, 时间, 你几, 以看]            {可, 以, 看}   \n",
       "21584       [们在, 在一, 好那, 一号, 门口, 这碰, 号门, 碰头, 那咱, 口这, 咱们]                   {}   \n",
       "\n",
       "      shared_words_bigrams  add_feature  \n",
       "0                 {一小, 采荷}         True  \n",
       "1                       {}         True  \n",
       "2                       {}         True  \n",
       "3                       {}        False  \n",
       "4                       {}        False  \n",
       "...                    ...          ...  \n",
       "21580                   {}        False  \n",
       "21581                   {}        False  \n",
       "21582                   {}        False  \n",
       "21583                 {可以}         True  \n",
       "21584                   {}        False  \n",
       "\n",
       "[21585 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21584/21585"
     ]
    }
   ],
   "source": [
    "length = len(new_df)\n",
    "for i, flag in enumerate(new_df['add_feature']):\n",
    "    print('\\r %d/%d'%(i, length), end='')\n",
    "    if flag:\n",
    "        df_cleaned.loc[i, 'd1'] = str(df_cleaned.loc[i, 'd1']) +  '@'\n",
    "        df_cleaned.loc[i, 'd2'] = str(df_cleaned.loc[i, 'd2']) +  '@'\n",
    "    else:\n",
    "        df_cleaned.loc[i, 'd1'] = str(df_cleaned.loc[i, 'd1']) +  '&'\n",
    "        df_cleaned.loc[i, 'd2'] = str(df_cleaned.loc[i, 'd2']) +  '&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"aug_train.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"code/train.tsv\", sep='\\t')\n",
    "train['q1'] = df_cleaned['d1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"code/train.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取shared words、powerful words、key words\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "import jieba.analyse\n",
    "from LAC import LAC\n",
    "lac = LAC(mode='seg')\n",
    "\n",
    "\n",
    "def fetch_feature(data):\n",
    "    # 分词、词性标注\n",
    "    %time data['d1_word_cut'] = data['d1'].apply(lambda x: list(lac.run(str(x))))\n",
    "    %time data['d2_word_cut'] = data['d2'].apply(lambda x: list(lac.run(str(x))))\n",
    "#     %time data['d1_pos_tag'] = data['d1'].apply(lambda x: [x.flag for x in list(psg.cut(str(x)))])\n",
    "#     %time data['d2_pos_tag'] = data['d2'].apply(lambda x: [x.flag for x in list(psg.cut(str(x)))])\n",
    "    # 回答一般会复述问题的关键词，所以抽取复述的词，而且复述词不能是停用词\n",
    "#     data['shared_words'] = data.apply(lambda x: [_ for _ in set(x['d1_word_cut']).intersection(set(x['d2_word_cut'])) if _ not in stopwords], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计特征\n",
    "# 文本特征：主要分为问句和回答\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "# 共现词比例\n",
    "def shared_word_proportion(x):\n",
    "    count_d1 = Counter(x['d1_word_cut'])\n",
    "    count_d2 = Counter(x['d2_word_cut'])\n",
    "    n_shared_word_in_d1 = sum([count_d1[w] for w in count_d1 if w in count_d2])\n",
    "    n_shared_word_in_d2 = sum([count_d2[w] for w in count_d2 if w in count_d1])\n",
    "    n_total = sum(count_d1.values()) + sum(count_d2.values())\n",
    "    return 1.0 * (n_shared_word_in_d1 + n_shared_word_in_d2) / n_total\n",
    "\n",
    "# 动态规划求解编辑距离，时间复杂度是O(n^2)\n",
    "def edit_distance(str1, str2):\n",
    "    # 坑爹的二维数组声明方法，如果直接用*就是浅拷贝\n",
    "    dp = [[0]*(len(str1)+1) for _ in range((len(str2)+1))]\n",
    "    for i in range(len(str1)+1):\n",
    "        dp[0][i] = i\n",
    "    for j in range(len(str2)+1):\n",
    "        dp[j][0] = j\n",
    "    for i in range(1, len(str2)+1):\n",
    "        for j in range(1, len(str1)+1):\n",
    "            if str2[i-1] == str1[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i-1][j-1], dp[i-1][j], dp[i][j-1])+1\n",
    "    return dp[len(str2)][len(str1)]\n",
    "\n",
    "# 生成某个句子的n-gram\n",
    "def n_gram(x, n=2):\n",
    "    if len(x) <= (n-1):\n",
    "        return x\n",
    "    result = []\n",
    "    # zip函数在达到最短长度时就停止迭代\n",
    "    n_grams = set(zip(*[x[i:] for i in range(n)]))\n",
    "    for n_gram in n_grams:\n",
    "        result.append(\" \".join(n_gram))\n",
    "    return result\n",
    "\n",
    "# 计算两个句子的Jaccard相似度\n",
    "def Jaccard(str1, str2):\n",
    "    s1 = set(str1)\n",
    "    s2 = set(str2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    union = s1.union(s2)\n",
    "    return 1.0 * len(intersection) / len(union)\n",
    "\n",
    "\n",
    "# 统计特征，选择了57个特征，后续再加\n",
    "def statistical_feature(data):\n",
    "    punctuations = r'^ !\"#$%&\\'()*+,-./:;<=>?@[]^_`{}~·—‘“”…、。《》！（），：；？【】｛｝～'\n",
    "    # 统计文本和单词的长度\n",
    "    %time data['d1_char_length'] = data['d1'].apply(lambda x: len(str(x)))\n",
    "    %time data['d2_char_length'] = data['d2'].apply(lambda x: len(str(x)))\n",
    "    %time data['d1_word_length'] = data['d1_word_cut'].apply(lambda x: len(x))\n",
    "    %time data['d2_word_length'] = data['d2_word_cut'].apply(lambda x: len(x))\n",
    "    %time data['d1_max_word_length'] = data['d1_word_cut'].apply(lambda x: max([len(_) for _ in x]))\n",
    "    %time data['d1_mean_word_length'] = data['d1_word_cut'].apply(lambda x: sum([len(_) for _ in x])/len(x))\n",
    "    %time data['d2_max_word_length'] = data['d2_word_cut'].apply(lambda x: max([len(_) for _ in x]))\n",
    "    %time data['d2_mean_word_length'] = data['d2_word_cut'].apply(lambda x: sum([len(_) for _ in x])/len(x))\n",
    "    %time data['char_length_difference'] = data.apply(lambda x: abs(len(str(x['d1'])) - len(str(x['d2']))), axis=1)\n",
    "    %time data['word_length_difference'] = data.apply(lambda x: abs(len(x['d1_word_cut']) - len(x['d2_word_cut'])), axis=1)\n",
    "    \n",
    "    # 统计词性唯一值数量\n",
    "    %time data['d1_pos_unique_num'] = data['d1_pos_tag'].apply(lambda x: len(set(x)))\n",
    "    %time data['d1_contain_location'] = data['d1_pos_tag'].apply(lambda x: int('nr' in x))\n",
    "    %time data['d1_contain_mood_particle'] = data['d1_pos_tag'].apply(lambda x: int('y' in x))\n",
    "    \n",
    "    # 统计唯一字符、单词数量以及标点符号数量\n",
    "    %time data['d1_unique_char_num'] = data['d1'].apply(lambda x: len(set(str(x))))\n",
    "    %time data['d2_unique_char_num'] = data['d2'].apply(lambda x: len(set(str(x))))\n",
    "    %time data['d1_unique_word_num'] = data['d1_word_cut'].apply(lambda x: len(set(x)))\n",
    "    %time data['d2_unique_word_num'] = data['d2_word_cut'].apply(lambda x: len(set(x)))\n",
    "    data['d1_punc_num'] = data['d1'].apply(lambda x: sum(1 for _ in str(x) if _ in punctuations))\n",
    "    data['d2_punc_num'] = data['d2'].apply(lambda x: sum(1 for _ in str(x) if _ in punctuations))\n",
    "    data['d1_punc_category'] = data['d1'].apply(lambda x: len(set([_ for _ in str(x) if _ in punctuations])))\n",
    "    data['d2_punc_category'] = data['d2'].apply(lambda x: len(set([_ for _ in str(x) if _ in punctuations])))\n",
    "    \n",
    "    # 是否包含停用词、字母、数字、emoji等等\n",
    "    data['d1_contain_stopwords'] = data['d1'].apply(lambda x: 1 if len([_ for _ in str(x) if _ in stopwords]) > 0 else 0)\n",
    "    data['d2_contain_stopwords'] = data['d2'].apply(lambda x: 1 if len([_ for _ in str(x) if _ in stopwords]) > 0 else 0)\n",
    "    %time data['d1_contain_alphabet'] = data['d1'].apply(lambda x: 1 if len(re.findall(r'[a-zA-Z]', str(x))) > 0 else 0)\n",
    "    %time data['d2_contain_alphabet'] = data['d2'].apply(lambda x: 1 if len(re.findall(r'[a-zA-Z]', str(x))) > 0 else 0)\n",
    "    %time data['d1_contain_number'] = data['d1'].apply(lambda x: 1 if len(re.findall(r'[\\d]', str(x))) > 0 else 0)\n",
    "    %time data['d2_contain_number'] = data['d2'].apply(lambda x: 1 if len(re.findall(r'[\\d]', str(x))) > 0 else 0)\n",
    "    %time data['d1_contain_emoji'] = data['d1'].apply(lambda x: 1 if len(re.findall(u'[\\U00010000-\\U0010ffff\\\\uD800-\\\\uDBFF\\\\uDC00-\\\\uDFFF]', str(x))) > 0 else 0)\n",
    "    %time data['d2_contain_emoji'] = data['d2'].apply(lambda x: 1 if len(re.findall(u'[\\U00010000-\\U0010ffff\\\\uD800-\\\\uDBFF\\\\uDC00-\\\\uDFFF]', str(x))) > 0 else 0)\n",
    "    \n",
    "    # 问题可以提取的业务特征有：\n",
    "    # 是否带有“?？”，一般带问号的是问句，问句的特征比较好找，而有些问题是陈述句，这种关系就不太好抽取\n",
    "    # 特殊句式“是/能/可以...”/“有...不”/“....对吗”+语气词一般回复“是的”，“可以”，“有的”，“嗯嗯”（否定回复一般加个否定词就可以了）\n",
    "    # 带“多少”的一般要会回复数量关系如：数额、百分比等等，进一步可以抽取：是否含有税、贷款、首付、价格、年等等关键词\n",
    "    # 带有“怎么样”，“怎么办”，这个回答太过于灵活，比较难抽取\n",
    "    # 询问位置：“在哪”，这个需要靠词性来推断回复是否含有地点\n",
    "    # 问很多的：“采光”基于规则也不太好判断\n",
    "    # 回答可提取的业务特征：是否含有价格、hashTag、疑问词、地点、时间、学校、楼层、百分比、单元、面积、年限、几期以及回复“是的”、“好的”、“可以”\n",
    "    # 找业务特征的目的：通过问题所问的内容，可以通过回答中某些业务特征找到是否匹配的关系；同理，问题中的业务特征和回答的特征可能也存在，某些关系\n",
    "    %time data['d1_is_interrogative'] = data['d1'].apply(lambda x: 1 if '?' in str(x) or '？' in str(x) else 0)\n",
    "    %time data['d1_spcial_statement'] = data['d1'].apply(lambda x: 1 if re.match(r'(是|能|可以|有|对吗)', str(x)) or '不' in str(x)[-2:] else 0)\n",
    "    %time data['d1_how_many'] = data['d1'].apply(lambda x: 1 if '多少' in str(x) else 0)\n",
    "    %time data['d1_num_feature'] = data['d1'].apply(lambda x: 1 if re.match(r'(税|贷|款|首付|价格|年|费|优惠)', str(x)) else 0)\n",
    "    %time data['d1_contain_where'] = data['d1'].apply(lambda x:1 if '在哪' in str(x) else 0)\n",
    "    \n",
    "    %time data['d1_contain_price'] = data['d1'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+((来|几)?)[w|W|万]', str(x)) else 0)\n",
    "    %time data['d2_contain_price'] = data['d2'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+((来|几)?)[w|W|万]', str(x)) else 0)\n",
    "\n",
    "    # 带有hashTag的一般都是客户复制的小区信息来咨询的\n",
    "    %time data['d1_contain_hashtag'] = data['d1'].apply(lambda x: 1 if re.match(r'#.+#', str(x)) else 0)\n",
    "    %time data['d2_contain_hashtag'] = data['d2'].apply(lambda x: 1 if re.match(r'#.+#', str(x)) else 0)\n",
    "    %time data['d1_contain_interrogation'] = data['d1'].apply(lambda x: 1 if re.match(r'(什么|哪儿|哪里|几时|几|多少怎|怎么|怎样|怎么样|如何|吗|呢)', str(x)) else 0)\n",
    "    %time data['d2_contain_interrogation'] = data['d2'].apply(lambda x: 1 if re.match(r'(什么|哪儿|哪里|几时|几|多少怎|怎么|怎样|怎么样|如何|吗|呢)', str(x)) else 0)\n",
    "\n",
    "    # 一点有歧义，数据里面一点表示很少的意思比较多，所以去掉了\n",
    "    %time data['d1_contain_time'] = data['d1'].apply(lambda x: 1 if re.match(r'(今天|明天|上午|中午|下午|晚上|周[二三四五六日末\\d]|[\\d]+点(半?)|[两三四五六七八九十]点(半?))', str(x)) else 0)\n",
    "    %time data['d2_contain_time'] = data['d2'].apply(lambda x: 1 if re.match(r'(今天|明天|上午|中午|下午|晚上|周[二三四五六日末\\d]|[\\d]+点(半?)|[两三四五六七八九十]点(半?))', str(x)) else 0)\n",
    "    %time data['d1_contain_school'] = data['d1'].apply(lambda x: 1 if re.match(r'([一三三四五六七八九十]+中|校区|(实验|南雅|雅礼)?(中学|小学|附中|幼儿园))', str(x)) else 0)\n",
    "    %time data['d2_contain_school'] = data['d2'].apply(lambda x: 1 if re.match(r'([一三三四五六七八九十]+中|校区|(实验|南雅|雅礼)?(中学|小学|附中|幼儿园))', str(x)) else 0)\n",
    "    %time data['d1_contain_floor'] = data['d1'].apply(lambda x: 1 if re.match(r'(([\\d一二三四五六七八九十]+(号?)[楼|层])|([一二三四五六七八九十\\d]+栋))', str(x)) else 0)\n",
    "    %time data['d2_contain_floor'] = data['d2'].apply(lambda x: 1 if re.match(r'(([\\d一二三四五六七八九十]+(号?)[楼|层])|([一二三四五六七八九十\\d]+栋))', str(x)) else 0)\n",
    "    %time data['d1_contain_percentage'] = data['d1'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+%', str(x)) else 0)\n",
    "    %time data['d2_contain_percentage'] = data['d2'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+%', str(x)) else 0)\n",
    "    %time data['d1_contain_unit'] = data['d1'].apply(lambda x: 1 if re.match(r'[ABCDEF东南西北一二三四五六七八九十\\d]+([边栋]?)单元', str(x)) else 0)\n",
    "    %time data['d2_contain_unit'] = data['d2'].apply(lambda x: 1 if re.match(r'[ABCDEF东南西北一二三四五六七八九十\\d]+([边栋]?)单元', str(x)) else 0)\n",
    "    %time data['d1_contain_area'] = data['d1'].apply(lambda x: 1 if re.match(r'((\\d+\\.?)[一二三四五六七八九十两百\\d]+(平|平方|平方米|平米)|面积\\d+)', str(x)) else 0)\n",
    "    %time data['d2_contain_area'] = data['d2'].apply(lambda x: 1 if re.match(r'((\\d+\\.?)[一二三四五六七八九十两百\\d]+(平|平方|平方米|平米)|面积\\d+)', str(x)) else 0)\n",
    "    %time data['d1_contain_year'] = data['d1'].apply(lambda x: 1 if re.match(r'[一两二三四五六七八九十半\\d]+年', str(x)) else 0)\n",
    "    %time data['d2_contain_year'] = data['d2'].apply(lambda x: 1 if re.match(r'[一两二三四五六七八九十半\\d]+年', str(x)) else 0)\n",
    "    \n",
    "    # 文本相似度特征：考虑到本次任务是语义上的匹配，不一定要问句和答句相似，但是大多数问题问句和答句都比较相似，在重复主题和关键字\n",
    "    # 可以查看共现词、编辑距离、或者其他距离如Jaccard相似度\n",
    "    %time data['shared_word_proportion'] = data.apply(shared_word_proportion, axis=1)\n",
    "    %time data['shared_word_num'] = data['shared_words'].apply(lambda x: len(x))\n",
    "    %time data['jaccard_similarity'] = data.apply(lambda x: Jaccard(x['d1_word_cut'], x['d2_word_cut']), axis=1)\n",
    "    %time data['jaccard_similarity_bigram'] = data.apply(lambda x: Jaccard(n_gram(x['d1_word_cut']), n_gram(x['d2_word_cut'])), axis=1)\n",
    "    %time data['jaccard_similarity_trigram'] = data.apply(lambda x: Jaccard(n_gram(x['d1_word_cut'], 3), n_gram(x['d2_word_cut'], 3)), axis=1)\n",
    "    %time data['edit_distance'] = data.apply(lambda x: edit_distance(str(x['d1']), str(x['d2'])), axis=1)\n",
    "    %time data['dice_distance'] = data.apply(lambda x: 2.0 * (len(set(x['d1_word_cut']).intersection(set(x['d2_word_cut']))) / (len(set(x['d1_word_cut']))+len(set(x['d2_word_cut'])))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.8 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "# 拿原始版本做训练\n",
    "# df_raw = pd.read_csv(\"df_raw.tsv\", sep='\\t')\n",
    "df_raw = df_cleaned\n",
    "fetch_feature(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 64 ms\n",
      "Wall time: 63 ms\n",
      "Wall time: 54 ms\n",
      "Wall time: 53 ms\n",
      "Wall time: 173 ms\n",
      "Wall time: 143 ms\n",
      "Wall time: 146 ms\n",
      "Wall time: 124 ms\n",
      "Wall time: 1.36 s\n",
      "Wall time: 1.4 s\n",
      "Wall time: 67 ms\n",
      "Wall time: 51 ms\n",
      "Wall time: 53 ms\n",
      "Wall time: 157 ms\n",
      "Wall time: 170 ms\n",
      "Wall time: 78 ms\n",
      "Wall time: 76 ms\n",
      "Wall time: 141 ms\n",
      "Wall time: 147 ms\n",
      "Wall time: 161 ms\n",
      "Wall time: 156 ms\n",
      "Wall time: 156 ms\n",
      "Wall time: 149 ms\n",
      "Wall time: 68 ms\n",
      "Wall time: 172 ms\n",
      "Wall time: 57.1 ms\n",
      "Wall time: 126 ms\n",
      "Wall time: 48 ms\n",
      "Wall time: 138 ms\n",
      "Wall time: 142 ms\n",
      "Wall time: 151 ms\n",
      "Wall time: 154 ms\n",
      "Wall time: 165 ms\n",
      "Wall time: 200 ms\n",
      "Wall time: 141 ms\n",
      "Wall time: 158 ms\n",
      "Wall time: 204 ms\n",
      "Wall time: 154 ms\n",
      "Wall time: 154 ms\n",
      "Wall time: 168 ms\n",
      "Wall time: 161 ms\n",
      "Wall time: 156 ms\n",
      "Wall time: 190 ms\n",
      "Wall time: 146 ms\n",
      "Wall time: 184 ms\n",
      "Wall time: 151 ms\n",
      "Wall time: 171 ms\n",
      "Wall time: 179 ms\n",
      "Wall time: 2.62 s\n",
      "Wall time: 37 ms\n",
      "Wall time: 1.88 s\n",
      "Wall time: 2.95 s\n",
      "Wall time: 2.74 s\n",
      "Wall time: 11.1 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "statistical_feature(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_csv(\"raw_tmp.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算文本的count vector、tfidf vector、word2vec、doc2vec、LDA、kmeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import word2vec, doc2vec\n",
    "from LAC import LAC\n",
    "\n",
    "lac = LAC(mode='seg')\n",
    "\n",
    "# 训练word2vec，输入是List(List(str))\n",
    "def train_word2vec(data):\n",
    "    sentences = []\n",
    "    for i, row in data.iterrows():\n",
    "        print(\"\\r 读取语料中：{}\".format(i), end=\"\")\n",
    "        sentences.append(lac.run(str(row['d1'])))\n",
    "        sentences.append(lac.run(str(row['d2'])))\n",
    "    w2v = word2vec.Word2Vec(\n",
    "        sentences,\n",
    "        size=300,\n",
    "        iter=30,\n",
    "        window = 5,\n",
    "        min_count = 0,\n",
    "        workers = 4,\n",
    "        sample = 1e-4)\n",
    "    return w2v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 读取语料中：53681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 48553 words, keeping 4014 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 读取语料中：53756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 96801 words, keeping 6132 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 145414 words, keeping 7878 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 195362 words, keeping 9373 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 243708 words, keeping 10750 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 292432 words, keeping 11987 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 341237 words, keeping 13142 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 390430 words, keeping 14325 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 439933 words, keeping 15385 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 489066 words, keeping 16417 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 539021 words, keeping 17445 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 588636 words, keeping 18392 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 638880 words, keeping 19338 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 687610 words, keeping 20141 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 737713 words, keeping 21139 word types\n",
      "INFO:gensim.models.word2vec:collected 21196 word types from a corpus of 741040 raw words and 150684 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=0 retains 21196 unique words (100% of original 21196, drops 0)\n",
      "INFO:gensim.models.word2vec:effective_min_count=0 leaves 741040 word corpus (100% of original 741040, drops 0)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 21196 items\n",
      "INFO:gensim.models.word2vec:sample=0.0001 downsamples 425 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 286006 word corpus (38.6% of prior 741040)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 21196 words and 300 dimensions: 61468400 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 4 workers on 21196 vocabulary and 300 features, using sg=0 hs=0 sample=0.0001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 86.46% examples, 234917 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 741040 raw words (286020 effective words) took 1.2s, 242362 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 741040 raw words (285821 effective words) took 0.8s, 341970 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 741040 raw words (285859 effective words) took 0.8s, 349357 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 82.41% examples, 230500 words/s, in_qsize 5, out_qsize 2\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 741040 raw words (285849 effective words) took 1.1s, 257781 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 741040 raw words (286352 effective words) took 0.8s, 342988 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 87.76% examples, 246209 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 6 : training on 741040 raw words (285612 effective words) took 1.1s, 264228 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 98.64% examples, 282428 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 7 : training on 741040 raw words (286399 effective words) took 1.0s, 283683 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 90.52% examples, 253171 words/s, in_qsize 7, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 8 : training on 741040 raw words (286298 effective words) took 1.1s, 264865 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 9 : training on 741040 raw words (286242 effective words) took 0.8s, 339697 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 91.88% examples, 257843 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 10 : training on 741040 raw words (286094 effective words) took 1.1s, 263156 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 11 : training on 741040 raw words (286371 effective words) took 1.0s, 293498 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 12 : training on 741040 raw words (286096 effective words) took 0.9s, 317160 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 13 : training on 741040 raw words (285607 effective words) took 0.9s, 331199 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 14 : training on 741040 raw words (285776 effective words) took 0.9s, 303164 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 15 : training on 741040 raw words (286282 effective words) took 0.9s, 324863 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 87.72% examples, 245514 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 16 : training on 741040 raw words (286247 effective words) took 1.1s, 265215 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 17 : training on 741040 raw words (286134 effective words) took 0.8s, 354125 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 18 : training on 741040 raw words (286055 effective words) took 0.9s, 318032 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 74.41% examples, 202947 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 19 : training on 741040 raw words (285802 effective words) took 1.2s, 242637 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 20 : training on 741040 raw words (285999 effective words) took 0.8s, 341758 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 21 : training on 741040 raw words (285649 effective words) took 1.0s, 297525 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 22 - PROGRESS: at 98.64% examples, 281435 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 22 : training on 741040 raw words (285940 effective words) took 1.0s, 282848 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 23 - PROGRESS: at 98.64% examples, 280814 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 23 : training on 741040 raw words (285839 effective words) took 1.0s, 282817 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 24 : training on 741040 raw words (285665 effective words) took 0.8s, 347281 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 25 - PROGRESS: at 77.04% examples, 215008 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 25 : training on 741040 raw words (285623 effective words) took 1.2s, 239286 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 26 : training on 741040 raw words (286514 effective words) took 0.8s, 354165 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 27 : training on 741040 raw words (286042 effective words) took 1.0s, 299249 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 28 : training on 741040 raw words (285746 effective words) took 0.9s, 313538 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 29 - PROGRESS: at 85.08% examples, 237456 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 29 : training on 741040 raw words (286135 effective words) took 1.3s, 227935 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 30 - PROGRESS: at 87.72% examples, 243286 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 30 : training on 741040 raw words (286536 effective words) took 1.1s, 259821 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 22231200 raw words (8580604 effective words) took 29.8s, 288414 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "w2v = train_word2vec(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Word2Vec object under w2v.pkt, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "INFO:gensim.utils:saved w2v.pkt\n"
     ]
    }
   ],
   "source": [
    "w2v.save(\"w2v.pkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别提取关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图特征，这里使用共现矩阵和相似度矩阵来构造图\n",
    "# 先提取关键词，提取关键词采用无监督学习算法，采用：词频统计、tfidf、hits算法和sgrank\n",
    "from time import time\n",
    "\n",
    "def key_words_union(k1, k2):\n",
    "    s1 = set([_[0] for _ in k1])\n",
    "    s2 = set([_[0] for _ in k2])\n",
    "    return s1.union(s2)\n",
    "\n",
    "def key_words_intersection(k1, k2):\n",
    "    s1 = set([_[0] for _ in k1])\n",
    "    s2 = set([_[0] for _ in k2])\n",
    "    return s1.intersection(s2)\n",
    "\n",
    "# 提取关键字时没有注意较短文本和短文本的关键字提取的效果不同，问题和回答体悟关键字也不同，所以这里对长短文本分开处理\n",
    "# 短文本一般只有一个核心词，而长一点的文本则有多个\n",
    "def extract_key_words(text, text_rank = False):\n",
    "    allow_flag=['a', 'ad', 'ag', 'an', 'b', 'd',\n",
    "                'df', 'dg', 'eng', 'f', 'g', 'h',\n",
    "                'i', 'j', 'k', 'l', 'n',\n",
    "                'ns', 'nt', 'nz',\n",
    "                's', 't', 'tg','v', 'vd', 'vg', 'vi',\n",
    "                'vn', 'vq']\n",
    "    extractor = jieba.analyse.extract_tags if not text_rank else jieba.analyse.textrank\n",
    "    if len(text) <= 6:\n",
    "        return extractor(text, topK=1, withWeight=True)\n",
    "    else:\n",
    "        return extractor(text, topK=3, withWeight=True, allowPOS=allow_flag)\n",
    "        \n",
    "\n",
    "def key_words(data):\n",
    "    # 两种算法的并集作为关键词\n",
    "    # 利用tfidf和textrank来获取关键词\n",
    "    # 有时候两种算法都不能覆盖到关键字，大约有1800多条就人工提取把\n",
    "\n",
    "    start = time()\n",
    "    data['key_words_tfidf'] = data.apply(lambda x: extract_key_words(str(x['d1'])+\" \"+str(x['d2'])), axis=1)\n",
    "    print(\"合并问答对TFIDF提取关键词累积耗时:{:.2f}\".format(time()-start))\n",
    "    data['key_words_textrank'] = data.apply(lambda x: extract_key_words(str(x['d1'])+\" \"+str(x['d2']), text_rank=True), axis=1)\n",
    "    print(\"合并问答对TextRank提取关键词累积耗时:{:.2f}\".format(time()-start))\n",
    "    data['d1_key_words_tfidf'] = data['d1'].apply(lambda x: extract_key_words(str(x)))\n",
    "    print(\"d1 TFIDF提取关键词累积耗时:{:.2f}\".format(time()-start))\n",
    "    data['d2_key_words_tfidf'] = data['d2'].apply(lambda x: extract_key_words(str(x)))\n",
    "    print(\"d2 TFIDF提取关键词累积耗时:{:.2f}\".format(time()-start))\n",
    "    data['d1_key_words_textrank'] = data['d1'].apply(lambda x: extract_key_words(str(x), text_rank=True))\n",
    "    print(\"d1 TextRank提取关键词累积耗时:{:.2f}\".format(time()-start))\n",
    "    data['d2_key_words_textrank'] = data['d2'].apply(lambda x: extract_key_words(str(x), text_rank=True))\n",
    "    print(\"d2 TextRank提取关键词累积耗时:{:.2f}\".format(time()-start))\n",
    "    data['key_words'] = data.apply(lambda x: key_words_union(x['key_words_tfidf'], x['key_words_textrank']), axis=1)\n",
    "    print(\"取两种算法结果并集提取关键词累积耗时:{:.2f}\".format(time()-start))\n",
    "    data['key_words_i'] = data.apply(lambda x: key_words_intersection(x['key_words_tfidf'], x['key_words_textrank']), axis=1)\n",
    "    print(\"取两种算法结果交集提取关键词累积耗时:{:.2f}\".format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并问答对TFIDF提取关键词累积耗时:141.10\n",
      "合并问答对TextRank提取关键词累积耗时:297.72\n",
      "d1 TFIDF提取关键词累积耗时:341.87\n",
      "d2 TFIDF提取关键词累积耗时:408.70\n",
      "d1 TextRank提取关键词累积耗时:474.30\n",
      "d2 TextRank提取关键词累积耗时:562.05\n",
      "取两种算法结果并集提取关键词累积耗时:564.04\n",
      "取两种算法结果交集提取关键词累积耗时:566.00\n"
     ]
    }
   ],
   "source": [
    "key_words(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "      <th>d1_word_cut</th>\n",
       "      <th>d2_word_cut</th>\n",
       "      <th>key_words_tfidf</th>\n",
       "      <th>key_words_textrank</th>\n",
       "      <th>d1_key_words_tfidf</th>\n",
       "      <th>d2_key_words_tfidf</th>\n",
       "      <th>d1_key_words_textrank</th>\n",
       "      <th>d2_key_words_textrank</th>\n",
       "      <th>key_words</th>\n",
       "      <th>key_words_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>0</td>\n",
       "      <td>杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[采荷, 一, 小, 是, 分校, 吧]</td>\n",
       "      <td>[杭州市采荷第一小学, 钱江苑校区, ，, 杭州市, 钱江新城实验学校, 。]</td>\n",
       "      <td>[(杭州市, 2.3164871659375), (实验学校, 1.462931634325...</td>\n",
       "      <td>[(杭州市, 1.0), (新城, 0.504449124178066), (校区, 0.4...</td>\n",
       "      <td>[(分校, 4.60009864309), (一小, 3.88909242123)]</td>\n",
       "      <td>[(杭州市, 3.0886495545833337), (实验学校, 1.950575512...</td>\n",
       "      <td>[(分校, 1.0), (一小, 0.9961264494011037)]</td>\n",
       "      <td>[(杭州市, 1.0), (新城, 0.6213251057675828), (校区, 0....</td>\n",
       "      <td>{杭州市, 校区}</td>\n",
       "      <td>{杭州市, 校区}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>1</td>\n",
       "      <td>是的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[采荷, 一, 小, 是, 分校, 吧]</td>\n",
       "      <td>[是, 的]</td>\n",
       "      <td>[(分校, 4.60009864309), (一小, 3.88909242123)]</td>\n",
       "      <td>[(分校, 1.0), (一小, 0.9961264494011037)]</td>\n",
       "      <td>[(分校, 4.60009864309), (一小, 3.88909242123)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(分校, 1.0), (一小, 0.9961264494011037)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{一小, 分校}</td>\n",
       "      <td>{一小, 分校}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>2</td>\n",
       "      <td>这是5楼</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[采荷, 一, 小, 是, 分校, 吧]</td>\n",
       "      <td>[这, 是, 5, 楼]</td>\n",
       "      <td>[(分校, 4.60009864309), (一小, 3.88909242123)]</td>\n",
       "      <td>[(分校, 1.0), (一小, 0.9961264494011037)]</td>\n",
       "      <td>[(分校, 4.60009864309), (一小, 3.88909242123)]</td>\n",
       "      <td>[(这是, 4.29162827639)]</td>\n",
       "      <td>[(分校, 1.0), (一小, 0.9961264494011037)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{一小, 分校}</td>\n",
       "      <td>{一小, 分校}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>因为公积金贷款贷的少</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[毛坯, 吗, ？]</td>\n",
       "      <td>[因为, 公积金, 贷款, 贷, 的, 少]</td>\n",
       "      <td>[(毛坯, 3.7308758169666665), (公积金, 2.78778112832...</td>\n",
       "      <td>[(贷款, 1.0), (公积金, 0.9961264494011037)]</td>\n",
       "      <td>[(毛坯, 11.1926274509)]</td>\n",
       "      <td>[(公积金, 4.18167169248), (贷款, 2.836784708815)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(贷款, 1.0), (公积金, 0.9961264494011037)]</td>\n",
       "      <td>{贷款, 公积金}</td>\n",
       "      <td>{贷款, 公积金}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>是呢</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[毛坯, 吗, ？]</td>\n",
       "      <td>[是, 呢]</td>\n",
       "      <td>[(毛坯, 11.1926274509)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(毛坯, 11.1926274509)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53752</th>\n",
       "      <td>13998</td>\n",
       "      <td>这套房子有啥问题吗  我看价格不高</td>\n",
       "      <td>3</td>\n",
       "      <td>租约还有两年</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[这, 套, 房子, 有, 啥, 问题, 吗,  ,  , 我, 看, 价格, 不, 高]</td>\n",
       "      <td>[租约, 还有, 两年]</td>\n",
       "      <td>[(租约, 2.1066763644), (房子, 1.2631809148720001),...</td>\n",
       "      <td>[(租约, 1.0), (问题, 0.6703672480838158), (房子, 0.6...</td>\n",
       "      <td>[(房子, 2.105301524786667), (价格, 1.5155855171733...</td>\n",
       "      <td>[(租约, 3.511127274)]</td>\n",
       "      <td>[(问题, 1.0), (房子, 0.9961264494011037)]</td>\n",
       "      <td>[(还有, 1.0)]</td>\n",
       "      <td>{房子, 租约}</td>\n",
       "      <td>{房子, 租约}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53753</th>\n",
       "      <td>13998</td>\n",
       "      <td>这套房子有啥问题吗  我看价格不高</td>\n",
       "      <td>4</td>\n",
       "      <td>都有学位的</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[这, 套, 房子, 有, 啥, 问题, 吗,  ,  , 我, 看, 价格, 不, 高]</td>\n",
       "      <td>[都, 有, 学位, 的]</td>\n",
       "      <td>[(学位, 2.08790039177), (房子, 1.57897614359), (价格...</td>\n",
       "      <td>[(问题, 1.0), (房子, 0.9961264494011037)]</td>\n",
       "      <td>[(房子, 2.105301524786667), (价格, 1.5155855171733...</td>\n",
       "      <td>[(学位, 8.35160156708)]</td>\n",
       "      <td>[(问题, 1.0), (房子, 0.9961264494011037)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{房子}</td>\n",
       "      <td>{房子}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53754</th>\n",
       "      <td>13999</td>\n",
       "      <td>我看看时间吧</td>\n",
       "      <td>0</td>\n",
       "      <td>没有呢</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[我, 看看, 时间, 吧]</td>\n",
       "      <td>[没有, 呢]</td>\n",
       "      <td>[(看看, 1.8034815473799999), (时间, 1.359846544153...</td>\n",
       "      <td>[(看看, 1.0), (没有, 0.9966849915940917), (时间, 0.9...</td>\n",
       "      <td>[(看看, 2.70522232107)]</td>\n",
       "      <td>[(没有, 3.11282356515)]</td>\n",
       "      <td>[(看看, 1.0)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{看看, 时间, 没有}</td>\n",
       "      <td>{看看, 时间, 没有}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53755</th>\n",
       "      <td>13999</td>\n",
       "      <td>我看看时间吧</td>\n",
       "      <td>1</td>\n",
       "      <td>今天新上的</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[我, 看看, 时间, 吧]</td>\n",
       "      <td>[今天, 新, 上, 的]</td>\n",
       "      <td>[(看看, 1.8034815473799999), (今天, 1.664039425610...</td>\n",
       "      <td>[(看看, 1.0), (时间, 0.9966849915940917), (今天, 0.9...</td>\n",
       "      <td>[(看看, 2.70522232107)]</td>\n",
       "      <td>[(新上, 5.97738375145)]</td>\n",
       "      <td>[(看看, 1.0)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{看看, 时间, 今天}</td>\n",
       "      <td>{看看, 时间, 今天}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53756</th>\n",
       "      <td>13999</td>\n",
       "      <td>我看看时间吧</td>\n",
       "      <td>2</td>\n",
       "      <td>房子我也没看过呢，不知道是几号楼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[我, 看看, 时间, 吧]</td>\n",
       "      <td>[房子, 我, 也, 没看过, 呢, ，, 不知道, 是, 几号, 楼]</td>\n",
       "      <td>[(几号楼, 2.3167796086666668), (看过, 1.22000641911...</td>\n",
       "      <td>[(房子, 1.0), (知道, 0.8093986725331231), (看过, 0.7...</td>\n",
       "      <td>[(看看, 2.70522232107)]</td>\n",
       "      <td>[(几号楼, 3.475169413), (看过, 1.8300096286725), (房...</td>\n",
       "      <td>[(看看, 1.0)]</td>\n",
       "      <td>[(知道, 1.0), (看过, 0.9942864157411772), (几号楼, 0....</td>\n",
       "      <td>{看过, 房子}</td>\n",
       "      <td>{看过, 房子}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75342 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cid                 d1  rid                           d2  label  \\\n",
       "0          0           采荷一小是分校吧    0  杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。    1.0   \n",
       "1          0           采荷一小是分校吧    1                           是的    0.0   \n",
       "2          0           采荷一小是分校吧    2                         这是5楼    0.0   \n",
       "3          1               毛坯吗？    0                   因为公积金贷款贷的少    0.0   \n",
       "4          1               毛坯吗？    1                           是呢    0.0   \n",
       "...      ...                ...  ...                          ...    ...   \n",
       "53752  13998  这套房子有啥问题吗  我看价格不高    3                       租约还有两年    NaN   \n",
       "53753  13998  这套房子有啥问题吗  我看价格不高    4                        都有学位的    NaN   \n",
       "53754  13999             我看看时间吧    0                          没有呢    NaN   \n",
       "53755  13999             我看看时间吧    1                        今天新上的    NaN   \n",
       "53756  13999             我看看时间吧    2             房子我也没看过呢，不知道是几号楼    NaN   \n",
       "\n",
       "                                         d1_word_cut  \\\n",
       "0                               [采荷, 一, 小, 是, 分校, 吧]   \n",
       "1                               [采荷, 一, 小, 是, 分校, 吧]   \n",
       "2                               [采荷, 一, 小, 是, 分校, 吧]   \n",
       "3                                         [毛坯, 吗, ？]   \n",
       "4                                         [毛坯, 吗, ？]   \n",
       "...                                              ...   \n",
       "53752  [这, 套, 房子, 有, 啥, 问题, 吗,  ,  , 我, 看, 价格, 不, 高]   \n",
       "53753  [这, 套, 房子, 有, 啥, 问题, 吗,  ,  , 我, 看, 价格, 不, 高]   \n",
       "53754                                 [我, 看看, 时间, 吧]   \n",
       "53755                                 [我, 看看, 时间, 吧]   \n",
       "53756                                 [我, 看看, 时间, 吧]   \n",
       "\n",
       "                                   d2_word_cut  \\\n",
       "0      [杭州市采荷第一小学, 钱江苑校区, ，, 杭州市, 钱江新城实验学校, 。]   \n",
       "1                                       [是, 的]   \n",
       "2                                 [这, 是, 5, 楼]   \n",
       "3                       [因为, 公积金, 贷款, 贷, 的, 少]   \n",
       "4                                       [是, 呢]   \n",
       "...                                        ...   \n",
       "53752                             [租约, 还有, 两年]   \n",
       "53753                            [都, 有, 学位, 的]   \n",
       "53754                                  [没有, 呢]   \n",
       "53755                            [今天, 新, 上, 的]   \n",
       "53756     [房子, 我, 也, 没看过, 呢, ，, 不知道, 是, 几号, 楼]   \n",
       "\n",
       "                                         key_words_tfidf  \\\n",
       "0      [(杭州市, 2.3164871659375), (实验学校, 1.462931634325...   \n",
       "1             [(分校, 4.60009864309), (一小, 3.88909242123)]   \n",
       "2             [(分校, 4.60009864309), (一小, 3.88909242123)]   \n",
       "3      [(毛坯, 3.7308758169666665), (公积金, 2.78778112832...   \n",
       "4                                  [(毛坯, 11.1926274509)]   \n",
       "...                                                  ...   \n",
       "53752  [(租约, 2.1066763644), (房子, 1.2631809148720001),...   \n",
       "53753  [(学位, 2.08790039177), (房子, 1.57897614359), (价格...   \n",
       "53754  [(看看, 1.8034815473799999), (时间, 1.359846544153...   \n",
       "53755  [(看看, 1.8034815473799999), (今天, 1.664039425610...   \n",
       "53756  [(几号楼, 2.3167796086666668), (看过, 1.22000641911...   \n",
       "\n",
       "                                      key_words_textrank  \\\n",
       "0      [(杭州市, 1.0), (新城, 0.504449124178066), (校区, 0.4...   \n",
       "1                  [(分校, 1.0), (一小, 0.9961264494011037)]   \n",
       "2                  [(分校, 1.0), (一小, 0.9961264494011037)]   \n",
       "3                 [(贷款, 1.0), (公积金, 0.9961264494011037)]   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "53752  [(租约, 1.0), (问题, 0.6703672480838158), (房子, 0.6...   \n",
       "53753              [(问题, 1.0), (房子, 0.9961264494011037)]   \n",
       "53754  [(看看, 1.0), (没有, 0.9966849915940917), (时间, 0.9...   \n",
       "53755  [(看看, 1.0), (时间, 0.9966849915940917), (今天, 0.9...   \n",
       "53756  [(房子, 1.0), (知道, 0.8093986725331231), (看过, 0.7...   \n",
       "\n",
       "                                      d1_key_words_tfidf  \\\n",
       "0             [(分校, 4.60009864309), (一小, 3.88909242123)]   \n",
       "1             [(分校, 4.60009864309), (一小, 3.88909242123)]   \n",
       "2             [(分校, 4.60009864309), (一小, 3.88909242123)]   \n",
       "3                                  [(毛坯, 11.1926274509)]   \n",
       "4                                  [(毛坯, 11.1926274509)]   \n",
       "...                                                  ...   \n",
       "53752  [(房子, 2.105301524786667), (价格, 1.5155855171733...   \n",
       "53753  [(房子, 2.105301524786667), (价格, 1.5155855171733...   \n",
       "53754                              [(看看, 2.70522232107)]   \n",
       "53755                              [(看看, 2.70522232107)]   \n",
       "53756                              [(看看, 2.70522232107)]   \n",
       "\n",
       "                                      d2_key_words_tfidf  \\\n",
       "0      [(杭州市, 3.0886495545833337), (实验学校, 1.950575512...   \n",
       "1                                                     []   \n",
       "2                                  [(这是, 4.29162827639)]   \n",
       "3           [(公积金, 4.18167169248), (贷款, 2.836784708815)]   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "53752                                [(租约, 3.511127274)]   \n",
       "53753                              [(学位, 8.35160156708)]   \n",
       "53754                              [(没有, 3.11282356515)]   \n",
       "53755                              [(新上, 5.97738375145)]   \n",
       "53756  [(几号楼, 3.475169413), (看过, 1.8300096286725), (房...   \n",
       "\n",
       "                       d1_key_words_textrank  \\\n",
       "0      [(分校, 1.0), (一小, 0.9961264494011037)]   \n",
       "1      [(分校, 1.0), (一小, 0.9961264494011037)]   \n",
       "2      [(分校, 1.0), (一小, 0.9961264494011037)]   \n",
       "3                                         []   \n",
       "4                                         []   \n",
       "...                                      ...   \n",
       "53752  [(问题, 1.0), (房子, 0.9961264494011037)]   \n",
       "53753  [(问题, 1.0), (房子, 0.9961264494011037)]   \n",
       "53754                            [(看看, 1.0)]   \n",
       "53755                            [(看看, 1.0)]   \n",
       "53756                            [(看看, 1.0)]   \n",
       "\n",
       "                                   d2_key_words_textrank     key_words  \\\n",
       "0      [(杭州市, 1.0), (新城, 0.6213251057675828), (校区, 0....     {杭州市, 校区}   \n",
       "1                                                     []      {一小, 分校}   \n",
       "2                                                     []      {一小, 分校}   \n",
       "3                 [(贷款, 1.0), (公积金, 0.9961264494011037)]     {贷款, 公积金}   \n",
       "4                                                     []            {}   \n",
       "...                                                  ...           ...   \n",
       "53752                                        [(还有, 1.0)]      {房子, 租约}   \n",
       "53753                                                 []          {房子}   \n",
       "53754                                                 []  {看看, 时间, 没有}   \n",
       "53755                                                 []  {看看, 时间, 今天}   \n",
       "53756  [(知道, 1.0), (看过, 0.9942864157411772), (几号楼, 0....      {看过, 房子}   \n",
       "\n",
       "        key_words_i  \n",
       "0         {杭州市, 校区}  \n",
       "1          {一小, 分校}  \n",
       "2          {一小, 分校}  \n",
       "3         {贷款, 公积金}  \n",
       "4                {}  \n",
       "...             ...  \n",
       "53752      {房子, 租约}  \n",
       "53753          {房子}  \n",
       "53754  {看看, 时间, 没有}  \n",
       "53755  {看看, 时间, 今天}  \n",
       "53756      {看过, 房子}  \n",
       "\n",
       "[75342 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75342it [00:10, 7016.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# 统计共现矩阵，这里统计的是关键词在在一条记录中共现的\n",
    "# 还有一种基于相似度的图，这里将关键词的相似度来构建出图特征\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "graph = nx.Graph()\n",
    "\n",
    "def fetch_nodes(data):\n",
    "    key_words = set()\n",
    "    for i, row in data.iterrows():\n",
    "        res = row['key_words']\n",
    "        key_words.update(res)\n",
    "\n",
    "    # 顶点用数字表示==\n",
    "    nodes2words = [_ for _ in key_words]\n",
    "    words2nodes = {word:idx for idx, word in enumerate(nodes2words)}\n",
    "    return nodes2words, words2nodes\n",
    "\n",
    "\n",
    "def build_graph(graph, data):\n",
    "    # 将顶点加入到图中\n",
    "    graph.add_nodes_from([_ for _ in range(len(nodes2words))])\n",
    "\n",
    "    # 给图增加边，一条记录的所有关键词两两之间都有边\n",
    "    for i, row in tqdm(data.iterrows()):\n",
    "        res = list(row['key_words'])\n",
    "        if len(res) >= 2:\n",
    "            for i in range(len(res)-1):\n",
    "                for j in range(i, len(res)):\n",
    "                    graph.add_edge(words2nodes[res[i]], words2nodes[res[j]])\n",
    "\n",
    "nodes2words, words2nodes = fetch_nodes(df_raw)\n",
    "build_graph(graph, df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 主要提取的特征有：每个关键字的连接边数（度），pagerrank值， hits算法的A和H值，每个关键词的邻居数量\n",
    "\n",
    "# 所有节点的连通分量\n",
    "def components(graph):\n",
    "    max_components = {}\n",
    "    components = nx.connected_components(graph)\n",
    "    for component in components:\n",
    "        for n in component:\n",
    "            max_components[n] = max(max_components.get(n, 0), len(component))\n",
    "    return max_components\n",
    "\n",
    "# hits算法\n",
    "def hits(graph):\n",
    "    hits_h, hits_a = nx.hits(graph, max_iter=500)\n",
    "    return hits_h, hits_a\n",
    "\n",
    "# 所有单词的度的计算\n",
    "def degrees(graph):\n",
    "    max_degrees = {}\n",
    "    edges = graph.edges()\n",
    "    for edge in edges:\n",
    "        for n in edge:\n",
    "            max_degrees[n] = max_degrees.get(n, 0) + 1\n",
    "    return max_degrees\n",
    "\n",
    "# 先求所有关键词的连通分量、hits、度\n",
    "max_components = components(graph)\n",
    "hits_h, hits_a = hits(graph)\n",
    "max_degrees = degrees(graph)\n",
    "pagerank = nx.pagerank_scipy(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图特征\n",
    "def graph_feature(data, graph):\n",
    "    data['neighbors_num_coo'] = data['key_words'].apply(lambda x: [len(set(graph.neighbors(words2nodes[_]))) for _ in x])\n",
    "    data['hits_a_coo'] = data['key_words'].apply(lambda x: [hits_a[words2nodes[_]] for _ in x])\n",
    "    data['hits_h_coo'] = data['key_words'].apply(lambda x: [hits_h[words2nodes[_]] for _ in x])\n",
    "    data['max_degrees_coo'] = data['key_words'].apply(lambda x: [max_degrees.get(words2nodes[_], 0) for _ in x])\n",
    "    data['pagerank_coo'] = data['key_words'].apply(lambda x: [pagerank[words2nodes[_]] for _ in x])\n",
    "    \n",
    "    # 映射成数值\n",
    "    data['max_hits_a_coo'] = data['hits_a_coo'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_hits_a_coo'] = data['hits_a_coo'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_max_degrees_coo'] = data['max_degrees_coo'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_max_degrees_coo'] = data['max_degrees_coo'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_pagerank_coo'] = data['pagerank_coo'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_pagerank_coo'] = data['pagerank_coo'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    \n",
    "    data['max_tfidf_coo'] = data['key_words_tfidf'].apply(lambda x: max([_[1] for _ in x]) if len(x) > 0 else 0)\n",
    "    data['mean_tfidf_coo'] = data['key_words_tfidf'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "    data['max_textrank_coo'] = data['key_words_textrank'].apply(lambda x: max([_[1] for _ in x])  if len(x) > 0 else 0)\n",
    "    data['mean_textrank_coo'] = data['key_words_textrank'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "\n",
    "graph_feature(df_raw, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# 再基于相似度来构造图模型\n",
    "# 根据关键字的相似词图构造图特征\n",
    "sim_graph = nx.Graph()\n",
    "\n",
    "def fetch_nodes():\n",
    "    # 顶点用数字表示==\n",
    "    nodes2words = w2v.wv.index2word\n",
    "    words2nodes = {word:idx for idx, word in enumerate(nodes2words)}\n",
    "    return nodes2words, words2nodes\n",
    "\n",
    "\n",
    "def build_graph(graph):\n",
    "    # 将顶点加入到图中\n",
    "    graph.add_nodes_from([_ for _ in range(len(nodes2words))])\n",
    "\n",
    "    # 给图增加边，一条记录的所有关键词两两之间都有边\n",
    "    for word in nodes2words:\n",
    "        similarities = w2v.wv.most_similar(word, topn=3)\n",
    "        for sim in similarities:\n",
    "            graph.add_edge(words2nodes[word], words2nodes[sim[0]])\n",
    "\n",
    "nodes2words, words2nodes = fetch_nodes()\n",
    "build_graph(sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_components = components(sim_graph)\n",
    "hits_h, hits_a = hits(sim_graph)\n",
    "max_degrees = degrees(sim_graph)\n",
    "pagerank = nx.pagerank_scipy(sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图特征\n",
    "def graph_feature(data, graph):\n",
    "    data['neighbors_num_sim'] = data['key_words'].apply(lambda x: [len(set(graph.neighbors(words2nodes[_]))) if _ in words2nodes else 0. for _ in x])\n",
    "    data['hits_a_sim'] = data['key_words'].apply(lambda x: [hits_a[words2nodes[_]] if _ in words2nodes else 0.  for _ in x])\n",
    "    data['hits_h_sim'] = data['key_words'].apply(lambda x: [hits_h[words2nodes[_]] if _ in words2nodes else 0.  for _ in x])\n",
    "    data['max_degrees_sim'] = data['key_words'].apply(lambda x: [max_degrees.get(words2nodes[_], 0)  if _ in words2nodes else 0  for _ in x])\n",
    "    data['pagerank_sim'] = data['key_words'].apply(lambda x: [pagerank[words2nodes[_]] if _ in words2nodes else 0.  for _ in x])\n",
    "    \n",
    "    # 映射成数值\n",
    "    data['max_hits_a_sim'] = data['hits_a_sim'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_hits_a_sim'] = data['hits_a_sim'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_max_degrees_sim'] = data['max_degrees_sim'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_max_degrees_sim'] = data['max_degrees_sim'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_pagerank_sim'] = data['pagerank_sim'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_pagerank_sim'] = data['pagerank_sim'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    \n",
    "    data['max_tfidf_sim'] = data['key_words_tfidf'].apply(lambda x: max([_[1] for _ in x]) if len(x) > 0 else 0)\n",
    "    data['mean_tfidf_sim'] = data['key_words_tfidf'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "    data['max_textrank_sim'] = data['key_words_textrank'].apply(lambda x: max([_[1] for _ in x])  if len(x) > 0 else 0)\n",
    "    data['mean_textrank_sim'] = data['key_words_textrank'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "\n",
    "graph_feature(df_raw, sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MiniConda\\lib\\site-packages\\gensim\\models\\doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "INFO:gensim.models.doc2vec:collecting all words and their counts\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #10000, processed 65462 words (735556/s), 5813 word types, 10000 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #20000, processed 132114 words (789530/s), 8771 word types, 20000 tags\n",
      "INFO:gensim.models.doc2vec:collected 9196 word types and 21585 unique tags from a corpus of 21585 examples and 142375 words\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 retains 1764 unique words (19% of original 9196, drops 7432)\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 leaves 131564 word corpus (92% of original 142375, drops 10811)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 9196 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 68 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 87256 word corpus (66.3% of prior 131564)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 1764 words and 300 dimensions: 31017600 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 4 workers on 1764 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 35.06% examples, 25365 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 84.15% examples, 36355 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 142375 raw words (108609 effective words) took 2.9s, 37801 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 35.21% examples, 23459 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 92.90% examples, 37860 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 142375 raw words (109109 effective words) took 2.7s, 40513 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 35.06% examples, 29363 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 84.15% examples, 39855 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 142375 raw words (108704 effective words) took 2.5s, 42761 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 35.06% examples, 28816 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 100.00% examples, 46710 words/s, in_qsize 0, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 142375 raw words (108871 effective words) took 2.3s, 46662 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 35.06% examples, 28071 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 92.90% examples, 42733 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 142375 raw words (108882 effective words) took 2.4s, 45731 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 711875 raw words (544175 effective words) took 12.9s, 42173 effective words/s\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "INFO:gensim.models.base_any2vec:training model with 4 workers on 1764 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 35.06% examples, 27243 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 92.90% examples, 39449 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 142375 raw words (108795 effective words) took 2.6s, 42241 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 35.06% examples, 22536 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 142375 raw words (108679 effective words) took 2.7s, 40786 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 35.06% examples, 26200 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 85.92% examples, 37799 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 142375 raw words (108896 effective words) took 2.7s, 40138 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 35.06% examples, 23627 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 85.92% examples, 35775 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 142375 raw words (108986 effective words) took 2.8s, 38364 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 35.06% examples, 29067 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 92.90% examples, 41526 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 142375 raw words (108934 effective words) took 2.5s, 44346 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 35.06% examples, 28869 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 92.90% examples, 41146 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 6 : training on 142375 raw words (108868 effective words) took 2.5s, 44104 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 35.06% examples, 26578 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 92.90% examples, 40626 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 7 : training on 142375 raw words (108889 effective words) took 2.5s, 43549 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 35.06% examples, 24053 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 92.90% examples, 36391 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 8 : training on 142375 raw words (108876 effective words) took 2.8s, 38999 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 35.21% examples, 26525 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 85.92% examples, 37320 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 9 : training on 142375 raw words (108618 effective words) took 2.7s, 40109 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 35.06% examples, 27938 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 70.12% examples, 32269 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 10 : training on 142375 raw words (108934 effective words) took 2.8s, 38353 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 7.00% examples, 7573 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 62.99% examples, 24851 words/s, in_qsize 6, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 11 : training on 142375 raw words (108839 effective words) took 3.2s, 34524 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 35.06% examples, 25714 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 85.92% examples, 35643 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 12 : training on 142375 raw words (109040 effective words) took 2.9s, 38001 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 35.06% examples, 25974 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 93.02% examples, 37768 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 13 : training on 142375 raw words (108789 effective words) took 2.7s, 40494 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 35.06% examples, 21944 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 92.90% examples, 35440 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 14 : training on 142375 raw words (108969 effective words) took 2.9s, 37911 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 35.06% examples, 27804 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 92.90% examples, 41558 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 15 : training on 142375 raw words (109070 effective words) took 2.5s, 44205 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 35.06% examples, 27065 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 92.90% examples, 40994 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 16 : training on 142375 raw words (108694 effective words) took 2.5s, 43869 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 35.21% examples, 23741 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 93.02% examples, 38207 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 17 : training on 142375 raw words (108748 effective words) took 2.6s, 41039 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 35.06% examples, 24273 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 92.90% examples, 37258 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 18 : training on 142375 raw words (108625 effective words) took 2.7s, 39947 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 35.06% examples, 26853 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 92.90% examples, 39753 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 19 : training on 142375 raw words (108741 effective words) took 2.6s, 42506 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 35.06% examples, 26979 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 92.90% examples, 41772 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 20 : training on 142375 raw words (108839 effective words) took 2.4s, 44795 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 21 - PROGRESS: at 35.06% examples, 28340 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 21 - PROGRESS: at 92.90% examples, 40367 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 21 : training on 142375 raw words (108814 effective words) took 2.5s, 43105 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 22 - PROGRESS: at 35.06% examples, 24881 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 22 - PROGRESS: at 92.90% examples, 38268 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 22 : training on 142375 raw words (108845 effective words) took 2.7s, 40905 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 23 - PROGRESS: at 35.06% examples, 28687 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 23 - PROGRESS: at 85.92% examples, 39941 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 23 : training on 142375 raw words (108878 effective words) took 2.6s, 42620 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 24 - PROGRESS: at 35.06% examples, 21537 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 24 - PROGRESS: at 85.92% examples, 33084 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 24 : training on 142375 raw words (108975 effective words) took 3.1s, 35585 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 25 - PROGRESS: at 35.06% examples, 22090 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 25 - PROGRESS: at 92.90% examples, 35530 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 25 : training on 142375 raw words (108695 effective words) took 2.9s, 38001 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 26 - PROGRESS: at 35.06% examples, 23459 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 26 - PROGRESS: at 92.90% examples, 38450 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 26 : training on 142375 raw words (108823 effective words) took 2.6s, 41072 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 27 - PROGRESS: at 35.06% examples, 25307 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 27 - PROGRESS: at 92.90% examples, 38358 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 27 : training on 142375 raw words (108700 effective words) took 2.6s, 41046 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 28 - PROGRESS: at 35.06% examples, 25095 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 28 - PROGRESS: at 85.92% examples, 36267 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 28 : training on 142375 raw words (108947 effective words) took 2.8s, 39237 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 29 - PROGRESS: at 35.06% examples, 30499 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 29 - PROGRESS: at 92.90% examples, 43428 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 29 : training on 142375 raw words (109024 effective words) took 2.4s, 46103 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 30 - PROGRESS: at 35.06% examples, 25240 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 30 - PROGRESS: at 92.90% examples, 37670 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 30 : training on 142375 raw words (108749 effective words) took 2.7s, 40302 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 4271250 raw words (3265279 effective words) took 80.7s, 40460 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# 训练doc2vec，将每一个句子表示成句向量，然后通过句向量和关键词匹配程度寻找特征\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from LAC import LAC\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "lac = LAC(mode='seg')\n",
    "\n",
    "# 将句子都分好词，然后包装好，生成句子向量\n",
    "def wrap_sentence(data):\n",
    "    sentences = []\n",
    "    # 把回答做句子编码就成\n",
    "    for i, row in data.iterrows():\n",
    "        sentences.append(TaggedDocument(lac.run(row['d2']), tags=[i]))\n",
    "    return sentences\n",
    "\n",
    "sentences = wrap_sentence(df_cleaned)\n",
    "d2v = Doc2Vec(sentences, window=5, size=300, sample=1e-3, workers=4, negative=5)\n",
    "d2v.train(sentences, total_examples=d2v.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['杭州市采荷第一小学', '钱江苑校区', '，', '杭州市', '钱江新城实验学校', '。'], tags=[0]),\n",
       " TaggedDocument(words=['是', '的'], tags=[1]),\n",
       " TaggedDocument(words=['这', '是', '5', '楼'], tags=[2]),\n",
       " TaggedDocument(words=['因为', '公积金', '贷款', '贷', '的', '少'], tags=[3]),\n",
       " TaggedDocument(words=['是', '呢'], tags=[4]),\n",
       " TaggedDocument(words=['这', '套', '一', '楼', '带', '院', '的', '，', '您', '看看'], tags=[5]),\n",
       " TaggedDocument(words=['房本', '都是', '五年', '外', '的'], tags=[6]),\n",
       " TaggedDocument(words=['好', '的', '?', '?', '，', '您', '先', '看', '下'], tags=[7]),\n",
       " TaggedDocument(words=['您', '是', '首套', '还是', '二套', '呢', '？'], tags=[8]),\n",
       " TaggedDocument(words=['所有', '费用', '下来', '654万'], tags=[9])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Doc2Vec object under d2v.pkt, separately None\n",
      "INFO:gensim.utils:saved d2v.pkt\n"
     ]
    }
   ],
   "source": [
    "# 保存好模型\n",
    "d2v.save(\"d2v.pkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用词向量和句子向量之间来度量\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def distance_calc(data):\n",
    "    \n",
    "    def union(l1, l2):\n",
    "        s1 = set(_[0] for _ in l1)\n",
    "        s2 = set(_[0] for _ in l2)\n",
    "        return s1.union(s2)\n",
    "    \n",
    "    def extractor(x):\n",
    "        res = union(x['d1_key_words_tfidf'], x['d1_key_words_textrank'])\n",
    "        if res == set():\n",
    "            ans = list(psg.cut(str(x['d1'])))\n",
    "            key_words = set([_.word for _ in ans if 'n' in _.flag or 'v' in _.flag or 'm' in _.flag or 'r' in _.flag])\n",
    "            if key_words == set() and len(str(x['d1']))<=2:\n",
    "                key_words.add(str(x['d1']))\n",
    "            return key_words\n",
    "        else:\n",
    "            return res\n",
    "        \n",
    "    def cosine(w1, w2):\n",
    "        return w1.dot(w2) / (math.sqrt((w1**2).sum()) * math.sqrt((w2**2).sum()))\n",
    "    \n",
    "    def euclidean(w1, w2):\n",
    "        return math.sqrt(((w1-w2)**2).sum())\n",
    "    \n",
    "    def inner_product(w1, w2):\n",
    "        return np.dot(w1, w2)\n",
    "        \n",
    "    # 单词之间的余弦相似度\n",
    "    def ww_(x, method=\"cosine\"):\n",
    "        if method == \"cosine\":\n",
    "            distance = cosine\n",
    "        elif method == \"euclidean\":\n",
    "            distance = euclidean\n",
    "        elif \"pearson\" in method:\n",
    "            distance = stats.pearsonr\n",
    "        else:\n",
    "            distance = inner_product\n",
    "        cos = 0.\n",
    "        num = 0\n",
    "        if x['key_words'] == []:\n",
    "            return 0.\n",
    "        else:\n",
    "            for i in range(len(x['key_words'])-1):\n",
    "                for j in range(i+1, len(x['key_words'])):\n",
    "                    w1, w2 = list(x['key_words'])[i], list(x['key_words'])[j]\n",
    "                    if w1 not in w2v.wv.vocab or w2 not in w2v.wv.vocab:\n",
    "                        break\n",
    "                    w1, w2 = w2v.wv[w1], w2v.wv[w2]\n",
    "                    dist = distance(w1, w2)\n",
    "                    if method == \"pearson_cor\":\n",
    "                        dist = dist[0]\n",
    "                    elif method == \"pearson_pvalue\":\n",
    "                        dist = dist[1]\n",
    "                    cos += dist\n",
    "                    num += 1\n",
    "        return cos/num if num > 0 else 0\n",
    "    \n",
    "    def ww_(x, method=\"cosine\"):\n",
    "        if method == \"cosine\":\n",
    "            distance = cosine\n",
    "        elif method == \"euclidean\":\n",
    "            distance = euclidean\n",
    "        elif \"pearson\" in method:\n",
    "            distance = stats.pearsonr\n",
    "        else:\n",
    "            distance = inner_product\n",
    "        cos = 0.\n",
    "        num = 0\n",
    "        if x['key_words'] == []:\n",
    "            return 0.\n",
    "        else:\n",
    "            for i in range(len(x['key_words'])-1):\n",
    "                w1, w2 = list(x['key_words'])[i], x['d1']\n",
    "                if w1 not in w2v.wv.vocab or w2 not in w2v.wv.vocab:\n",
    "                    return 0\n",
    "                w1, w2 = w2v.wv[w1], w2v.wv[w2]\n",
    "                dist = distance(w1, w2)\n",
    "                if method == \"pearson_cor\":\n",
    "                    dist = dist[0]\n",
    "                elif method == \"pearson_pvalue\":\n",
    "                    dist = dist[1]\n",
    "                cos += dist\n",
    "                num += 1\n",
    "        return cos/num if num > 0 else 0\n",
    "        \n",
    "    data['d1_key_words'] = data.apply(lambda x: extractor(x), axis=1)\n",
    "    # 距离度量系列：余弦相似度、欧氏距离、皮尔逊相关系数\n",
    "    data['ww_cosine'] =  data.apply(lambda x: ww_(x, method=\"cosine\"), axis=1)\n",
    "    data['ww_euclidean'] = data.apply(lambda x: ww_(x, method=\"euclidean\"), axis=1)\n",
    "    data['ww_inner_product'] = data.apply(lambda x: ww_(x, method=\"\"), axis=1)\n",
    "    data['ww_pearson_cor'] = data.apply(lambda x: ww_(x, method=\"pearson_cor\"), axis=1)\n",
    "    data['ww_pearson_pvalue'] = data.apply(lambda x: ww_(x, method=\"pearson_pvalue\"), axis=1)\n",
    "    \n",
    "    # 计算关键词与文档向量的距离\n",
    "\n",
    "distance_calc(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共现矩阵和相似矩阵的构建\n",
    "coocurance = np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "      <th>d1_word_cut</th>\n",
       "      <th>d2_word_cut</th>\n",
       "      <th>d1_pos_tag</th>\n",
       "      <th>d2_pos_tag</th>\n",
       "      <th>shared_words</th>\n",
       "      <th>...</th>\n",
       "      <th>max_tfidf_sim</th>\n",
       "      <th>mean_tfidf_sim</th>\n",
       "      <th>max_textrank_sim</th>\n",
       "      <th>mean_textrank_sim</th>\n",
       "      <th>d1_key_words</th>\n",
       "      <th>ww_cosine</th>\n",
       "      <th>ww_euclidean</th>\n",
       "      <th>ww_inner_product</th>\n",
       "      <th>ww_pearson_cor</th>\n",
       "      <th>ww_pearson_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>0</td>\n",
       "      <td>杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[采荷, 一小, 是, 分校, 吧]</td>\n",
       "      <td>[杭州市, 采荷, 第一, 小学, 钱江苑, 校区, ，, 杭州市, 钱江, 新城, 实验学...</td>\n",
       "      <td>[nr, d, v, n, y]</td>\n",
       "      <td>[ns, nr, m, n, nr, n, x, ns, nr, ns, n, x]</td>\n",
       "      <td>[采荷]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.316487</td>\n",
       "      <td>1.666371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667346</td>\n",
       "      <td>{一小, 分校}</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>6.525649</td>\n",
       "      <td>35.439222</td>\n",
       "      <td>0.721577</td>\n",
       "      <td>1.503320e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>1</td>\n",
       "      <td>是的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[采荷, 一小, 是, 分校, 吧]</td>\n",
       "      <td>[是, 的]</td>\n",
       "      <td>[nr, d, v, n, y]</td>\n",
       "      <td>[v, uj]</td>\n",
       "      <td>[是]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600099</td>\n",
       "      <td>4.244596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{一小, 分校}</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>6.326831</td>\n",
       "      <td>72.129395</td>\n",
       "      <td>0.814207</td>\n",
       "      <td>2.414553e-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>2</td>\n",
       "      <td>这是5楼</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[采荷, 一小, 是, 分校, 吧]</td>\n",
       "      <td>[这是, 5, 楼]</td>\n",
       "      <td>[nr, d, v, n, y]</td>\n",
       "      <td>[r, v, m, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600099</td>\n",
       "      <td>4.244596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{一小, 分校}</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>6.326831</td>\n",
       "      <td>72.129395</td>\n",
       "      <td>0.814207</td>\n",
       "      <td>2.414553e-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>因为公积金贷款贷的少</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[毛坯, 吗, ？]</td>\n",
       "      <td>[因为, 公积金, 贷款, 贷, 的, 少]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[c, n, n, v, uj, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.730876</td>\n",
       "      <td>2.803282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{毛坯}</td>\n",
       "      <td>0.358034</td>\n",
       "      <td>9.279583</td>\n",
       "      <td>28.669621</td>\n",
       "      <td>0.357980</td>\n",
       "      <td>1.464102e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>是呢</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[毛坯, 吗, ？]</td>\n",
       "      <td>[是, 呢]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[v, y]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>11.192627</td>\n",
       "      <td>11.192627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{毛坯}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>2</td>\n",
       "      <td>这套一楼带院的，您看看</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[毛坯, 吗, ？]</td>\n",
       "      <td>[这套, 一楼, 带院, 的, ，, 您, 看看]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[r, q, n, n, uj, x, zg, v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.988692</td>\n",
       "      <td>2.705259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{毛坯}</td>\n",
       "      <td>0.261414</td>\n",
       "      <td>8.436319</td>\n",
       "      <td>9.165813</td>\n",
       "      <td>0.264155</td>\n",
       "      <td>2.499604e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>3</td>\n",
       "      <td>房本都是五年外的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[毛坯, 吗, ？]</td>\n",
       "      <td>[房本, 都, 是, 五年, 外, 的]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[n, d, v, t, f, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984923</td>\n",
       "      <td>3.291877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{毛坯}</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>11.473662</td>\n",
       "      <td>14.102968</td>\n",
       "      <td>0.188384</td>\n",
       "      <td>1.006249e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>4</td>\n",
       "      <td>好的??，您先看下</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[毛坯, 吗, ？]</td>\n",
       "      <td>[好, 的, ?, ?, ，, 您, 先, 看, 下]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[a, uj, x, x, x, r, d, v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>5.596314</td>\n",
       "      <td>5.580179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{毛坯}</td>\n",
       "      <td>0.068315</td>\n",
       "      <td>9.121356</td>\n",
       "      <td>3.014279</td>\n",
       "      <td>0.068243</td>\n",
       "      <td>2.386186e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>你们的佣金费大约是多少和契税是多少。</td>\n",
       "      <td>0</td>\n",
       "      <td>您是首套还是二套呢？</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]</td>\n",
       "      <td>[您, 是, 首套, 还是, 二套, 呢, ？]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[r, v, m, c, m, y, x]</td>\n",
       "      <td>[是]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.263268</td>\n",
       "      <td>2.675451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{大约, 佣金, 契税}</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>8.677430</td>\n",
       "      <td>25.828073</td>\n",
       "      <td>0.451183</td>\n",
       "      <td>3.532106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>你们的佣金费大约是多少和契税是多少。</td>\n",
       "      <td>1</td>\n",
       "      <td>所有费用下来654万</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]</td>\n",
       "      <td>[所有, 费用, 下来, 654, 万]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[b, n, t, m, m]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631634</td>\n",
       "      <td>1.358860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.779548</td>\n",
       "      <td>{大约, 佣金, 契税}</td>\n",
       "      <td>0.399413</td>\n",
       "      <td>10.100416</td>\n",
       "      <td>31.169064</td>\n",
       "      <td>0.399436</td>\n",
       "      <td>4.351321e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>你们的佣金费大约是多少和契税是多少。</td>\n",
       "      <td>2</td>\n",
       "      <td>包含着税费和我们的服务费和房款</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]</td>\n",
       "      <td>[包含, 着, 税费, 和, 我们, 的, 服务费, 和, 房款]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[v, uz, n, c, r, uj, n, c, n]</td>\n",
       "      <td>[和]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.514977</td>\n",
       "      <td>1.448768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923581</td>\n",
       "      <td>{大约, 佣金, 契税}</td>\n",
       "      <td>0.443351</td>\n",
       "      <td>8.748080</td>\n",
       "      <td>30.491407</td>\n",
       "      <td>0.443521</td>\n",
       "      <td>1.142209e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>你们的佣金费大约是多少和契税是多少。</td>\n",
       "      <td>3</td>\n",
       "      <td>好的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]</td>\n",
       "      <td>[好, 的]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[a, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.263268</td>\n",
       "      <td>2.675451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{大约, 佣金, 契税}</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>8.677430</td>\n",
       "      <td>25.828073</td>\n",
       "      <td>0.451183</td>\n",
       "      <td>3.532106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>你们的佣金费大约是多少和契税是多少。</td>\n",
       "      <td>4</td>\n",
       "      <td>链家天鸿美域店NAME，电话是PHONE（同微信号），随时联系?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]</td>\n",
       "      <td>[链家, 天鸿美域, 店, NAME, ，, 电话, 是, PHONE, （, 同微, 信号...</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[n, nr, ns, n, eng, x, n, v, eng, x, d, n, x, ...</td>\n",
       "      <td>[是]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864473</td>\n",
       "      <td>{大约, 佣金, 契税}</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>12.927756</td>\n",
       "      <td>28.974901</td>\n",
       "      <td>0.167511</td>\n",
       "      <td>1.158997e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>靠近川沙路嘛？</td>\n",
       "      <td>0</td>\n",
       "      <td>正常银行贷款，可以自己还的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[靠近, 川沙, 路, 嘛, ？]</td>\n",
       "      <td>[正常, 银行贷款, ，, 可以, 自己, 还, 的]</td>\n",
       "      <td>[v, ns, n, y, x]</td>\n",
       "      <td>[d, n, x, c, r, d, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.304637</td>\n",
       "      <td>2.081506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998044</td>\n",
       "      <td>{靠近, 川沙}</td>\n",
       "      <td>0.399596</td>\n",
       "      <td>7.959680</td>\n",
       "      <td>6.335780</td>\n",
       "      <td>0.399047</td>\n",
       "      <td>5.580720e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>靠近川沙路嘛？</td>\n",
       "      <td>1</td>\n",
       "      <td>有一点靠近川沙路</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[靠近, 川沙, 路, 嘛, ？]</td>\n",
       "      <td>[有, 一点, 靠近, 川沙, 路]</td>\n",
       "      <td>[v, ns, n, y, x]</td>\n",
       "      <td>[v, m, v, ns, n]</td>\n",
       "      <td>[靠近, 川沙, 路]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.609273</td>\n",
       "      <td>4.165221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{靠近, 川沙}</td>\n",
       "      <td>0.633462</td>\n",
       "      <td>10.497736</td>\n",
       "      <td>13.216286</td>\n",
       "      <td>0.632798</td>\n",
       "      <td>5.739747e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>靠近川沙路嘛？</td>\n",
       "      <td>2</td>\n",
       "      <td>只有那一套毛坯的不靠近川沙路</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[靠近, 川沙, 路, 嘛, ？]</td>\n",
       "      <td>[只有, 那, 一套, 毛坯, 的, 不, 靠近, 川沙, 路]</td>\n",
       "      <td>[v, ns, n, y, x]</td>\n",
       "      <td>[c, r, m, n, uj, a, v, ns, n]</td>\n",
       "      <td>[靠近, 川沙, 路]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.687419</td>\n",
       "      <td>2.967627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.890709</td>\n",
       "      <td>{靠近, 川沙}</td>\n",
       "      <td>0.270723</td>\n",
       "      <td>10.317979</td>\n",
       "      <td>6.199821</td>\n",
       "      <td>0.270414</td>\n",
       "      <td>1.561286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>这套房源价格还有优惠空间吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>有</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[这, 套房, 源, 价格, 还有, 优惠, 空间, 吗, ？]</td>\n",
       "      <td>[有]</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609121</td>\n",
       "      <td>1.337969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994260</td>\n",
       "      <td>{价格, 优惠, 套房, 空间, 还有}</td>\n",
       "      <td>0.419433</td>\n",
       "      <td>8.040307</td>\n",
       "      <td>24.576616</td>\n",
       "      <td>0.416502</td>\n",
       "      <td>4.217419e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>这套房源价格还有优惠空间吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>河西区海河沿线的新房，均价30000，带装修，看看去吗，优惠点位很大，五一特惠</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这, 套房, 源, 价格, 还有, 优惠, 空间, 吗, ？]</td>\n",
       "      <td>[河西区, 海河, 沿线, 的, 新房, ，, 均价, 30000, ，, 带, 装修, ，...</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[ns, ns, f, uj, n, x, n, m, x, v, v, x, v, v, ...</td>\n",
       "      <td>[优惠]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899475</td>\n",
       "      <td>0.778574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715349</td>\n",
       "      <td>{价格, 优惠, 套房, 空间, 还有}</td>\n",
       "      <td>0.264608</td>\n",
       "      <td>6.754923</td>\n",
       "      <td>1.012900</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>2.011383e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>这套房源价格还有优惠空间吗？</td>\n",
       "      <td>2</td>\n",
       "      <td>宾水里，肿瘤医院地铁5-6号线旁，私产过五年唯一，3楼，南北通透偏独，业主着急卖，看房有钥匙</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这, 套房, 源, 价格, 还有, 优惠, 空间, 吗, ？]</td>\n",
       "      <td>[宾水里, ，, 肿瘤医院, 地铁, 5, -, 6, 号线, 旁, ，, 私产, 过, 五...</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[n, f, x, n, n, x, x, m, n, f, x, n, ug, t, b,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664154</td>\n",
       "      <td>0.664154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936278</td>\n",
       "      <td>{价格, 优惠, 套房, 空间, 还有}</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>9.966531</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.040875</td>\n",
       "      <td>1.540320e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>这个税多少钱</td>\n",
       "      <td>0</td>\n",
       "      <td>您看看这个</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这个, 税, 多少, 钱]</td>\n",
       "      <td>[您, 看看, 这个]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[zg, v, r]</td>\n",
       "      <td>[这个]</td>\n",
       "      <td>...</td>\n",
       "      <td>5.410445</td>\n",
       "      <td>5.410445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{多少}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>这个税多少钱</td>\n",
       "      <td>1</td>\n",
       "      <td>13楼，精装修的/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这个, 税, 多少, 钱]</td>\n",
       "      <td>[13, 楼, ，, 精装修, 的, /,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[m, n, x, l, uj, x, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>11.261620</td>\n",
       "      <td>11.261620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{多少}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>这个税多少钱</td>\n",
       "      <td>2</td>\n",
       "      <td>您现在方便吗</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这个, 税, 多少, 钱]</td>\n",
       "      <td>[您, 现在, 方便, 吗,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[zg, t, a, y, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.150388</td>\n",
       "      <td>2.563631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{多少}</td>\n",
       "      <td>0.103222</td>\n",
       "      <td>9.581085</td>\n",
       "      <td>4.513747</td>\n",
       "      <td>0.101286</td>\n",
       "      <td>7.985726e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>这个税多少钱</td>\n",
       "      <td>3</td>\n",
       "      <td>可以先线上带您看一下</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这个, 税, 多少, 钱]</td>\n",
       "      <td>[可以, 先线, 上, 带, 您, 看, 一下,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[c, n, f, v, r, v, m, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>11.954768</td>\n",
       "      <td>11.954768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{多少}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>这个税多少钱</td>\n",
       "      <td>4</td>\n",
       "      <td>您稍等一下，给您发链接您点进来就行</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这个, 税, 多少, 钱]</td>\n",
       "      <td>[您, 稍等一下, ，, 给, 您, 发, 链接, 您, 点, 进来, 就行,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[zg, l, x, p, r, v, n, r, q, v, d, v, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984923</td>\n",
       "      <td>2.933870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{多少}</td>\n",
       "      <td>0.669373</td>\n",
       "      <td>4.903178</td>\n",
       "      <td>21.826728</td>\n",
       "      <td>0.670483</td>\n",
       "      <td>6.181808e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>这套房源价格还有优惠空间么？</td>\n",
       "      <td>0</td>\n",
       "      <td>价格周期可谈</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[这, 套房, 源, 价格, 还有, 优惠, 空间, 么, ？]</td>\n",
       "      <td>[价格, 周期, 可谈]</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[n, t, v]</td>\n",
       "      <td>[价格]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.494346</td>\n",
       "      <td>1.212245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.709042</td>\n",
       "      <td>{价格, 优惠, 套房, 空间, 还有}</td>\n",
       "      <td>0.364859</td>\n",
       "      <td>8.025300</td>\n",
       "      <td>18.749713</td>\n",
       "      <td>0.361521</td>\n",
       "      <td>4.323876e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>这套房源价格还有优惠空间么？</td>\n",
       "      <td>1</td>\n",
       "      <td>您好</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这, 套房, 源, 价格, 还有, 优惠, 空间, 么, ？]</td>\n",
       "      <td>[您好]</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[l]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455032</td>\n",
       "      <td>1.306770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>{价格, 优惠, 套房, 空间, 还有}</td>\n",
       "      <td>0.299576</td>\n",
       "      <td>10.032229</td>\n",
       "      <td>18.581886</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>1.127904e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>这套房源价格还有优惠空间么？</td>\n",
       "      <td>2</td>\n",
       "      <td>您好，您之前咨询的房源户型很优质，您有时间去看看吗？</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[这, 套房, 源, 价格, 还有, 优惠, 空间, 么, ？]</td>\n",
       "      <td>[您好, ，, 您, 之前, 咨询, 的, 房源, 户型, 很, 优质, ，, 您, 有, ...</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[l, x, zg, f, vn, uj, n, n, zg, n, x, r, v, n,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722294</td>\n",
       "      <td>0.691560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>{价格, 优惠, 套房, 空间, 还有}</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>11.781522</td>\n",
       "      <td>45.625881</td>\n",
       "      <td>0.374266</td>\n",
       "      <td>1.298957e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>有房子可以带我看看吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>宾至路有套82平方的</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[有, 房子, 可以, 带, 我, 看看, 吗, ？]</td>\n",
       "      <td>[宾至路, 有, 套, 82, 平方, 的]</td>\n",
       "      <td>[v, n, c, v, r, v, y, x]</td>\n",
       "      <td>[nr, v, q, m, q, uj]</td>\n",
       "      <td>[有]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.157952</td>\n",
       "      <td>2.931587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{房子, 看看}</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>8.254086</td>\n",
       "      <td>12.487435</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>5.332867e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>有房子可以带我看看吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>笋盘</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[有, 房子, 可以, 带, 我, 看看, 吗, ？]</td>\n",
       "      <td>[笋盘]</td>\n",
       "      <td>[v, n, c, v, r, v, y, x]</td>\n",
       "      <td>[n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984923</td>\n",
       "      <td>2.631235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{房子, 看看}</td>\n",
       "      <td>0.164922</td>\n",
       "      <td>7.227518</td>\n",
       "      <td>4.869229</td>\n",
       "      <td>0.158570</td>\n",
       "      <td>1.033444e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>有房子可以带我看看吗？</td>\n",
       "      <td>2</td>\n",
       "      <td>可以带您看一下</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[有, 房子, 可以, 带, 我, 看看, 吗, ？]</td>\n",
       "      <td>[可以, 带, 您, 看, 一下]</td>\n",
       "      <td>[v, n, c, v, r, v, y, x]</td>\n",
       "      <td>[c, v, r, v, m]</td>\n",
       "      <td>[带, 可以]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.157952</td>\n",
       "      <td>2.931587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{房子, 看看}</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>8.254086</td>\n",
       "      <td>12.487435</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>5.332867e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>光线不好，是吗</td>\n",
       "      <td>0</td>\n",
       "      <td>光线非常好，友联花园都是可以</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[光线, 不好, ，, 是, 吗]</td>\n",
       "      <td>[光线, 非常, 好, ，, 友联, 花园, 都, 是, 可以]</td>\n",
       "      <td>[n, d, x, v, y]</td>\n",
       "      <td>[n, d, a, x, ns, n, d, v, c]</td>\n",
       "      <td>[光线, 是]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.549591</td>\n",
       "      <td>2.027951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968942</td>\n",
       "      <td>{光线, 不好}</td>\n",
       "      <td>0.264109</td>\n",
       "      <td>10.832539</td>\n",
       "      <td>5.235958</td>\n",
       "      <td>0.265234</td>\n",
       "      <td>1.719930e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>光线不好，是吗</td>\n",
       "      <td>1</td>\n",
       "      <td>你点开图片，逐一看看</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[光线, 不好, ，, 是, 吗]</td>\n",
       "      <td>[你, 点开, 图片, ，, 逐一, 看看]</td>\n",
       "      <td>[n, d, x, v, y]</td>\n",
       "      <td>[r, q, v, n, x, d, v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.742658</td>\n",
       "      <td>1.515771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998585</td>\n",
       "      <td>{光线, 不好}</td>\n",
       "      <td>0.235205</td>\n",
       "      <td>9.215364</td>\n",
       "      <td>8.099103</td>\n",
       "      <td>0.234985</td>\n",
       "      <td>2.627015e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>光线不好，是吗</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[光线, 不好, ，, 是, 吗]</td>\n",
       "      <td>[?]</td>\n",
       "      <td>[n, d, x, v, y]</td>\n",
       "      <td>[x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.824387</td>\n",
       "      <td>3.329985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{光线, 不好}</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>13.357806</td>\n",
       "      <td>10.065587</td>\n",
       "      <td>0.096629</td>\n",
       "      <td>9.480238e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>几期的？</td>\n",
       "      <td>0</td>\n",
       "      <td>是的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[几期, 的, ？]</td>\n",
       "      <td>[是, 的]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[v, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>10.904945</td>\n",
       "      <td>10.904945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{几期}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9</td>\n",
       "      <td>几期的？</td>\n",
       "      <td>1</td>\n",
       "      <td>这个是二期的老师</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[几期, 的, ？]</td>\n",
       "      <td>[这个, 是, 二期, 的, 老师]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[r, v, b, uj, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.634982</td>\n",
       "      <td>2.866061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{几期}</td>\n",
       "      <td>0.163893</td>\n",
       "      <td>8.705774</td>\n",
       "      <td>8.883473</td>\n",
       "      <td>0.165021</td>\n",
       "      <td>3.949651e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9</td>\n",
       "      <td>几期的？</td>\n",
       "      <td>2</td>\n",
       "      <td>还有的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[几期, 的, ？]</td>\n",
       "      <td>[还有, 的]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[v, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>5.452473</td>\n",
       "      <td>3.733149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{几期}</td>\n",
       "      <td>-0.012560</td>\n",
       "      <td>9.763052</td>\n",
       "      <td>-0.586899</td>\n",
       "      <td>-0.011621</td>\n",
       "      <td>8.411273e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>几期的？</td>\n",
       "      <td>3</td>\n",
       "      <td>二期都刚下证今年</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[几期, 的, ？]</td>\n",
       "      <td>[二期, 都, 刚, 下证, 今年]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[b, d, d, v, t]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.988692</td>\n",
       "      <td>2.614658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771492</td>\n",
       "      <td>{几期}</td>\n",
       "      <td>0.268873</td>\n",
       "      <td>8.727287</td>\n",
       "      <td>12.534684</td>\n",
       "      <td>0.269065</td>\n",
       "      <td>1.042334e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>几期的？</td>\n",
       "      <td>4</td>\n",
       "      <td>一期的有免税的了</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[几期, 的, ？]</td>\n",
       "      <td>[一期, 的, 有, 免税, 的, 了]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[d, uj, v, v, uj, ul]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.634982</td>\n",
       "      <td>3.029338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.669574</td>\n",
       "      <td>{几期}</td>\n",
       "      <td>0.233220</td>\n",
       "      <td>7.210079</td>\n",
       "      <td>9.234592</td>\n",
       "      <td>0.232988</td>\n",
       "      <td>1.309377e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10</td>\n",
       "      <td>什么情况呢？</td>\n",
       "      <td>0</td>\n",
       "      <td>我们下班比较晚，现在也能看房</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[什么, 情况, 呢, ？]</td>\n",
       "      <td>[我们, 下班, 比较, 晚, ，, 现在, 也, 能, 看房]</td>\n",
       "      <td>[r, n, y, x]</td>\n",
       "      <td>[r, v, d, tg, x, t, d, v, v, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.087900</td>\n",
       "      <td>1.427551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996560</td>\n",
       "      <td>{情况}</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>9.733622</td>\n",
       "      <td>6.152428</td>\n",
       "      <td>0.133468</td>\n",
       "      <td>1.429926e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>什么情况呢？</td>\n",
       "      <td>1</td>\n",
       "      <td>哦</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[什么, 情况, 呢, ？]</td>\n",
       "      <td>[哦]</td>\n",
       "      <td>[r, n, y, x]</td>\n",
       "      <td>[zg]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.007240</td>\n",
       "      <td>4.007240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{情况}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cid                  d1  rid  \\\n",
       "0     0            采荷一小是分校吧    0   \n",
       "1     0            采荷一小是分校吧    1   \n",
       "2     0            采荷一小是分校吧    2   \n",
       "3     1                毛坯吗？    0   \n",
       "4     1                毛坯吗？    1   \n",
       "5     1                毛坯吗？    2   \n",
       "6     1                毛坯吗？    3   \n",
       "7     1                毛坯吗？    4   \n",
       "8     2  你们的佣金费大约是多少和契税是多少。    0   \n",
       "9     2  你们的佣金费大约是多少和契税是多少。    1   \n",
       "10    2  你们的佣金费大约是多少和契税是多少。    2   \n",
       "11    2  你们的佣金费大约是多少和契税是多少。    3   \n",
       "12    2  你们的佣金费大约是多少和契税是多少。    4   \n",
       "13    3             靠近川沙路嘛？    0   \n",
       "14    3             靠近川沙路嘛？    1   \n",
       "15    3             靠近川沙路嘛？    2   \n",
       "16    4      这套房源价格还有优惠空间吗？    0   \n",
       "17    4      这套房源价格还有优惠空间吗？    1   \n",
       "18    4      这套房源价格还有优惠空间吗？    2   \n",
       "19    5              这个税多少钱    0   \n",
       "20    5              这个税多少钱    1   \n",
       "21    5              这个税多少钱    2   \n",
       "22    5              这个税多少钱    3   \n",
       "23    5              这个税多少钱    4   \n",
       "24    6      这套房源价格还有优惠空间么？    0   \n",
       "25    6      这套房源价格还有优惠空间么？    1   \n",
       "26    6      这套房源价格还有优惠空间么？    2   \n",
       "27    7         有房子可以带我看看吗？    0   \n",
       "28    7         有房子可以带我看看吗？    1   \n",
       "29    7         有房子可以带我看看吗？    2   \n",
       "30    8             光线不好，是吗    0   \n",
       "31    8             光线不好，是吗    1   \n",
       "32    8             光线不好，是吗    2   \n",
       "33    9                几期的？    0   \n",
       "34    9                几期的？    1   \n",
       "35    9                几期的？    2   \n",
       "36    9                几期的？    3   \n",
       "37    9                几期的？    4   \n",
       "38   10              什么情况呢？    0   \n",
       "39   10              什么情况呢？    1   \n",
       "\n",
       "                                                d2  label  \\\n",
       "0                      杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。    1.0   \n",
       "1                                               是的    0.0   \n",
       "2                                             这是5楼    0.0   \n",
       "3                                       因为公积金贷款贷的少    0.0   \n",
       "4                                               是呢    0.0   \n",
       "5                                      这套一楼带院的，您看看    0.0   \n",
       "6                                         房本都是五年外的    0.0   \n",
       "7                                        好的??，您先看下    0.0   \n",
       "8                                       您是首套还是二套呢？    0.0   \n",
       "9                                       所有费用下来654万    1.0   \n",
       "10                                 包含着税费和我们的服务费和房款    1.0   \n",
       "11                                              好的    0.0   \n",
       "12                链家天鸿美域店NAME，电话是PHONE（同微信号），随时联系?    0.0   \n",
       "13                                   正常银行贷款，可以自己还的    0.0   \n",
       "14                                        有一点靠近川沙路    1.0   \n",
       "15                                  只有那一套毛坯的不靠近川沙路    0.0   \n",
       "16                                               有    1.0   \n",
       "17         河西区海河沿线的新房，均价30000，带装修，看看去吗，优惠点位很大，五一特惠    0.0   \n",
       "18  宾水里，肿瘤医院地铁5-6号线旁，私产过五年唯一，3楼，南北通透偏独，业主着急卖，看房有钥匙    0.0   \n",
       "19                                           您看看这个    0.0   \n",
       "20                                      13楼，精装修的/     0.0   \n",
       "21                                         您现在方便吗     0.0   \n",
       "22                                     可以先线上带您看一下     0.0   \n",
       "23                              您稍等一下，给您发链接您点进来就行     0.0   \n",
       "24                                          价格周期可谈    1.0   \n",
       "25                                              您好    0.0   \n",
       "26                      您好，您之前咨询的房源户型很优质，您有时间去看看吗？    0.0   \n",
       "27                                      宾至路有套82平方的    1.0   \n",
       "28                                              笋盘    1.0   \n",
       "29                                         可以带您看一下    1.0   \n",
       "30                                  光线非常好，友联花园都是可以    1.0   \n",
       "31                                      你点开图片，逐一看看    0.0   \n",
       "32                                               ?    0.0   \n",
       "33                                              是的    0.0   \n",
       "34                                        这个是二期的老师    1.0   \n",
       "35                                             还有的    0.0   \n",
       "36                                        二期都刚下证今年    0.0   \n",
       "37                                        一期的有免税的了    0.0   \n",
       "38                                  我们下班比较晚，现在也能看房    0.0   \n",
       "39                                               哦    0.0   \n",
       "\n",
       "                                   d1_word_cut  \\\n",
       "0                           [采荷, 一小, 是, 分校, 吧]   \n",
       "1                           [采荷, 一小, 是, 分校, 吧]   \n",
       "2                           [采荷, 一小, 是, 分校, 吧]   \n",
       "3                                   [毛坯, 吗, ？]   \n",
       "4                                   [毛坯, 吗, ？]   \n",
       "5                                   [毛坯, 吗, ？]   \n",
       "6                                   [毛坯, 吗, ？]   \n",
       "7                                   [毛坯, 吗, ？]   \n",
       "8   [你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]   \n",
       "9   [你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]   \n",
       "10  [你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]   \n",
       "11  [你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]   \n",
       "12  [你们, 的, 佣金, 费, 大约, 是, 多少, 和, 契税, 是, 多少, 。]   \n",
       "13                           [靠近, 川沙, 路, 嘛, ？]   \n",
       "14                           [靠近, 川沙, 路, 嘛, ？]   \n",
       "15                           [靠近, 川沙, 路, 嘛, ？]   \n",
       "16            [这, 套房, 源, 价格, 还有, 优惠, 空间, 吗, ？]   \n",
       "17            [这, 套房, 源, 价格, 还有, 优惠, 空间, 吗, ？]   \n",
       "18            [这, 套房, 源, 价格, 还有, 优惠, 空间, 吗, ？]   \n",
       "19                              [这个, 税, 多少, 钱]   \n",
       "20                              [这个, 税, 多少, 钱]   \n",
       "21                              [这个, 税, 多少, 钱]   \n",
       "22                              [这个, 税, 多少, 钱]   \n",
       "23                              [这个, 税, 多少, 钱]   \n",
       "24            [这, 套房, 源, 价格, 还有, 优惠, 空间, 么, ？]   \n",
       "25            [这, 套房, 源, 价格, 还有, 优惠, 空间, 么, ？]   \n",
       "26            [这, 套房, 源, 价格, 还有, 优惠, 空间, 么, ？]   \n",
       "27                 [有, 房子, 可以, 带, 我, 看看, 吗, ？]   \n",
       "28                 [有, 房子, 可以, 带, 我, 看看, 吗, ？]   \n",
       "29                 [有, 房子, 可以, 带, 我, 看看, 吗, ？]   \n",
       "30                           [光线, 不好, ，, 是, 吗]   \n",
       "31                           [光线, 不好, ，, 是, 吗]   \n",
       "32                           [光线, 不好, ，, 是, 吗]   \n",
       "33                                  [几期, 的, ？]   \n",
       "34                                  [几期, 的, ？]   \n",
       "35                                  [几期, 的, ？]   \n",
       "36                                  [几期, 的, ？]   \n",
       "37                                  [几期, 的, ？]   \n",
       "38                              [什么, 情况, 呢, ？]   \n",
       "39                              [什么, 情况, 呢, ？]   \n",
       "\n",
       "                                          d2_word_cut  \\\n",
       "0   [杭州市, 采荷, 第一, 小学, 钱江苑, 校区, ，, 杭州市, 钱江, 新城, 实验学...   \n",
       "1                                              [是, 的]   \n",
       "2                                          [这是, 5, 楼]   \n",
       "3                              [因为, 公积金, 贷款, 贷, 的, 少]   \n",
       "4                                              [是, 呢]   \n",
       "5                           [这套, 一楼, 带院, 的, ，, 您, 看看]   \n",
       "6                                [房本, 都, 是, 五年, 外, 的]   \n",
       "7                         [好, 的, ?, ?, ，, 您, 先, 看, 下]   \n",
       "8                            [您, 是, 首套, 还是, 二套, 呢, ？]   \n",
       "9                                [所有, 费用, 下来, 654, 万]   \n",
       "10                  [包含, 着, 税费, 和, 我们, 的, 服务费, 和, 房款]   \n",
       "11                                             [好, 的]   \n",
       "12  [链家, 天鸿美域, 店, NAME, ，, 电话, 是, PHONE, （, 同微, 信号...   \n",
       "13                        [正常, 银行贷款, ，, 可以, 自己, 还, 的]   \n",
       "14                                 [有, 一点, 靠近, 川沙, 路]   \n",
       "15                   [只有, 那, 一套, 毛坯, 的, 不, 靠近, 川沙, 路]   \n",
       "16                                                [有]   \n",
       "17  [河西区, 海河, 沿线, 的, 新房, ，, 均价, 30000, ，, 带, 装修, ，...   \n",
       "18  [宾水里, ，, 肿瘤医院, 地铁, 5, -, 6, 号线, 旁, ，, 私产, 过, 五...   \n",
       "19                                        [您, 看看, 这个]   \n",
       "20                           [13, 楼, ，, 精装修, 的, /,  ]   \n",
       "21                                  [您, 现在, 方便, 吗,  ]   \n",
       "22                        [可以, 先线, 上, 带, 您, 看, 一下,  ]   \n",
       "23         [您, 稍等一下, ，, 给, 您, 发, 链接, 您, 点, 进来, 就行,  ]   \n",
       "24                                       [价格, 周期, 可谈]   \n",
       "25                                               [您好]   \n",
       "26  [您好, ，, 您, 之前, 咨询, 的, 房源, 户型, 很, 优质, ，, 您, 有, ...   \n",
       "27                             [宾至路, 有, 套, 82, 平方, 的]   \n",
       "28                                               [笋盘]   \n",
       "29                                  [可以, 带, 您, 看, 一下]   \n",
       "30                   [光线, 非常, 好, ，, 友联, 花园, 都, 是, 可以]   \n",
       "31                             [你, 点开, 图片, ，, 逐一, 看看]   \n",
       "32                                                [?]   \n",
       "33                                             [是, 的]   \n",
       "34                                 [这个, 是, 二期, 的, 老师]   \n",
       "35                                            [还有, 的]   \n",
       "36                                 [二期, 都, 刚, 下证, 今年]   \n",
       "37                               [一期, 的, 有, 免税, 的, 了]   \n",
       "38                   [我们, 下班, 比较, 晚, ，, 现在, 也, 能, 看房]   \n",
       "39                                                [哦]   \n",
       "\n",
       "                               d1_pos_tag  \\\n",
       "0                        [nr, d, v, n, y]   \n",
       "1                        [nr, d, v, n, y]   \n",
       "2                        [nr, d, v, n, y]   \n",
       "3                               [n, y, x]   \n",
       "4                               [n, y, x]   \n",
       "5                               [n, y, x]   \n",
       "6                               [n, y, x]   \n",
       "7                               [n, y, x]   \n",
       "8   [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "9   [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "10  [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "11  [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "12  [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "13                       [v, ns, n, y, x]   \n",
       "14                       [v, ns, n, y, x]   \n",
       "15                       [v, ns, n, y, x]   \n",
       "16          [r, n, ng, n, v, vn, n, y, x]   \n",
       "17          [r, n, ng, n, v, vn, n, y, x]   \n",
       "18          [r, n, ng, n, v, vn, n, y, x]   \n",
       "19                           [r, n, m, n]   \n",
       "20                           [r, n, m, n]   \n",
       "21                           [r, n, m, n]   \n",
       "22                           [r, n, m, n]   \n",
       "23                           [r, n, m, n]   \n",
       "24          [r, n, ng, n, v, vn, n, y, x]   \n",
       "25          [r, n, ng, n, v, vn, n, y, x]   \n",
       "26          [r, n, ng, n, v, vn, n, y, x]   \n",
       "27               [v, n, c, v, r, v, y, x]   \n",
       "28               [v, n, c, v, r, v, y, x]   \n",
       "29               [v, n, c, v, r, v, y, x]   \n",
       "30                        [n, d, x, v, y]   \n",
       "31                        [n, d, x, v, y]   \n",
       "32                        [n, d, x, v, y]   \n",
       "33                             [d, uj, x]   \n",
       "34                             [d, uj, x]   \n",
       "35                             [d, uj, x]   \n",
       "36                             [d, uj, x]   \n",
       "37                             [d, uj, x]   \n",
       "38                           [r, n, y, x]   \n",
       "39                           [r, n, y, x]   \n",
       "\n",
       "                                           d2_pos_tag shared_words  ...  \\\n",
       "0          [ns, nr, m, n, nr, n, x, ns, nr, ns, n, x]         [采荷]  ...   \n",
       "1                                             [v, uj]          [是]  ...   \n",
       "2                                        [r, v, m, n]           []  ...   \n",
       "3                                 [c, n, n, v, uj, n]           []  ...   \n",
       "4                                              [v, y]           []  ...   \n",
       "5                          [r, q, n, n, uj, x, zg, v]           []  ...   \n",
       "6                                 [n, d, v, t, f, uj]           []  ...   \n",
       "7                           [a, uj, x, x, x, r, d, v]           []  ...   \n",
       "8                               [r, v, m, c, m, y, x]          [是]  ...   \n",
       "9                                     [b, n, t, m, m]           []  ...   \n",
       "10                      [v, uz, n, c, r, uj, n, c, n]          [和]  ...   \n",
       "11                                            [a, uj]           []  ...   \n",
       "12  [n, nr, ns, n, eng, x, n, v, eng, x, d, n, x, ...          [是]  ...   \n",
       "13                             [d, n, x, c, r, d, uj]           []  ...   \n",
       "14                                   [v, m, v, ns, n]  [靠近, 川沙, 路]  ...   \n",
       "15                      [c, r, m, n, uj, a, v, ns, n]  [靠近, 川沙, 路]  ...   \n",
       "16                                                [v]           []  ...   \n",
       "17  [ns, ns, f, uj, n, x, n, m, x, v, v, x, v, v, ...         [优惠]  ...   \n",
       "18  [n, f, x, n, n, x, x, m, n, f, x, n, ug, t, b,...           []  ...   \n",
       "19                                         [zg, v, r]         [这个]  ...   \n",
       "20                             [m, n, x, l, uj, x, x]           []  ...   \n",
       "21                                   [zg, t, a, y, x]           []  ...   \n",
       "22                           [c, n, f, v, r, v, m, x]           []  ...   \n",
       "23           [zg, l, x, p, r, v, n, r, q, v, d, v, x]           []  ...   \n",
       "24                                          [n, t, v]         [价格]  ...   \n",
       "25                                                [l]           []  ...   \n",
       "26  [l, x, zg, f, vn, uj, n, n, zg, n, x, r, v, n,...           []  ...   \n",
       "27                               [nr, v, q, m, q, uj]          [有]  ...   \n",
       "28                                                [n]           []  ...   \n",
       "29                                    [c, v, r, v, m]      [带, 可以]  ...   \n",
       "30                       [n, d, a, x, ns, n, d, v, c]      [光线, 是]  ...   \n",
       "31                              [r, q, v, n, x, d, v]           []  ...   \n",
       "32                                                [x]           []  ...   \n",
       "33                                            [v, uj]           []  ...   \n",
       "34                                   [r, v, b, uj, n]           []  ...   \n",
       "35                                            [v, uj]           []  ...   \n",
       "36                                    [b, d, d, v, t]           []  ...   \n",
       "37                              [d, uj, v, v, uj, ul]           []  ...   \n",
       "38                    [r, v, d, tg, x, t, d, v, v, n]           []  ...   \n",
       "39                                               [zg]           []  ...   \n",
       "\n",
       "    max_tfidf_sim  mean_tfidf_sim  max_textrank_sim  mean_textrank_sim  \\\n",
       "0        2.316487        1.666371               1.0           0.667346   \n",
       "1        4.600099        4.244596               1.0           0.998063   \n",
       "2        4.600099        4.244596               1.0           0.998063   \n",
       "3        3.730876        2.803282               1.0           0.998063   \n",
       "4       11.192627       11.192627               0.0           0.000000   \n",
       "5        2.988692        2.705259               1.0           0.668145   \n",
       "6        3.984923        3.291877               1.0           0.668145   \n",
       "7        5.596314        5.580179               0.0           0.000000   \n",
       "8        3.263268        2.675451               1.0           0.668145   \n",
       "9        1.631634        1.358860               1.0           0.779548   \n",
       "10       1.514977        1.448768               1.0           0.923581   \n",
       "11       3.263268        2.675451               1.0           0.668145   \n",
       "12       0.996231        0.996231               1.0           0.864473   \n",
       "13       2.304637        2.081506               1.0           0.998044   \n",
       "14       4.609273        4.165221               1.0           0.998063   \n",
       "15       3.687419        2.967627               1.0           0.890709   \n",
       "16       1.609121        1.337969               1.0           0.994260   \n",
       "17       0.899475        0.778574               1.0           0.715349   \n",
       "18       0.664154        0.664154               1.0           0.936278   \n",
       "19       5.410445        5.410445               0.0           0.000000   \n",
       "20      11.261620       11.261620               0.0           0.000000   \n",
       "21       3.150388        2.563631               1.0           0.998063   \n",
       "22      11.954768       11.954768               0.0           0.000000   \n",
       "23       3.984923        2.933870               1.0           0.998063   \n",
       "24       1.494346        1.212245               1.0           0.709042   \n",
       "25       1.455032        1.306770               1.0           0.952318   \n",
       "26       0.722294        0.691560               1.0           0.984411   \n",
       "27       3.157952        2.931587               1.0           0.998063   \n",
       "28       3.984923        2.631235               1.0           0.668145   \n",
       "29       3.157952        2.931587               1.0           0.998063   \n",
       "30       2.549591        2.027951               1.0           0.968942   \n",
       "31       1.742658        1.515771               1.0           0.998585   \n",
       "32       3.824387        3.329985               1.0           0.998063   \n",
       "33      10.904945       10.904945               0.0           0.000000   \n",
       "34       3.634982        2.866061               1.0           0.998063   \n",
       "35       5.452473        3.733149               1.0           0.998063   \n",
       "36       2.988692        2.614658               1.0           0.771492   \n",
       "37       3.634982        3.029338               1.0           0.669574   \n",
       "38       2.087900        1.427551               1.0           0.996560   \n",
       "39       4.007240        4.007240               0.0           0.000000   \n",
       "\n",
       "            d1_key_words  ww_cosine  ww_euclidean  ww_inner_product  \\\n",
       "0               {一小, 分校}   0.721863      6.525649         35.439222   \n",
       "1               {一小, 分校}   0.814446      6.326831         72.129395   \n",
       "2               {一小, 分校}   0.814446      6.326831         72.129395   \n",
       "3                   {毛坯}   0.358034      9.279583         28.669621   \n",
       "4                   {毛坯}   0.000000      0.000000          0.000000   \n",
       "5                   {毛坯}   0.261414      8.436319          9.165813   \n",
       "6                   {毛坯}   0.188383     11.473662         14.102968   \n",
       "7                   {毛坯}   0.068315      9.121356          3.014279   \n",
       "8           {大约, 佣金, 契税}   0.450929      8.677430         25.828073   \n",
       "9           {大约, 佣金, 契税}   0.399413     10.100416         31.169064   \n",
       "10          {大约, 佣金, 契税}   0.443351      8.748080         30.491407   \n",
       "11          {大约, 佣金, 契税}   0.450929      8.677430         25.828073   \n",
       "12          {大约, 佣金, 契税}   0.169944     12.927756         28.974901   \n",
       "13              {靠近, 川沙}   0.399596      7.959680          6.335780   \n",
       "14              {靠近, 川沙}   0.633462     10.497736         13.216286   \n",
       "15              {靠近, 川沙}   0.270723     10.317979          6.199821   \n",
       "16  {价格, 优惠, 套房, 空间, 还有}   0.419433      8.040307         24.576616   \n",
       "17  {价格, 优惠, 套房, 空间, 还有}   0.264608      6.754923          1.012900   \n",
       "18  {价格, 优惠, 套房, 空间, 还有}   0.039830      9.966531          0.000573   \n",
       "19                  {多少}   0.000000      0.000000          0.000000   \n",
       "20                  {多少}   0.000000      0.000000          0.000000   \n",
       "21                  {多少}   0.103222      9.581085          4.513747   \n",
       "22                  {多少}   0.000000      0.000000          0.000000   \n",
       "23                  {多少}   0.669373      4.903178         21.826728   \n",
       "24  {价格, 优惠, 套房, 空间, 还有}   0.364859      8.025300         18.749713   \n",
       "25  {价格, 优惠, 套房, 空间, 还有}   0.299576     10.032229         18.581886   \n",
       "26  {价格, 优惠, 套房, 空间, 还有}   0.373016     11.781522         45.625881   \n",
       "27              {房子, 看看}   0.288784      8.254086         12.487435   \n",
       "28              {房子, 看看}   0.164922      7.227518          4.869229   \n",
       "29              {房子, 看看}   0.288784      8.254086         12.487435   \n",
       "30              {光线, 不好}   0.264109     10.832539          5.235958   \n",
       "31              {光线, 不好}   0.235205      9.215364          8.099103   \n",
       "32              {光线, 不好}   0.101477     13.357806         10.065587   \n",
       "33                  {几期}   0.000000      0.000000          0.000000   \n",
       "34                  {几期}   0.163893      8.705774          8.883473   \n",
       "35                  {几期}  -0.012560      9.763052         -0.586899   \n",
       "36                  {几期}   0.268873      8.727287         12.534684   \n",
       "37                  {几期}   0.233220      7.210079          9.234592   \n",
       "38                  {情况}   0.132563      9.733622          6.152428   \n",
       "39                  {情况}   0.000000      0.000000          0.000000   \n",
       "\n",
       "    ww_pearson_cor  ww_pearson_pvalue  \n",
       "0         0.721577       1.503320e-21  \n",
       "1         0.814207       2.414553e-72  \n",
       "2         0.814207       2.414553e-72  \n",
       "3         0.357980       1.464102e-02  \n",
       "4         0.000000       0.000000e+00  \n",
       "5         0.264155       2.499604e-01  \n",
       "6         0.188384       1.006249e-01  \n",
       "7         0.068243       2.386186e-01  \n",
       "8         0.451183       3.532106e-09  \n",
       "9         0.399436       4.351321e-02  \n",
       "10        0.443521       1.142209e-06  \n",
       "11        0.451183       3.532106e-09  \n",
       "12        0.167511       1.158997e-02  \n",
       "13        0.399047       5.580720e-05  \n",
       "14        0.632798       5.739747e-35  \n",
       "15        0.270414       1.561286e-01  \n",
       "16        0.416502       4.217419e-05  \n",
       "17        0.265200       2.011383e-01  \n",
       "18        0.040875       1.540320e-01  \n",
       "19        0.000000       0.000000e+00  \n",
       "20        0.000000       0.000000e+00  \n",
       "21        0.101286       7.985726e-02  \n",
       "22        0.000000       0.000000e+00  \n",
       "23        0.670483       6.181808e-31  \n",
       "24        0.361521       4.323876e-05  \n",
       "25        0.297019       1.127904e-01  \n",
       "26        0.374266       1.298957e-02  \n",
       "27        0.284657       5.332867e-07  \n",
       "28        0.158570       1.033444e-01  \n",
       "29        0.284657       5.332867e-07  \n",
       "30        0.265234       1.719930e-01  \n",
       "31        0.234985       2.627015e-02  \n",
       "32        0.096629       9.480238e-02  \n",
       "33        0.000000       0.000000e+00  \n",
       "34        0.165021       3.949651e-01  \n",
       "35       -0.011621       8.411273e-01  \n",
       "36        0.269065       1.042334e-01  \n",
       "37        0.232988       1.309377e-01  \n",
       "38        0.133468       1.429926e-01  \n",
       "39        0.000000       0.000000e+00  \n",
       "\n",
       "[40 rows x 114 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "X = [w2v.wv[_] for k in df_raw.d1_key_words for _ in k if _ != set() and _ in w2v.wv]\n",
    "kmeans = KMeans(n_clusters=20)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length: 17268\n",
      "Test data length: 4317\n",
      "[1]\tvalid_0's auc: 0.750424\tvalid_0's binary_logloss: 0.56407\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's auc: 0.757913\tvalid_0's binary_logloss: 0.558262\n",
      "[3]\tvalid_0's auc: 0.767214\tvalid_0's binary_logloss: 0.552647\n",
      "[4]\tvalid_0's auc: 0.76969\tvalid_0's binary_logloss: 0.5477\n",
      "[5]\tvalid_0's auc: 0.773798\tvalid_0's binary_logloss: 0.542925\n",
      "[6]\tvalid_0's auc: 0.78068\tvalid_0's binary_logloss: 0.53828\n",
      "[7]\tvalid_0's auc: 0.780022\tvalid_0's binary_logloss: 0.53426\n",
      "[8]\tvalid_0's auc: 0.781914\tvalid_0's binary_logloss: 0.530246\n",
      "[9]\tvalid_0's auc: 0.782775\tvalid_0's binary_logloss: 0.52656\n",
      "[10]\tvalid_0's auc: 0.782727\tvalid_0's binary_logloss: 0.523058\n",
      "[11]\tvalid_0's auc: 0.782382\tvalid_0's binary_logloss: 0.519847\n",
      "[12]\tvalid_0's auc: 0.782734\tvalid_0's binary_logloss: 0.516732\n",
      "[13]\tvalid_0's auc: 0.782552\tvalid_0's binary_logloss: 0.513861\n",
      "[14]\tvalid_0's auc: 0.783923\tvalid_0's binary_logloss: 0.510812\n",
      "[15]\tvalid_0's auc: 0.78519\tvalid_0's binary_logloss: 0.508299\n",
      "[16]\tvalid_0's auc: 0.786882\tvalid_0's binary_logloss: 0.505492\n",
      "[17]\tvalid_0's auc: 0.787565\tvalid_0's binary_logloss: 0.502937\n",
      "[18]\tvalid_0's auc: 0.788135\tvalid_0's binary_logloss: 0.500718\n",
      "[19]\tvalid_0's auc: 0.78842\tvalid_0's binary_logloss: 0.498417\n",
      "[20]\tvalid_0's auc: 0.788669\tvalid_0's binary_logloss: 0.496321\n",
      "[21]\tvalid_0's auc: 0.788518\tvalid_0's binary_logloss: 0.494299\n",
      "[22]\tvalid_0's auc: 0.79017\tvalid_0's binary_logloss: 0.492146\n",
      "[23]\tvalid_0's auc: 0.790476\tvalid_0's binary_logloss: 0.49037\n",
      "[24]\tvalid_0's auc: 0.791079\tvalid_0's binary_logloss: 0.488741\n",
      "[25]\tvalid_0's auc: 0.791739\tvalid_0's binary_logloss: 0.486928\n",
      "[26]\tvalid_0's auc: 0.791656\tvalid_0's binary_logloss: 0.48553\n",
      "[27]\tvalid_0's auc: 0.793154\tvalid_0's binary_logloss: 0.483519\n",
      "[28]\tvalid_0's auc: 0.794234\tvalid_0's binary_logloss: 0.481799\n",
      "[29]\tvalid_0's auc: 0.794532\tvalid_0's binary_logloss: 0.480438\n",
      "[30]\tvalid_0's auc: 0.795244\tvalid_0's binary_logloss: 0.478931\n",
      "[31]\tvalid_0's auc: 0.795353\tvalid_0's binary_logloss: 0.477548\n",
      "[32]\tvalid_0's auc: 0.795103\tvalid_0's binary_logloss: 0.476401\n",
      "[33]\tvalid_0's auc: 0.795409\tvalid_0's binary_logloss: 0.475169\n",
      "[34]\tvalid_0's auc: 0.796214\tvalid_0's binary_logloss: 0.473857\n",
      "[35]\tvalid_0's auc: 0.797287\tvalid_0's binary_logloss: 0.472549\n",
      "[36]\tvalid_0's auc: 0.798169\tvalid_0's binary_logloss: 0.471304\n",
      "[37]\tvalid_0's auc: 0.798756\tvalid_0's binary_logloss: 0.470093\n",
      "[38]\tvalid_0's auc: 0.79913\tvalid_0's binary_logloss: 0.468919\n",
      "[39]\tvalid_0's auc: 0.799119\tvalid_0's binary_logloss: 0.467975\n",
      "[40]\tvalid_0's auc: 0.799663\tvalid_0's binary_logloss: 0.466934\n",
      "[41]\tvalid_0's auc: 0.800009\tvalid_0's binary_logloss: 0.466028\n",
      "[42]\tvalid_0's auc: 0.80041\tvalid_0's binary_logloss: 0.464989\n",
      "[43]\tvalid_0's auc: 0.800998\tvalid_0's binary_logloss: 0.463967\n",
      "[44]\tvalid_0's auc: 0.801182\tvalid_0's binary_logloss: 0.463202\n",
      "[45]\tvalid_0's auc: 0.801253\tvalid_0's binary_logloss: 0.462483\n",
      "[46]\tvalid_0's auc: 0.801567\tvalid_0's binary_logloss: 0.461658\n",
      "[47]\tvalid_0's auc: 0.802055\tvalid_0's binary_logloss: 0.460835\n",
      "[48]\tvalid_0's auc: 0.80207\tvalid_0's binary_logloss: 0.460067\n",
      "[49]\tvalid_0's auc: 0.802205\tvalid_0's binary_logloss: 0.459385\n",
      "[50]\tvalid_0's auc: 0.802943\tvalid_0's binary_logloss: 0.458522\n",
      "[51]\tvalid_0's auc: 0.803371\tvalid_0's binary_logloss: 0.457851\n",
      "[52]\tvalid_0's auc: 0.803535\tvalid_0's binary_logloss: 0.457327\n",
      "[53]\tvalid_0's auc: 0.804055\tvalid_0's binary_logloss: 0.456516\n",
      "[54]\tvalid_0's auc: 0.804181\tvalid_0's binary_logloss: 0.455973\n",
      "[55]\tvalid_0's auc: 0.804426\tvalid_0's binary_logloss: 0.455332\n",
      "[56]\tvalid_0's auc: 0.804875\tvalid_0's binary_logloss: 0.454606\n",
      "[57]\tvalid_0's auc: 0.804846\tvalid_0's binary_logloss: 0.454102\n",
      "[58]\tvalid_0's auc: 0.805214\tvalid_0's binary_logloss: 0.453497\n",
      "[59]\tvalid_0's auc: 0.805464\tvalid_0's binary_logloss: 0.452937\n",
      "[60]\tvalid_0's auc: 0.806023\tvalid_0's binary_logloss: 0.452293\n",
      "[61]\tvalid_0's auc: 0.806411\tvalid_0's binary_logloss: 0.4517\n",
      "[62]\tvalid_0's auc: 0.806519\tvalid_0's binary_logloss: 0.451268\n",
      "[63]\tvalid_0's auc: 0.806657\tvalid_0's binary_logloss: 0.450835\n",
      "[64]\tvalid_0's auc: 0.806926\tvalid_0's binary_logloss: 0.450377\n",
      "[65]\tvalid_0's auc: 0.807279\tvalid_0's binary_logloss: 0.449865\n",
      "[66]\tvalid_0's auc: 0.807301\tvalid_0's binary_logloss: 0.449434\n",
      "[67]\tvalid_0's auc: 0.807424\tvalid_0's binary_logloss: 0.449082\n",
      "[68]\tvalid_0's auc: 0.807872\tvalid_0's binary_logloss: 0.448563\n",
      "[69]\tvalid_0's auc: 0.808396\tvalid_0's binary_logloss: 0.447976\n",
      "[70]\tvalid_0's auc: 0.808995\tvalid_0's binary_logloss: 0.447447\n",
      "[71]\tvalid_0's auc: 0.809588\tvalid_0's binary_logloss: 0.446837\n",
      "[72]\tvalid_0's auc: 0.80994\tvalid_0's binary_logloss: 0.446317\n",
      "[73]\tvalid_0's auc: 0.810555\tvalid_0's binary_logloss: 0.445664\n",
      "[74]\tvalid_0's auc: 0.810541\tvalid_0's binary_logloss: 0.445354\n",
      "[75]\tvalid_0's auc: 0.810717\tvalid_0's binary_logloss: 0.445042\n",
      "[76]\tvalid_0's auc: 0.81105\tvalid_0's binary_logloss: 0.444603\n",
      "[77]\tvalid_0's auc: 0.811624\tvalid_0's binary_logloss: 0.444066\n",
      "[78]\tvalid_0's auc: 0.812125\tvalid_0's binary_logloss: 0.443593\n",
      "[79]\tvalid_0's auc: 0.812273\tvalid_0's binary_logloss: 0.443321\n",
      "[80]\tvalid_0's auc: 0.812485\tvalid_0's binary_logloss: 0.442925\n",
      "[81]\tvalid_0's auc: 0.81277\tvalid_0's binary_logloss: 0.442577\n",
      "[82]\tvalid_0's auc: 0.813168\tvalid_0's binary_logloss: 0.442079\n",
      "[83]\tvalid_0's auc: 0.813331\tvalid_0's binary_logloss: 0.441695\n",
      "[84]\tvalid_0's auc: 0.813381\tvalid_0's binary_logloss: 0.441412\n",
      "[85]\tvalid_0's auc: 0.813757\tvalid_0's binary_logloss: 0.440927\n",
      "[86]\tvalid_0's auc: 0.814276\tvalid_0's binary_logloss: 0.440443\n",
      "[87]\tvalid_0's auc: 0.814507\tvalid_0's binary_logloss: 0.440055\n",
      "[88]\tvalid_0's auc: 0.814861\tvalid_0's binary_logloss: 0.43963\n",
      "[89]\tvalid_0's auc: 0.815053\tvalid_0's binary_logloss: 0.439447\n",
      "[90]\tvalid_0's auc: 0.815281\tvalid_0's binary_logloss: 0.439149\n",
      "[91]\tvalid_0's auc: 0.815266\tvalid_0's binary_logloss: 0.439029\n",
      "[92]\tvalid_0's auc: 0.815439\tvalid_0's binary_logloss: 0.438782\n",
      "[93]\tvalid_0's auc: 0.815684\tvalid_0's binary_logloss: 0.438617\n",
      "[94]\tvalid_0's auc: 0.816159\tvalid_0's binary_logloss: 0.438201\n",
      "[95]\tvalid_0's auc: 0.816132\tvalid_0's binary_logloss: 0.438029\n",
      "[96]\tvalid_0's auc: 0.81644\tvalid_0's binary_logloss: 0.437686\n",
      "[97]\tvalid_0's auc: 0.816735\tvalid_0's binary_logloss: 0.437462\n",
      "[98]\tvalid_0's auc: 0.816779\tvalid_0's binary_logloss: 0.437304\n",
      "[99]\tvalid_0's auc: 0.817306\tvalid_0's binary_logloss: 0.436853\n",
      "[100]\tvalid_0's auc: 0.817481\tvalid_0's binary_logloss: 0.436564\n",
      "[101]\tvalid_0's auc: 0.817533\tvalid_0's binary_logloss: 0.436402\n",
      "[102]\tvalid_0's auc: 0.817746\tvalid_0's binary_logloss: 0.436175\n",
      "[103]\tvalid_0's auc: 0.81834\tvalid_0's binary_logloss: 0.435629\n",
      "[104]\tvalid_0's auc: 0.818661\tvalid_0's binary_logloss: 0.435239\n",
      "[105]\tvalid_0's auc: 0.818878\tvalid_0's binary_logloss: 0.434987\n",
      "[106]\tvalid_0's auc: 0.819102\tvalid_0's binary_logloss: 0.434737\n",
      "[107]\tvalid_0's auc: 0.819424\tvalid_0's binary_logloss: 0.434392\n",
      "[108]\tvalid_0's auc: 0.819502\tvalid_0's binary_logloss: 0.434181\n",
      "[109]\tvalid_0's auc: 0.819768\tvalid_0's binary_logloss: 0.433965\n",
      "[110]\tvalid_0's auc: 0.820138\tvalid_0's binary_logloss: 0.433557\n",
      "[111]\tvalid_0's auc: 0.820584\tvalid_0's binary_logloss: 0.433211\n",
      "[112]\tvalid_0's auc: 0.821013\tvalid_0's binary_logloss: 0.432846\n",
      "[113]\tvalid_0's auc: 0.821358\tvalid_0's binary_logloss: 0.432522\n",
      "[114]\tvalid_0's auc: 0.821641\tvalid_0's binary_logloss: 0.432297\n",
      "[115]\tvalid_0's auc: 0.821746\tvalid_0's binary_logloss: 0.43207\n",
      "[116]\tvalid_0's auc: 0.821878\tvalid_0's binary_logloss: 0.431929\n",
      "[117]\tvalid_0's auc: 0.821959\tvalid_0's binary_logloss: 0.431823\n",
      "[118]\tvalid_0's auc: 0.822171\tvalid_0's binary_logloss: 0.431603\n",
      "[119]\tvalid_0's auc: 0.822351\tvalid_0's binary_logloss: 0.431355\n",
      "[120]\tvalid_0's auc: 0.822342\tvalid_0's binary_logloss: 0.43119\n",
      "[121]\tvalid_0's auc: 0.822839\tvalid_0's binary_logloss: 0.430833\n",
      "[122]\tvalid_0's auc: 0.823029\tvalid_0's binary_logloss: 0.430654\n",
      "[123]\tvalid_0's auc: 0.823107\tvalid_0's binary_logloss: 0.430475\n",
      "[124]\tvalid_0's auc: 0.82316\tvalid_0's binary_logloss: 0.430367\n",
      "[125]\tvalid_0's auc: 0.8231\tvalid_0's binary_logloss: 0.430351\n",
      "[126]\tvalid_0's auc: 0.823435\tvalid_0's binary_logloss: 0.43007\n",
      "[127]\tvalid_0's auc: 0.82342\tvalid_0's binary_logloss: 0.430018\n",
      "[128]\tvalid_0's auc: 0.823524\tvalid_0's binary_logloss: 0.429977\n",
      "[129]\tvalid_0's auc: 0.823683\tvalid_0's binary_logloss: 0.429879\n",
      "[130]\tvalid_0's auc: 0.823847\tvalid_0's binary_logloss: 0.429733\n",
      "[131]\tvalid_0's auc: 0.824069\tvalid_0's binary_logloss: 0.429536\n",
      "[132]\tvalid_0's auc: 0.824298\tvalid_0's binary_logloss: 0.429286\n",
      "[133]\tvalid_0's auc: 0.824502\tvalid_0's binary_logloss: 0.429112\n",
      "[134]\tvalid_0's auc: 0.824722\tvalid_0's binary_logloss: 0.428909\n",
      "[135]\tvalid_0's auc: 0.824846\tvalid_0's binary_logloss: 0.428756\n",
      "[136]\tvalid_0's auc: 0.824786\tvalid_0's binary_logloss: 0.428736\n",
      "[137]\tvalid_0's auc: 0.824925\tvalid_0's binary_logloss: 0.428611\n",
      "[138]\tvalid_0's auc: 0.825092\tvalid_0's binary_logloss: 0.428444\n",
      "[139]\tvalid_0's auc: 0.825422\tvalid_0's binary_logloss: 0.428164\n",
      "[140]\tvalid_0's auc: 0.825594\tvalid_0's binary_logloss: 0.42795\n",
      "[141]\tvalid_0's auc: 0.825838\tvalid_0's binary_logloss: 0.427737\n",
      "[142]\tvalid_0's auc: 0.825925\tvalid_0's binary_logloss: 0.427688\n",
      "[143]\tvalid_0's auc: 0.82613\tvalid_0's binary_logloss: 0.427573\n",
      "[144]\tvalid_0's auc: 0.826314\tvalid_0's binary_logloss: 0.427364\n",
      "[145]\tvalid_0's auc: 0.826255\tvalid_0's binary_logloss: 0.427289\n",
      "[146]\tvalid_0's auc: 0.826288\tvalid_0's binary_logloss: 0.427262\n",
      "[147]\tvalid_0's auc: 0.826381\tvalid_0's binary_logloss: 0.427142\n",
      "[148]\tvalid_0's auc: 0.826236\tvalid_0's binary_logloss: 0.427148\n",
      "[149]\tvalid_0's auc: 0.826248\tvalid_0's binary_logloss: 0.427137\n",
      "[150]\tvalid_0's auc: 0.826374\tvalid_0's binary_logloss: 0.427014\n",
      "[151]\tvalid_0's auc: 0.826336\tvalid_0's binary_logloss: 0.426985\n",
      "[152]\tvalid_0's auc: 0.826462\tvalid_0's binary_logloss: 0.426832\n",
      "[153]\tvalid_0's auc: 0.82649\tvalid_0's binary_logloss: 0.426724\n",
      "[154]\tvalid_0's auc: 0.82661\tvalid_0's binary_logloss: 0.42661\n",
      "[155]\tvalid_0's auc: 0.826592\tvalid_0's binary_logloss: 0.426544\n",
      "[156]\tvalid_0's auc: 0.826631\tvalid_0's binary_logloss: 0.426488\n",
      "[157]\tvalid_0's auc: 0.826645\tvalid_0's binary_logloss: 0.426422\n",
      "[158]\tvalid_0's auc: 0.826762\tvalid_0's binary_logloss: 0.426341\n",
      "[159]\tvalid_0's auc: 0.826792\tvalid_0's binary_logloss: 0.426263\n",
      "[160]\tvalid_0's auc: 0.826929\tvalid_0's binary_logloss: 0.426121\n",
      "[161]\tvalid_0's auc: 0.82708\tvalid_0's binary_logloss: 0.426014\n",
      "[162]\tvalid_0's auc: 0.827225\tvalid_0's binary_logloss: 0.425812\n",
      "[163]\tvalid_0's auc: 0.827339\tvalid_0's binary_logloss: 0.425671\n",
      "[164]\tvalid_0's auc: 0.827322\tvalid_0's binary_logloss: 0.425663\n",
      "[165]\tvalid_0's auc: 0.827331\tvalid_0's binary_logloss: 0.4256\n",
      "[166]\tvalid_0's auc: 0.82737\tvalid_0's binary_logloss: 0.425574\n",
      "[167]\tvalid_0's auc: 0.827479\tvalid_0's binary_logloss: 0.425391\n",
      "[168]\tvalid_0's auc: 0.827534\tvalid_0's binary_logloss: 0.425293\n",
      "[169]\tvalid_0's auc: 0.827382\tvalid_0's binary_logloss: 0.42537\n",
      "[170]\tvalid_0's auc: 0.827321\tvalid_0's binary_logloss: 0.425376\n",
      "[171]\tvalid_0's auc: 0.827527\tvalid_0's binary_logloss: 0.425164\n",
      "[172]\tvalid_0's auc: 0.827483\tvalid_0's binary_logloss: 0.425105\n",
      "[173]\tvalid_0's auc: 0.827526\tvalid_0's binary_logloss: 0.425037\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.827534\tvalid_0's binary_logloss: 0.425293\n",
      "The f1 score of prediction is: 0.5334859759587864\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df_raw[:len(train_df)][features]\n",
    "target = df_raw[:len(train_df)]['label']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    "print(\"Train data length:\", len(X_train))\n",
    "print(\"Test data length:\", len(X_test))\n",
    "\n",
    "# 转换为Dataset数据格式\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# 参数\n",
    "params = {'num_leaves': 75, #结果对最终效果影响较大，越大值越好，太大会出现过拟合\n",
    "          'min_data_in_leaf': 30,\n",
    "          'objective': 'binary', #定义的目标函数\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.03,\n",
    "          \"min_sum_hessian_in_leaf\": 6,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"feature_fraction\": 0.9,#提取的特征比率\n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.8,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"lambda_l1\": 0.1,#l1正则\n",
    "          \"verbosity\": -1,\n",
    "          \"nthread\": -1,#线程数量，-1表示全部线程，线程越多，运行的速度越快\n",
    "          'metric': {'binary_logloss', 'auc', 'f1'},##评价函数选择\n",
    "          \"random_state\": 2019,#随机数种子，可以防止每次运行的结果不一致\n",
    "          # 'device': 'gpu' ##如果安装的事gpu版本的lightgbm,可以加快运算\n",
    "          }\n",
    "\n",
    "\n",
    "# 模型训练\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=500, valid_sets=lgb_eval, early_stopping_rounds=5)\n",
    "\n",
    "# 模型保存\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "# 模型加载\n",
    "gbm = lgb.Booster(model_file='model.txt')\n",
    "\n",
    "# 模型预测\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "y_pred = (y_pred>=0.5).astype(float)\n",
    "\n",
    "# 模型评估\n",
    "print('The f1 score of prediction is:', f1_score(y_test.values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp特征：包括主题模型、LDA、kmeans、词表示、句子表示、词向量的各种距离度量等等\n",
    "def train_lda(all_df,  n_topics=15):\n",
    "    ## 使用不包含停止词的分词结果\n",
    "    corpus = all_df['tokens']\n",
    "    cnt = CountVectorizer()\n",
    "    cntIf = cnt.fit_transform(corpus)\n",
    "\n",
    "    lda_path = os.path.join(model_path, 'lda.pkl')\n",
    "\n",
    "    ## 使用LDA主题模型进行分类\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=150)\n",
    "    print(\"正在训练LDA主题模型...\")\n",
    "    lda_pred = lda.fit_transform(cntIf)\n",
    "    lda_classes = np.argmax(lda_pred, axis=1)\n",
    "    ## 保存模型\n",
    "    with open(lda_path, 'wb') as f:\n",
    "        pickle.dump(lda, f)\n",
    "    print(\"LDA主题模型已保存...\")\n",
    "\n",
    "    return lda_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 康康关键词，大致判断有多少主题吧\n",
    "df_raw.to_csv(\"tmp.tsv\", sep='\\t', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaf1cda7d109dc4e3ba3b4252742f6d994"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
