{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>0</td>\n",
       "      <td>æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºï¼Œæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡ã€‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯çš„</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>2</td>\n",
       "      <td>è¿™æ˜¯5æ¥¼</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·çš„å°‘</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯å‘¢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid        d1  rid                           d2  label\n",
       "0    0  é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    0  æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºï¼Œæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡ã€‚      1\n",
       "1    0  é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    1                           æ˜¯çš„      0\n",
       "2    0  é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    2                         è¿™æ˜¯5æ¥¼      0\n",
       "3    1      æ¯›å¯å—ï¼Ÿ    0                   å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·çš„å°‘      0\n",
       "4    1      æ¯›å¯å—ï¼Ÿ    1                           æ˜¯å‘¢      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç‰¹å¾å·¥ç¨‹éƒ¨åˆ†ï¼Œå¤§è‡´æ€è·¯ä¸ºï¼šç»Ÿè®¡ç‰¹å¾ã€nlpç‰¹å¾å’Œå›¾ç‰¹å¾\n",
    "# é¦–å…ˆé€šè¿‡åšæ•°æ®é¢„å¤„ç†ï¼Œå°†æ•°æ®åˆ’åˆ†ä¸ºä¸‰ä¸ªç‰ˆæœ¬ï¼šåŸå§‹ç‰ˆæœ¬ã€å»æ‰åœç”¨è¯çš„ç‰ˆæœ¬ã€æ–‡æœ¬æ¸…æ´—çš„ç‰ˆæœ¬\n",
    "import pandas as pd\n",
    "\n",
    "train_query = pd.read_csv(\"./train/train.query.tsv\", sep=\"\\t\", header=None)\n",
    "train_reply = pd.read_csv(\"./train/train.reply.tsv\", sep=\"\\t\", header=None)\n",
    "test_query = pd.read_csv(\"./test/test.query.tsv\", sep=\"\\t\", header=None)\n",
    "test_reply = pd.read_csv(\"./test/test.reply.tsv\", sep=\"\\t\", header=None)\n",
    "train_query.columns = [\"cid\", \"d1\"]\n",
    "train_reply.columns = [\"cid\", \"rid\", \"d2\", \"label\"]\n",
    "train_df = pd.merge(train_query, train_reply, how=\"left\", on=\"cid\")\n",
    "test_query.columns = [\"cid\", \"d1\"]\n",
    "test_reply.columns = [\"cid\", \"rid\", \"d2\"]\n",
    "test_df = pd.merge(test_query, test_reply, how=\"left\", on=\"cid\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>604</td>\n",
       "      <td>æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cid                d1  rid   d2  label\n",
       "2194  604  æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡    3  NaN      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['d2'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>604</td>\n",
       "      <td>æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡</td>\n",
       "      <td>0</td>\n",
       "      <td>ä¸­å­¦é™„è¿‘æœ‰ä¸€åˆ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>604</td>\n",
       "      <td>æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡</td>\n",
       "      <td>1</td>\n",
       "      <td>ä¸€åˆæ˜¯é‡ç‚¹</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>604</td>\n",
       "      <td>æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡</td>\n",
       "      <td>2</td>\n",
       "      <td>æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°æ‚¨</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>604</td>\n",
       "      <td>æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡</td>\n",
       "      <td>3</td>\n",
       "      <td>å¥½çš„</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>604</td>\n",
       "      <td>æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡</td>\n",
       "      <td>4</td>\n",
       "      <td>ä¸€åˆåªèƒ½è€ƒ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cid                d1  rid        d2  label\n",
       "2191  604  æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡    0   ä¸­å­¦é™„è¿‘æœ‰ä¸€åˆ      1\n",
       "2192  604  æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡    1     ä¸€åˆæ˜¯é‡ç‚¹      1\n",
       "2193  604  æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡    2  æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°æ‚¨      0\n",
       "2194  604  æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡    3        å¥½çš„      0\n",
       "2195  604  æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªæˆ¿å­å‘¨è¾¹æœ‰å“ªäº›å­¦æ ¡    4     ä¸€åˆåªèƒ½è€ƒ      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['d2'] = train_df.d2.fillna(\"å¥½çš„\")\n",
    "train_df[train_df['cid'] == 604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆä¸åŒç‰ˆæœ¬çš„æ•°æ®\n",
    "\n",
    "# åŸå§‹ç‰ˆæœ¬\n",
    "df = pd.concat([train_df, test_df])\n",
    "df[['d1', 'd2']].to_csv(\"df_raw.tsv\", index = None, sep=' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»é™¤åœç”¨è¯ç‰ˆæœ¬\n",
    "\n",
    "# åŠ è½½åœç”¨è¯ï¼ˆæœ¬æ¥æƒ³è€ƒè™‘æƒ…æ„Ÿè¯çš„åœç”¨è¯ï¼Œä½†æ˜¯å‘ç°å¥½åƒç”¨ä¸åˆ°ï¼Œ\n",
    "# å¾ˆå¤šå¥å­ä½¿ç”¨åœç”¨è¯ä¹‹åå˜ä¸ºç©ºçš„äº†ï¼Œè¿™é‡Œåœç”¨äº†æ ‡ç‚¹ç¬¦å·å’Œæ„Ÿå¹è¯ï¼‰\n",
    "import string\n",
    "\n",
    "\n",
    "stopwords = [x for x in string.punctuation]\n",
    "with open(\"stopwords.txt\", encoding='utf-8') as fin:\n",
    "    for word in fin.readlines():\n",
    "        stopwords.append(word.strip())\n",
    "        \n",
    "def remove_sw(sen):\n",
    "    for w in stopwords:\n",
    "        sen = sen.replace(w, \"\")\n",
    "    return sen\n",
    "\n",
    "df_sw_removal = df.copy(deep=True)\n",
    "df_sw_removal['d1'] = df_sw_removal['d1'].apply(remove_sw)\n",
    "df_sw_removal['d2'] = df_sw_removal['d2'].apply(remove_sw)\n",
    "df_sw_removal.to_csv(\"df_rm_sw.tsv\", index = None, sep = '\\t',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ‰â‘¡ğŸ˜”ğŸ’°âŠ™ğŸ˜Šâˆšï½›ğŸ˜‚ğŸ˜†ã€âœªğŸ˜œâ…¤ËŠï¼²ï½–âˆ¨ã¡ï¼°Ã—ï½ğŸ˜…Ë‹ğŸ˜ğŸ˜³ğŸ‘ï½’ï¼‹ï¹‰ï¼†Î»â˜€ğŸ˜²ğŸ ã€‘ğŸ¾ï¸ï¼ƒğŸ˜–ğŸ”‘â•ğŸ˜ï¼¶Ï‰ğŸ˜«Ã¹ğŸ˜ŒğŸŠï¼·ï¼…ğŸ»ğŸ˜ƒğŸ˜“ğŸ˜â—ã¥ªğŸ˜˜ğŸ˜„ğŸ˜°ğŸ˜‹â†’ğŸˆ¶ï¿¼ğŸ˜ï½ï¼â“ğŸ‘Œâ–½'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ–‡æœ¬æ¸…æ´—è¿‡çš„æ•°æ®\n",
    "\n",
    "# æ•°æ®å¹¶æ²¡æœ‰å¾ˆè„ï¼Œåªä¸è¿‡æœ‰æ¯”è¾ƒå¤šçš„æ‰“é”™å­—çš„æƒ…å†µ\n",
    "# è¿˜æœ‰éƒ¨åˆ†æ‰“æˆæ‹¼éŸ³çš„æƒ…å†µ\n",
    "# çœ‹çœ‹æœ‰å“ªäº›ç‰¹æ®Šå­—ç¬¦\n",
    "import re\n",
    "\n",
    "def find_special_tokens(text):\n",
    "    # è¿‡æ»¤ä¸­æ–‡å­—ç¬¦\n",
    "    result = re.findall(u'[^\\u4e00-\\u9fa5]', text)\n",
    "    # è¿‡æ»¤è‹±æ–‡å­—ç¬¦\n",
    "    result = re.findall(r'[^a-zA-Z]', ''.join(result))\n",
    "    # è¿‡æ»¤æ•°å­—\n",
    "    result = re.findall(r'[^\\d]', ''.join(result))\n",
    "    # è¿‡æ»¤ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·\n",
    "    result = re.findall(r'[^ !\"#$%&\\'()*+,-./:;<=>?@\\[\\\\\\]^_`{}~Â·â€”â€˜â€œâ€â€¦ã€ã€‚ã€Šã€‹ï¼ï¼ˆï¼‰ï¼Œï¼šï¼›ï¼Ÿ]', ''.join(result))\n",
    "    return result\n",
    "\n",
    "def get_special_tokens():\n",
    "    special_tokens = []\n",
    "    sentences = []\n",
    "    for i, row in df.iterrows():\n",
    "        res = find_special_tokens(str(row.d1) + str(row.d2))\n",
    "        special_tokens += res\n",
    "        if res != []:\n",
    "            sentences.append((row, res))\n",
    "    return \"\".join(set(special_tokens)), sentences\n",
    "\n",
    "special_tokens, sentences = get_special_tokens()\n",
    "with open(\"special_tokens_sentence.txt\", 'w', encoding='utf-8') as fin:\n",
    "    for s in sentences:\n",
    "        fin.write(str(s[0].cid)+\"\\t\" + str(s[0].rid)+\"\\t\"+str(s[0].d1)+\"\\t\" + str(s[0].d2) + \"\\t\" + \" \".join(s[1])+\"\\n\")\n",
    "# å¥½å®¶ä¼™ï¼Œä»€ä¹ˆå¥‡å¥‡æ€ªæ€ªçš„ç¬¦å·éƒ½æœ‰ï¼Œç”šè‡³è¿˜æœ‰å…¨è§’çš„ï¼Œä¿å­˜åˆ°æ–‡ä»¶æ¨æµ‹è¿™äº›ç¬¦å·çš„å«ä¹‰ï¼Œç„¶åç”¨æ–‡å­—æ›¿æ¢\n",
    "special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…é™¤ç‰¹æ®Šç¬¦å·å’Œæ‰“æˆæ‹¼éŸ³çš„æ±‰å­—\n",
    "# é‡Œé¢æœ‰å…¨è§’çš„å­—ç¬¦ï¼Œå¥½åœ¨ä¸å¤šï¼Œå¯ä»¥ç©·ä¸¾å®Œ\n",
    "# ä¸»è¦å¯¹ç«‹é¢çš„ç‰¹æ®Šå­—ç¬¦è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä¾¿äºè®­ç»ƒ\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_special_tokens(text):\n",
    "    text = text.replace(\"ğŸ˜‚\", \"å“ˆå“ˆ\")\n",
    "    text = text.replace(\"ğŸ‘Œ\", \"å¥½\")\n",
    "    text = text.replace(\"ğŸ˜Š\", \"å¥½\")\n",
    "    text = text.replace(\"ğŸ˜“\", \"æ±—\")\n",
    "    text = text.replace(\"ğŸ˜\", \"å“ˆå“ˆ\")\n",
    "    text = text.replace(\"ğŸ‘ŒğŸ»\", \"å¥½\")\n",
    "    text = text.replace(\" ğŸ»\", \"\")\n",
    "    text = text.replace(\"Ã¹\", \"\")\n",
    "    text = text.replace(\"ğŸˆ¶ï¸\", \"æœ‰\")\n",
    "    text = text.replace(\"ğŸ”‘\", \"é’¥åŒ™\")\n",
    "    text = text.replace(\"â•\", \"åŠ \")\n",
    "    text = text.replace(\"ğŸ \", \"æˆ¿å­\")\n",
    "    text = text.replace(\"ğŸ‘\", \"å¯ä»¥\")\n",
    "    text = text.replace(\"ã¡\", \"å¹³ç±³\")\n",
    "    text = text.replace(\"ğŸ‰\", \"å¾—\")\n",
    "    text = text.replace(\"ï¼¶\", \"v\")\n",
    "    text = text.replace(\"ï¼²\", \"r\")\n",
    "    text = text.replace(\"â“\", \"ï¼Ÿ\")\n",
    "    text = text.replace(\"â˜€\", \"\")\n",
    "    text = text.replace(\"ï½–\", \"v\")\n",
    "    text = text.replace(\"ï½’\", \"r\")\n",
    "    text = text.replace(\"ã¥ª\", \"æ¥¼\")\n",
    "    text = text.replace(\"ï¿¼\", \"\")\n",
    "    text = text.replace(\"ï¼ƒ\", \"#\")\n",
    "    text = text.replace(\"âˆš\", \"å¯¹\")\n",
    "    text = text.replace(\"ï¼‹\", \"åŠ \")\n",
    "    text = text.replace(\"ï¹‰\", \"\")\n",
    "    text = text.replace(\"â‘¡\", \"äºŒ\")\n",
    "    text = text.replace(\"ï¼·\", \"ä¸‡\")\n",
    "    text = text.replace(\"Î»\", \"\")\n",
    "    text = text.replace(\"nh\", \"ä½ å¥½\")\n",
    "    text = text.replace(\"zaima\", \"åœ¨å—\")\n",
    "    text = text.replace(\"me\", \"ä¹ˆ\")\n",
    "    text = text.replace(\"ceng\", \"å±‚\")\n",
    "    text = text.replace(\"keyi\", \"å¯ä»¥\")\n",
    "    text = text.replace(\"taobao\", \"æ·˜å®\")\n",
    "    text = text.replace(\"VR\", \"vr\")\n",
    "    text = text.replace(\"vR\", \"vr\")\n",
    "    text = text.replace(\"Vr\", \"vr\")\n",
    "    text = text.replace(\"NAMEPHONE\", \"NAME / PHONE\")\n",
    "    text = text.replace(\"l\", \"\")\n",
    "    text = text.replace(\"keyitan\", \"å¯ä»¥è°ˆ\")\n",
    "    text = text.replace(\"be\", \"\")\n",
    "    text = text.replace(\"ve\", \"vr\")\n",
    "    text = text.replace(\"key\", \"å¯ä»¥\")\n",
    "    text = text.replace(\"laile\", \"æ¥äº†\")\n",
    "    text = text.replace(\"haole\", \"å¥½äº†\")\n",
    "    text = text.replace(\"shaodeng\", \"ç¨ç­‰\")\n",
    "    text = text.replace(\"ninha\", \"æ‚¨å¥½\")\n",
    "    text = text.replace(\"nihao\", \"æ‚¨å¥½\")\n",
    "    text = text.replace(\"ï¼°\", \"P\")\n",
    "    text = text.replace(\"wan\", \"ä¸‡\")\n",
    "    text = text.replace(\"DAU\", \"å¸¦\")\n",
    "    text = text.replace(\"lou\", \"æ¥¼\")\n",
    "    text = text.replace(\"kanfang\", \"çœ‹æˆ¿\")\n",
    "    text = text.replace(\"is\", \"\")\n",
    "    text = text.replace(\"shenm\", \"\")\n",
    "    text = text.replace(\"ï¼†\", \"&\")\n",
    "    text = text.replace(\"gaosunoi\", \"å‘Šè¯‰ä½ \")\n",
    "    text = text.replace(\"Va\", \"vr\")\n",
    "    text = text.replace(\"hao\", \"å¥½\")\n",
    "    text = text.replace(\"ma\", \"\")\n",
    "    text = text.replace(\"zengzhi\", \"å¢å€¼\")\n",
    "    # urlç›´æ¥æ¸…æ´—\n",
    "    html = re.compile(r'(https?://)([\\da-zA-Z=&\\?_\\.-]+)\\.([a-z=&\\?_\\.]{2,6})([/\\w =&\\?_\\.-]*)*/?')\n",
    "    text = re.sub(html, \"\", text)\n",
    "    return text\n",
    "\n",
    "df_cleaned = df.copy(deep=True)\n",
    "df_cleaned['d1'] = df_cleaned['d1'].apply(clean_special_tokens)\n",
    "df_cleaned['d2'] = df_cleaned['d2'].apply(clean_special_tokens)\n",
    "df_cleaned.to_csv(\"df_cleaned.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cleaned[:len(train_df)]\n",
    "test = df_cleaned[len(train_df):]\n",
    "unmatched = pd.read_csv(\"unmatched.tsv\", sep=\"\\t\")\n",
    "for i, row in unmatched.iterrows():\n",
    "    train.loc[int(row['id']), 'label'] = int(row['label'])\n",
    "train.to_csv(\"train.tsv\", sep='\\t', index=None)\n",
    "test.to_csv(\"test.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ç”ŸæˆæŸä¸ªå¥å­çš„n-gram\n",
    "def n_gram(x, n=2):\n",
    "    if len(x) <= (n-1):\n",
    "        return x\n",
    "    result = []\n",
    "    # zipå‡½æ•°åœ¨è¾¾åˆ°æœ€çŸ­é•¿åº¦æ—¶å°±åœæ­¢è¿­ä»£\n",
    "    n_grams = set(zip(*[x[i:] for i in range(n)]))\n",
    "    for n_gram in n_grams:\n",
    "        result.append(\"\".join(n_gram))\n",
    "    return result\n",
    "\n",
    "df_cleaned['d1_unigram'] = df_cleaned['d1'].apply(lambda x: list(str(x)))\n",
    "df_cleaned['d2_unigram'] = df_cleaned['d2'].apply(lambda x: list(str(x)))\n",
    "df_cleaned['d1_bigrams'] = df_cleaned['d1'].apply(lambda x: n_gram(list(str(x))))\n",
    "df_cleaned['d2_bigrams'] = df_cleaned['d2'].apply(lambda x: n_gram(list(str(x))))\n",
    "df_cleaned['shared_words_unigram'] = df_cleaned.apply(\n",
    "    lambda x: set(x['d1_unigram']).intersection(set(x['d2_unigram'])),\n",
    "    axis = 1\n",
    ")\n",
    "df_cleaned['shared_words_bigrams'] = df_cleaned.apply(\n",
    "    lambda x: set(x['d1_bigrams']).intersection(set(x['d2_bigrams'])),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"df_share_words.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ä»¶æœ¬æ¥åº”è¯¥æ˜¯ï¼šä¸€å…ƒè¯­æ³•2ä¸ªå­—åŠä»¥ä¸Šï¼Œ äºŒå…ƒè¯­æ³•1ä¸ªè¯åŠä»¥ä¸Šï¼Œå°±ç®—ä½œæœ‰share words\n",
    "def add_feature(x):\n",
    "    special_unigram = 'æ˜¯èƒ½æœ‰å¯¹'\n",
    "    \n",
    "    unigram = x['shared_words_unigram']\n",
    "    bigram = x['shared_words_bigrams']\n",
    "    \n",
    "    if len(unigram) == 1:\n",
    "        for _ in special_unigram:\n",
    "            if _ in unigram:\n",
    "                return True\n",
    "        \n",
    "    if len(unigram) >= 2 and len(bigram) >= 1:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "df_cleaned['add_feature'] = df_cleaned.apply(lambda x: add_feature(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_cleaned.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "      <th>d1_unigram</th>\n",
       "      <th>d2_unigram</th>\n",
       "      <th>d1_bigrams</th>\n",
       "      <th>d2_bigrams</th>\n",
       "      <th>shared_words_unigram</th>\n",
       "      <th>shared_words_bigrams</th>\n",
       "      <th>add_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡</td>\n",
       "      <td>0</td>\n",
       "      <td>æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡</td>\n",
       "      <td>1</td>\n",
       "      <td>[é‡‡, è·, ä¸€, å°, æ˜¯, åˆ†, æ ¡]</td>\n",
       "      <td>[æ­, å·, å¸‚, é‡‡, è·, ç¬¬, ä¸€, å°, å­¦, é’±, æ±Ÿ, è‹‘, æ ¡, åŒº, æ­, ...</td>\n",
       "      <td>[é‡‡è·, å°æ˜¯, è·ä¸€, ä¸€å°, æ˜¯åˆ†, åˆ†æ ¡]</td>\n",
       "      <td>[ç¬¬ä¸€, é‡‡è·, å­¦æ ¡, åŸå®, å·å¸‚, åŒºæ­, è‹‘æ ¡, æ ¡åŒº, éªŒå­¦, æ–°åŸ, å°å­¦, å­¦...</td>\n",
       "      <td>{é‡‡, ä¸€, æ ¡, å°, è·}</td>\n",
       "      <td>{ä¸€å°, é‡‡è·}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯</td>\n",
       "      <td>0</td>\n",
       "      <td>[é‡‡, è·, ä¸€, å°, æ˜¯, åˆ†, æ ¡]</td>\n",
       "      <td>[æ˜¯]</td>\n",
       "      <td>[é‡‡è·, å°æ˜¯, è·ä¸€, ä¸€å°, æ˜¯åˆ†, åˆ†æ ¡]</td>\n",
       "      <td>[æ˜¯]</td>\n",
       "      <td>{æ˜¯}</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡</td>\n",
       "      <td>2</td>\n",
       "      <td>è¿™æ˜¯5æ¥¼</td>\n",
       "      <td>0</td>\n",
       "      <td>[é‡‡, è·, ä¸€, å°, æ˜¯, åˆ†, æ ¡]</td>\n",
       "      <td>[è¿™, æ˜¯, 5, æ¥¼]</td>\n",
       "      <td>[é‡‡è·, å°æ˜¯, è·ä¸€, ä¸€å°, æ˜¯åˆ†, åˆ†æ ¡]</td>\n",
       "      <td>[5æ¥¼, è¿™æ˜¯, æ˜¯5]</td>\n",
       "      <td>{æ˜¯}</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯</td>\n",
       "      <td>0</td>\n",
       "      <td>å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·å°‘</td>\n",
       "      <td>0</td>\n",
       "      <td>[æ¯›, å¯]</td>\n",
       "      <td>[å› , ä¸º, å…¬, ç§¯, é‡‘, è´·, æ¬¾, è´·, å°‘]</td>\n",
       "      <td>[æ¯›å¯]</td>\n",
       "      <td>[å…¬ç§¯, å› ä¸º, ä¸ºå…¬, è´·å°‘, æ¬¾è´·, ç§¯é‡‘, é‡‘è´·, è´·æ¬¾]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯</td>\n",
       "      <td>0</td>\n",
       "      <td>[æ¯›, å¯]</td>\n",
       "      <td>[æ˜¯]</td>\n",
       "      <td>[æ¯›å¯]</td>\n",
       "      <td>[æ˜¯]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21580</th>\n",
       "      <td>5998</td>\n",
       "      <td>æ‚¨å¥½æˆ‘æ­£åœ¨çœ‹å°šæ—å®¶å›­æˆ¿å­</td>\n",
       "      <td>1</td>\n",
       "      <td>æœ‰</td>\n",
       "      <td>0</td>\n",
       "      <td>[æ‚¨, å¥½, æˆ‘, æ­£, åœ¨, çœ‹, å°š, æ—, å®¶, å›­, æˆ¿, å­]</td>\n",
       "      <td>[æœ‰]</td>\n",
       "      <td>[å°šæ—, å®¶å›­, æˆ¿å­, çœ‹å°š, æ—å®¶, æ‚¨å¥½, å¥½æˆ‘, åœ¨çœ‹, æ­£åœ¨, å›­æˆ¿, æˆ‘æ­£]</td>\n",
       "      <td>[æœ‰]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>5998</td>\n",
       "      <td>æ‚¨å¥½æˆ‘æ­£åœ¨çœ‹å°šæ—å®¶å›­æˆ¿å­</td>\n",
       "      <td>2</td>\n",
       "      <td>æˆ‘å¸¦ä½ çœ‹çœ‹</td>\n",
       "      <td>0</td>\n",
       "      <td>[æ‚¨, å¥½, æˆ‘, æ­£, åœ¨, çœ‹, å°š, æ—, å®¶, å›­, æˆ¿, å­]</td>\n",
       "      <td>[æˆ‘, å¸¦, ä½ , çœ‹, çœ‹]</td>\n",
       "      <td>[å°šæ—, å®¶å›­, æˆ¿å­, çœ‹å°š, æ—å®¶, æ‚¨å¥½, å¥½æˆ‘, åœ¨çœ‹, æ­£åœ¨, å›­æˆ¿, æˆ‘æ­£]</td>\n",
       "      <td>[æˆ‘å¸¦, çœ‹çœ‹, ä½ çœ‹, å¸¦ä½ ]</td>\n",
       "      <td>{çœ‹, æˆ‘}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>5999</td>\n",
       "      <td>ä»Šå¤©å¯ä»¥å®‰æ’çœ‹æˆ¿å­</td>\n",
       "      <td>0</td>\n",
       "      <td>æˆ‘çº¦ä¸‹æˆ¿ä¸œç¨åå›ä½ </td>\n",
       "      <td>1</td>\n",
       "      <td>[ä»Š, å¤©, å¯, ä»¥, å®‰, æ’, çœ‹, æˆ¿, å­]</td>\n",
       "      <td>[æˆ‘, çº¦, ä¸‹, æˆ¿, ä¸œ, ç¨, å, å›, ä½ ]</td>\n",
       "      <td>[å¤©å¯, æ’çœ‹, å®‰æ’, çœ‹æˆ¿, æˆ¿å­, å¯ä»¥, ä»Šå¤©, ä»¥å®‰]</td>\n",
       "      <td>[ä¸‹æˆ¿, æˆ¿ä¸œ, å›ä½ , åå›, ä¸œç¨, ç¨å, çº¦ä¸‹, æˆ‘çº¦]</td>\n",
       "      <td>{æˆ¿}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>5999</td>\n",
       "      <td>ä»Šå¤©å¯ä»¥å®‰æ’çœ‹æˆ¿å­</td>\n",
       "      <td>1</td>\n",
       "      <td>å¯ä»¥çœ‹ä½ å‡ ç‚¹æœ‰æ—¶é—´è¿‡</td>\n",
       "      <td>1</td>\n",
       "      <td>[ä»Š, å¤©, å¯, ä»¥, å®‰, æ’, çœ‹, æˆ¿, å­]</td>\n",
       "      <td>[å¯, ä»¥, çœ‹, ä½ , å‡ , ç‚¹, æœ‰, æ—¶, é—´, è¿‡]</td>\n",
       "      <td>[å¤©å¯, æ’çœ‹, å®‰æ’, çœ‹æˆ¿, æˆ¿å­, å¯ä»¥, ä»Šå¤©, ä»¥å®‰]</td>\n",
       "      <td>[ç‚¹æœ‰, å‡ ç‚¹, çœ‹ä½ , å¯ä»¥, é—´è¿‡, æœ‰æ—¶, æ—¶é—´, ä½ å‡ , ä»¥çœ‹]</td>\n",
       "      <td>{å¯, ä»¥, çœ‹}</td>\n",
       "      <td>{å¯ä»¥}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>5999</td>\n",
       "      <td>ä»Šå¤©å¯ä»¥å®‰æ’çœ‹æˆ¿å­</td>\n",
       "      <td>2</td>\n",
       "      <td>å¥½é‚£å’±ä»¬åœ¨ä¸€å·é—¨å£è¿™ç¢°å¤´</td>\n",
       "      <td>0</td>\n",
       "      <td>[ä»Š, å¤©, å¯, ä»¥, å®‰, æ’, çœ‹, æˆ¿, å­]</td>\n",
       "      <td>[å¥½, é‚£, å’±, ä»¬, åœ¨, ä¸€, å·, é—¨, å£, è¿™, ç¢°, å¤´]</td>\n",
       "      <td>[å¤©å¯, æ’çœ‹, å®‰æ’, çœ‹æˆ¿, æˆ¿å­, å¯ä»¥, ä»Šå¤©, ä»¥å®‰]</td>\n",
       "      <td>[ä»¬åœ¨, åœ¨ä¸€, å¥½é‚£, ä¸€å·, é—¨å£, è¿™ç¢°, å·é—¨, ç¢°å¤´, é‚£å’±, å£è¿™, å’±ä»¬]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21585 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cid            d1  rid                         d2  label  \\\n",
       "0         0       é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡    0  æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡      1   \n",
       "1         0       é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡    1                          æ˜¯      0   \n",
       "2         0       é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡    2                       è¿™æ˜¯5æ¥¼      0   \n",
       "3         1            æ¯›å¯    0                  å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·å°‘      0   \n",
       "4         1            æ¯›å¯    1                          æ˜¯      0   \n",
       "...     ...           ...  ...                        ...    ...   \n",
       "21580  5998  æ‚¨å¥½æˆ‘æ­£åœ¨çœ‹å°šæ—å®¶å›­æˆ¿å­    1                          æœ‰      0   \n",
       "21581  5998  æ‚¨å¥½æˆ‘æ­£åœ¨çœ‹å°šæ—å®¶å›­æˆ¿å­    2                      æˆ‘å¸¦ä½ çœ‹çœ‹      0   \n",
       "21582  5999     ä»Šå¤©å¯ä»¥å®‰æ’çœ‹æˆ¿å­    0                  æˆ‘çº¦ä¸‹æˆ¿ä¸œç¨åå›ä½       1   \n",
       "21583  5999     ä»Šå¤©å¯ä»¥å®‰æ’çœ‹æˆ¿å­    1                 å¯ä»¥çœ‹ä½ å‡ ç‚¹æœ‰æ—¶é—´è¿‡      1   \n",
       "21584  5999     ä»Šå¤©å¯ä»¥å®‰æ’çœ‹æˆ¿å­    2               å¥½é‚£å’±ä»¬åœ¨ä¸€å·é—¨å£è¿™ç¢°å¤´      0   \n",
       "\n",
       "                                 d1_unigram  \\\n",
       "0                     [é‡‡, è·, ä¸€, å°, æ˜¯, åˆ†, æ ¡]   \n",
       "1                     [é‡‡, è·, ä¸€, å°, æ˜¯, åˆ†, æ ¡]   \n",
       "2                     [é‡‡, è·, ä¸€, å°, æ˜¯, åˆ†, æ ¡]   \n",
       "3                                    [æ¯›, å¯]   \n",
       "4                                    [æ¯›, å¯]   \n",
       "...                                     ...   \n",
       "21580  [æ‚¨, å¥½, æˆ‘, æ­£, åœ¨, çœ‹, å°š, æ—, å®¶, å›­, æˆ¿, å­]   \n",
       "21581  [æ‚¨, å¥½, æˆ‘, æ­£, åœ¨, çœ‹, å°š, æ—, å®¶, å›­, æˆ¿, å­]   \n",
       "21582           [ä»Š, å¤©, å¯, ä»¥, å®‰, æ’, çœ‹, æˆ¿, å­]   \n",
       "21583           [ä»Š, å¤©, å¯, ä»¥, å®‰, æ’, çœ‹, æˆ¿, å­]   \n",
       "21584           [ä»Š, å¤©, å¯, ä»¥, å®‰, æ’, çœ‹, æˆ¿, å­]   \n",
       "\n",
       "                                              d2_unigram  \\\n",
       "0      [æ­, å·, å¸‚, é‡‡, è·, ç¬¬, ä¸€, å°, å­¦, é’±, æ±Ÿ, è‹‘, æ ¡, åŒº, æ­, ...   \n",
       "1                                                    [æ˜¯]   \n",
       "2                                           [è¿™, æ˜¯, 5, æ¥¼]   \n",
       "3                            [å› , ä¸º, å…¬, ç§¯, é‡‘, è´·, æ¬¾, è´·, å°‘]   \n",
       "4                                                    [æ˜¯]   \n",
       "...                                                  ...   \n",
       "21580                                                [æœ‰]   \n",
       "21581                                    [æˆ‘, å¸¦, ä½ , çœ‹, çœ‹]   \n",
       "21582                        [æˆ‘, çº¦, ä¸‹, æˆ¿, ä¸œ, ç¨, å, å›, ä½ ]   \n",
       "21583                     [å¯, ä»¥, çœ‹, ä½ , å‡ , ç‚¹, æœ‰, æ—¶, é—´, è¿‡]   \n",
       "21584               [å¥½, é‚£, å’±, ä»¬, åœ¨, ä¸€, å·, é—¨, å£, è¿™, ç¢°, å¤´]   \n",
       "\n",
       "                                         d1_bigrams  \\\n",
       "0                          [é‡‡è·, å°æ˜¯, è·ä¸€, ä¸€å°, æ˜¯åˆ†, åˆ†æ ¡]   \n",
       "1                          [é‡‡è·, å°æ˜¯, è·ä¸€, ä¸€å°, æ˜¯åˆ†, åˆ†æ ¡]   \n",
       "2                          [é‡‡è·, å°æ˜¯, è·ä¸€, ä¸€å°, æ˜¯åˆ†, åˆ†æ ¡]   \n",
       "3                                              [æ¯›å¯]   \n",
       "4                                              [æ¯›å¯]   \n",
       "...                                             ...   \n",
       "21580  [å°šæ—, å®¶å›­, æˆ¿å­, çœ‹å°š, æ—å®¶, æ‚¨å¥½, å¥½æˆ‘, åœ¨çœ‹, æ­£åœ¨, å›­æˆ¿, æˆ‘æ­£]   \n",
       "21581  [å°šæ—, å®¶å›­, æˆ¿å­, çœ‹å°š, æ—å®¶, æ‚¨å¥½, å¥½æˆ‘, åœ¨çœ‹, æ­£åœ¨, å›­æˆ¿, æˆ‘æ­£]   \n",
       "21582              [å¤©å¯, æ’çœ‹, å®‰æ’, çœ‹æˆ¿, æˆ¿å­, å¯ä»¥, ä»Šå¤©, ä»¥å®‰]   \n",
       "21583              [å¤©å¯, æ’çœ‹, å®‰æ’, çœ‹æˆ¿, æˆ¿å­, å¯ä»¥, ä»Šå¤©, ä»¥å®‰]   \n",
       "21584              [å¤©å¯, æ’çœ‹, å®‰æ’, çœ‹æˆ¿, æˆ¿å­, å¯ä»¥, ä»Šå¤©, ä»¥å®‰]   \n",
       "\n",
       "                                              d2_bigrams shared_words_unigram  \\\n",
       "0      [ç¬¬ä¸€, é‡‡è·, å­¦æ ¡, åŸå®, å·å¸‚, åŒºæ­, è‹‘æ ¡, æ ¡åŒº, éªŒå­¦, æ–°åŸ, å°å­¦, å­¦...      {é‡‡, ä¸€, æ ¡, å°, è·}   \n",
       "1                                                    [æ˜¯]                  {æ˜¯}   \n",
       "2                                           [5æ¥¼, è¿™æ˜¯, æ˜¯5]                  {æ˜¯}   \n",
       "3                       [å…¬ç§¯, å› ä¸º, ä¸ºå…¬, è´·å°‘, æ¬¾è´·, ç§¯é‡‘, é‡‘è´·, è´·æ¬¾]                   {}   \n",
       "4                                                    [æ˜¯]                   {}   \n",
       "...                                                  ...                  ...   \n",
       "21580                                                [æœ‰]                   {}   \n",
       "21581                                   [æˆ‘å¸¦, çœ‹çœ‹, ä½ çœ‹, å¸¦ä½ ]               {çœ‹, æˆ‘}   \n",
       "21582                   [ä¸‹æˆ¿, æˆ¿ä¸œ, å›ä½ , åå›, ä¸œç¨, ç¨å, çº¦ä¸‹, æˆ‘çº¦]                  {æˆ¿}   \n",
       "21583               [ç‚¹æœ‰, å‡ ç‚¹, çœ‹ä½ , å¯ä»¥, é—´è¿‡, æœ‰æ—¶, æ—¶é—´, ä½ å‡ , ä»¥çœ‹]            {å¯, ä»¥, çœ‹}   \n",
       "21584       [ä»¬åœ¨, åœ¨ä¸€, å¥½é‚£, ä¸€å·, é—¨å£, è¿™ç¢°, å·é—¨, ç¢°å¤´, é‚£å’±, å£è¿™, å’±ä»¬]                   {}   \n",
       "\n",
       "      shared_words_bigrams  add_feature  \n",
       "0                 {ä¸€å°, é‡‡è·}         True  \n",
       "1                       {}         True  \n",
       "2                       {}         True  \n",
       "3                       {}        False  \n",
       "4                       {}        False  \n",
       "...                    ...          ...  \n",
       "21580                   {}        False  \n",
       "21581                   {}        False  \n",
       "21582                   {}        False  \n",
       "21583                 {å¯ä»¥}         True  \n",
       "21584                   {}        False  \n",
       "\n",
       "[21585 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21584/21585"
     ]
    }
   ],
   "source": [
    "length = len(new_df)\n",
    "for i, flag in enumerate(new_df['add_feature']):\n",
    "    print('\\r %d/%d'%(i, length), end='')\n",
    "    if flag:\n",
    "        df_cleaned.loc[i, 'd1'] = str(df_cleaned.loc[i, 'd1']) +  '@'\n",
    "        df_cleaned.loc[i, 'd2'] = str(df_cleaned.loc[i, 'd2']) +  '@'\n",
    "    else:\n",
    "        df_cleaned.loc[i, 'd1'] = str(df_cleaned.loc[i, 'd1']) +  '&'\n",
    "        df_cleaned.loc[i, 'd2'] = str(df_cleaned.loc[i, 'd2']) +  '&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"aug_train.tsv\", sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"code/train.tsv\", sep='\\t')\n",
    "train['q1'] = df_cleaned['d1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"code/train.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–shared wordsã€powerful wordsã€key words\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "import jieba.analyse\n",
    "from LAC import LAC\n",
    "lac = LAC(mode='seg')\n",
    "\n",
    "\n",
    "def fetch_feature(data):\n",
    "    # åˆ†è¯ã€è¯æ€§æ ‡æ³¨\n",
    "    %time data['d1_word_cut'] = data['d1'].apply(lambda x: list(lac.run(str(x))))\n",
    "    %time data['d2_word_cut'] = data['d2'].apply(lambda x: list(lac.run(str(x))))\n",
    "#     %time data['d1_pos_tag'] = data['d1'].apply(lambda x: [x.flag for x in list(psg.cut(str(x)))])\n",
    "#     %time data['d2_pos_tag'] = data['d2'].apply(lambda x: [x.flag for x in list(psg.cut(str(x)))])\n",
    "    # å›ç­”ä¸€èˆ¬ä¼šå¤è¿°é—®é¢˜çš„å…³é”®è¯ï¼Œæ‰€ä»¥æŠ½å–å¤è¿°çš„è¯ï¼Œè€Œä¸”å¤è¿°è¯ä¸èƒ½æ˜¯åœç”¨è¯\n",
    "#     data['shared_words'] = data.apply(lambda x: [_ for _ in set(x['d1_word_cut']).intersection(set(x['d2_word_cut'])) if _ not in stopwords], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»Ÿè®¡ç‰¹å¾\n",
    "# æ–‡æœ¬ç‰¹å¾ï¼šä¸»è¦åˆ†ä¸ºé—®å¥å’Œå›ç­”\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "# å…±ç°è¯æ¯”ä¾‹\n",
    "def shared_word_proportion(x):\n",
    "    count_d1 = Counter(x['d1_word_cut'])\n",
    "    count_d2 = Counter(x['d2_word_cut'])\n",
    "    n_shared_word_in_d1 = sum([count_d1[w] for w in count_d1 if w in count_d2])\n",
    "    n_shared_word_in_d2 = sum([count_d2[w] for w in count_d2 if w in count_d1])\n",
    "    n_total = sum(count_d1.values()) + sum(count_d2.values())\n",
    "    return 1.0 * (n_shared_word_in_d1 + n_shared_word_in_d2) / n_total\n",
    "\n",
    "# åŠ¨æ€è§„åˆ’æ±‚è§£ç¼–è¾‘è·ç¦»ï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯O(n^2)\n",
    "def edit_distance(str1, str2):\n",
    "    # å‘çˆ¹çš„äºŒç»´æ•°ç»„å£°æ˜æ–¹æ³•ï¼Œå¦‚æœç›´æ¥ç”¨*å°±æ˜¯æµ…æ‹·è´\n",
    "    dp = [[0]*(len(str1)+1) for _ in range((len(str2)+1))]\n",
    "    for i in range(len(str1)+1):\n",
    "        dp[0][i] = i\n",
    "    for j in range(len(str2)+1):\n",
    "        dp[j][0] = j\n",
    "    for i in range(1, len(str2)+1):\n",
    "        for j in range(1, len(str1)+1):\n",
    "            if str2[i-1] == str1[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i-1][j-1], dp[i-1][j], dp[i][j-1])+1\n",
    "    return dp[len(str2)][len(str1)]\n",
    "\n",
    "# ç”ŸæˆæŸä¸ªå¥å­çš„n-gram\n",
    "def n_gram(x, n=2):\n",
    "    if len(x) <= (n-1):\n",
    "        return x\n",
    "    result = []\n",
    "    # zipå‡½æ•°åœ¨è¾¾åˆ°æœ€çŸ­é•¿åº¦æ—¶å°±åœæ­¢è¿­ä»£\n",
    "    n_grams = set(zip(*[x[i:] for i in range(n)]))\n",
    "    for n_gram in n_grams:\n",
    "        result.append(\" \".join(n_gram))\n",
    "    return result\n",
    "\n",
    "# è®¡ç®—ä¸¤ä¸ªå¥å­çš„Jaccardç›¸ä¼¼åº¦\n",
    "def Jaccard(str1, str2):\n",
    "    s1 = set(str1)\n",
    "    s2 = set(str2)\n",
    "    intersection = s1.intersection(s2)\n",
    "    union = s1.union(s2)\n",
    "    return 1.0 * len(intersection) / len(union)\n",
    "\n",
    "\n",
    "# ç»Ÿè®¡ç‰¹å¾ï¼Œé€‰æ‹©äº†57ä¸ªç‰¹å¾ï¼Œåç»­å†åŠ \n",
    "def statistical_feature(data):\n",
    "    punctuations = r'^ !\"#$%&\\'()*+,-./:;<=>?@[]^_`{}~Â·â€”â€˜â€œâ€â€¦ã€ã€‚ã€Šã€‹ï¼ï¼ˆï¼‰ï¼Œï¼šï¼›ï¼Ÿã€ã€‘ï½›ï½ï½'\n",
    "    # ç»Ÿè®¡æ–‡æœ¬å’Œå•è¯çš„é•¿åº¦\n",
    "    %time data['d1_char_length'] = data['d1'].apply(lambda x: len(str(x)))\n",
    "    %time data['d2_char_length'] = data['d2'].apply(lambda x: len(str(x)))\n",
    "    %time data['d1_word_length'] = data['d1_word_cut'].apply(lambda x: len(x))\n",
    "    %time data['d2_word_length'] = data['d2_word_cut'].apply(lambda x: len(x))\n",
    "    %time data['d1_max_word_length'] = data['d1_word_cut'].apply(lambda x: max([len(_) for _ in x]))\n",
    "    %time data['d1_mean_word_length'] = data['d1_word_cut'].apply(lambda x: sum([len(_) for _ in x])/len(x))\n",
    "    %time data['d2_max_word_length'] = data['d2_word_cut'].apply(lambda x: max([len(_) for _ in x]))\n",
    "    %time data['d2_mean_word_length'] = data['d2_word_cut'].apply(lambda x: sum([len(_) for _ in x])/len(x))\n",
    "    %time data['char_length_difference'] = data.apply(lambda x: abs(len(str(x['d1'])) - len(str(x['d2']))), axis=1)\n",
    "    %time data['word_length_difference'] = data.apply(lambda x: abs(len(x['d1_word_cut']) - len(x['d2_word_cut'])), axis=1)\n",
    "    \n",
    "    # ç»Ÿè®¡è¯æ€§å”¯ä¸€å€¼æ•°é‡\n",
    "    %time data['d1_pos_unique_num'] = data['d1_pos_tag'].apply(lambda x: len(set(x)))\n",
    "    %time data['d1_contain_location'] = data['d1_pos_tag'].apply(lambda x: int('nr' in x))\n",
    "    %time data['d1_contain_mood_particle'] = data['d1_pos_tag'].apply(lambda x: int('y' in x))\n",
    "    \n",
    "    # ç»Ÿè®¡å”¯ä¸€å­—ç¬¦ã€å•è¯æ•°é‡ä»¥åŠæ ‡ç‚¹ç¬¦å·æ•°é‡\n",
    "    %time data['d1_unique_char_num'] = data['d1'].apply(lambda x: len(set(str(x))))\n",
    "    %time data['d2_unique_char_num'] = data['d2'].apply(lambda x: len(set(str(x))))\n",
    "    %time data['d1_unique_word_num'] = data['d1_word_cut'].apply(lambda x: len(set(x)))\n",
    "    %time data['d2_unique_word_num'] = data['d2_word_cut'].apply(lambda x: len(set(x)))\n",
    "    data['d1_punc_num'] = data['d1'].apply(lambda x: sum(1 for _ in str(x) if _ in punctuations))\n",
    "    data['d2_punc_num'] = data['d2'].apply(lambda x: sum(1 for _ in str(x) if _ in punctuations))\n",
    "    data['d1_punc_category'] = data['d1'].apply(lambda x: len(set([_ for _ in str(x) if _ in punctuations])))\n",
    "    data['d2_punc_category'] = data['d2'].apply(lambda x: len(set([_ for _ in str(x) if _ in punctuations])))\n",
    "    \n",
    "    # æ˜¯å¦åŒ…å«åœç”¨è¯ã€å­—æ¯ã€æ•°å­—ã€emojiç­‰ç­‰\n",
    "    data['d1_contain_stopwords'] = data['d1'].apply(lambda x: 1 if len([_ for _ in str(x) if _ in stopwords]) > 0 else 0)\n",
    "    data['d2_contain_stopwords'] = data['d2'].apply(lambda x: 1 if len([_ for _ in str(x) if _ in stopwords]) > 0 else 0)\n",
    "    %time data['d1_contain_alphabet'] = data['d1'].apply(lambda x: 1 if len(re.findall(r'[a-zA-Z]', str(x))) > 0 else 0)\n",
    "    %time data['d2_contain_alphabet'] = data['d2'].apply(lambda x: 1 if len(re.findall(r'[a-zA-Z]', str(x))) > 0 else 0)\n",
    "    %time data['d1_contain_number'] = data['d1'].apply(lambda x: 1 if len(re.findall(r'[\\d]', str(x))) > 0 else 0)\n",
    "    %time data['d2_contain_number'] = data['d2'].apply(lambda x: 1 if len(re.findall(r'[\\d]', str(x))) > 0 else 0)\n",
    "    %time data['d1_contain_emoji'] = data['d1'].apply(lambda x: 1 if len(re.findall(u'[\\U00010000-\\U0010ffff\\\\uD800-\\\\uDBFF\\\\uDC00-\\\\uDFFF]', str(x))) > 0 else 0)\n",
    "    %time data['d2_contain_emoji'] = data['d2'].apply(lambda x: 1 if len(re.findall(u'[\\U00010000-\\U0010ffff\\\\uD800-\\\\uDBFF\\\\uDC00-\\\\uDFFF]', str(x))) > 0 else 0)\n",
    "    \n",
    "    # é—®é¢˜å¯ä»¥æå–çš„ä¸šåŠ¡ç‰¹å¾æœ‰ï¼š\n",
    "    # æ˜¯å¦å¸¦æœ‰â€œ?ï¼Ÿâ€ï¼Œä¸€èˆ¬å¸¦é—®å·çš„æ˜¯é—®å¥ï¼Œé—®å¥çš„ç‰¹å¾æ¯”è¾ƒå¥½æ‰¾ï¼Œè€Œæœ‰äº›é—®é¢˜æ˜¯é™ˆè¿°å¥ï¼Œè¿™ç§å…³ç³»å°±ä¸å¤ªå¥½æŠ½å–\n",
    "    # ç‰¹æ®Šå¥å¼â€œæ˜¯/èƒ½/å¯ä»¥...â€/â€œæœ‰...ä¸â€/â€œ....å¯¹å—â€+è¯­æ°”è¯ä¸€èˆ¬å›å¤â€œæ˜¯çš„â€ï¼Œâ€œå¯ä»¥â€ï¼Œâ€œæœ‰çš„â€ï¼Œâ€œå—¯å—¯â€ï¼ˆå¦å®šå›å¤ä¸€èˆ¬åŠ ä¸ªå¦å®šè¯å°±å¯ä»¥äº†ï¼‰\n",
    "    # å¸¦â€œå¤šå°‘â€çš„ä¸€èˆ¬è¦ä¼šå›å¤æ•°é‡å…³ç³»å¦‚ï¼šæ•°é¢ã€ç™¾åˆ†æ¯”ç­‰ç­‰ï¼Œè¿›ä¸€æ­¥å¯ä»¥æŠ½å–ï¼šæ˜¯å¦å«æœ‰ç¨ã€è´·æ¬¾ã€é¦–ä»˜ã€ä»·æ ¼ã€å¹´ç­‰ç­‰å…³é”®è¯\n",
    "    # å¸¦æœ‰â€œæ€ä¹ˆæ ·â€ï¼Œâ€œæ€ä¹ˆåŠâ€ï¼Œè¿™ä¸ªå›ç­”å¤ªè¿‡äºçµæ´»ï¼Œæ¯”è¾ƒéš¾æŠ½å–\n",
    "    # è¯¢é—®ä½ç½®ï¼šâ€œåœ¨å“ªâ€ï¼Œè¿™ä¸ªéœ€è¦é è¯æ€§æ¥æ¨æ–­å›å¤æ˜¯å¦å«æœ‰åœ°ç‚¹\n",
    "    # é—®å¾ˆå¤šçš„ï¼šâ€œé‡‡å…‰â€åŸºäºè§„åˆ™ä¹Ÿä¸å¤ªå¥½åˆ¤æ–­\n",
    "    # å›ç­”å¯æå–çš„ä¸šåŠ¡ç‰¹å¾ï¼šæ˜¯å¦å«æœ‰ä»·æ ¼ã€hashTagã€ç–‘é—®è¯ã€åœ°ç‚¹ã€æ—¶é—´ã€å­¦æ ¡ã€æ¥¼å±‚ã€ç™¾åˆ†æ¯”ã€å•å…ƒã€é¢ç§¯ã€å¹´é™ã€å‡ æœŸä»¥åŠå›å¤â€œæ˜¯çš„â€ã€â€œå¥½çš„â€ã€â€œå¯ä»¥â€\n",
    "    # æ‰¾ä¸šåŠ¡ç‰¹å¾çš„ç›®çš„ï¼šé€šè¿‡é—®é¢˜æ‰€é—®çš„å†…å®¹ï¼Œå¯ä»¥é€šè¿‡å›ç­”ä¸­æŸäº›ä¸šåŠ¡ç‰¹å¾æ‰¾åˆ°æ˜¯å¦åŒ¹é…çš„å…³ç³»ï¼›åŒç†ï¼Œé—®é¢˜ä¸­çš„ä¸šåŠ¡ç‰¹å¾å’Œå›ç­”çš„ç‰¹å¾å¯èƒ½ä¹Ÿå­˜åœ¨ï¼ŒæŸäº›å…³ç³»\n",
    "    %time data['d1_is_interrogative'] = data['d1'].apply(lambda x: 1 if '?' in str(x) or 'ï¼Ÿ' in str(x) else 0)\n",
    "    %time data['d1_spcial_statement'] = data['d1'].apply(lambda x: 1 if re.match(r'(æ˜¯|èƒ½|å¯ä»¥|æœ‰|å¯¹å—)', str(x)) or 'ä¸' in str(x)[-2:] else 0)\n",
    "    %time data['d1_how_many'] = data['d1'].apply(lambda x: 1 if 'å¤šå°‘' in str(x) else 0)\n",
    "    %time data['d1_num_feature'] = data['d1'].apply(lambda x: 1 if re.match(r'(ç¨|è´·|æ¬¾|é¦–ä»˜|ä»·æ ¼|å¹´|è´¹|ä¼˜æƒ )', str(x)) else 0)\n",
    "    %time data['d1_contain_where'] = data['d1'].apply(lambda x:1 if 'åœ¨å“ª' in str(x) else 0)\n",
    "    \n",
    "    %time data['d1_contain_price'] = data['d1'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+((æ¥|å‡ )?)[w|W|ä¸‡]', str(x)) else 0)\n",
    "    %time data['d2_contain_price'] = data['d2'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+((æ¥|å‡ )?)[w|W|ä¸‡]', str(x)) else 0)\n",
    "\n",
    "    # å¸¦æœ‰hashTagçš„ä¸€èˆ¬éƒ½æ˜¯å®¢æˆ·å¤åˆ¶çš„å°åŒºä¿¡æ¯æ¥å’¨è¯¢çš„\n",
    "    %time data['d1_contain_hashtag'] = data['d1'].apply(lambda x: 1 if re.match(r'#.+#', str(x)) else 0)\n",
    "    %time data['d2_contain_hashtag'] = data['d2'].apply(lambda x: 1 if re.match(r'#.+#', str(x)) else 0)\n",
    "    %time data['d1_contain_interrogation'] = data['d1'].apply(lambda x: 1 if re.match(r'(ä»€ä¹ˆ|å“ªå„¿|å“ªé‡Œ|å‡ æ—¶|å‡ |å¤šå°‘æ€|æ€ä¹ˆ|æ€æ ·|æ€ä¹ˆæ ·|å¦‚ä½•|å—|å‘¢)', str(x)) else 0)\n",
    "    %time data['d2_contain_interrogation'] = data['d2'].apply(lambda x: 1 if re.match(r'(ä»€ä¹ˆ|å“ªå„¿|å“ªé‡Œ|å‡ æ—¶|å‡ |å¤šå°‘æ€|æ€ä¹ˆ|æ€æ ·|æ€ä¹ˆæ ·|å¦‚ä½•|å—|å‘¢)', str(x)) else 0)\n",
    "\n",
    "    # ä¸€ç‚¹æœ‰æ­§ä¹‰ï¼Œæ•°æ®é‡Œé¢ä¸€ç‚¹è¡¨ç¤ºå¾ˆå°‘çš„æ„æ€æ¯”è¾ƒå¤šï¼Œæ‰€ä»¥å»æ‰äº†\n",
    "    %time data['d1_contain_time'] = data['d1'].apply(lambda x: 1 if re.match(r'(ä»Šå¤©|æ˜å¤©|ä¸Šåˆ|ä¸­åˆ|ä¸‹åˆ|æ™šä¸Š|å‘¨[äºŒä¸‰å››äº”å…­æ—¥æœ«\\d]|[\\d]+ç‚¹(åŠ?)|[ä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ç‚¹(åŠ?))', str(x)) else 0)\n",
    "    %time data['d2_contain_time'] = data['d2'].apply(lambda x: 1 if re.match(r'(ä»Šå¤©|æ˜å¤©|ä¸Šåˆ|ä¸­åˆ|ä¸‹åˆ|æ™šä¸Š|å‘¨[äºŒä¸‰å››äº”å…­æ—¥æœ«\\d]|[\\d]+ç‚¹(åŠ?)|[ä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ç‚¹(åŠ?))', str(x)) else 0)\n",
    "    %time data['d1_contain_school'] = data['d1'].apply(lambda x: 1 if re.match(r'([ä¸€ä¸‰ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ä¸­|æ ¡åŒº|(å®éªŒ|å—é›…|é›…ç¤¼)?(ä¸­å­¦|å°å­¦|é™„ä¸­|å¹¼å„¿å›­))', str(x)) else 0)\n",
    "    %time data['d2_contain_school'] = data['d2'].apply(lambda x: 1 if re.match(r'([ä¸€ä¸‰ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ä¸­|æ ¡åŒº|(å®éªŒ|å—é›…|é›…ç¤¼)?(ä¸­å­¦|å°å­¦|é™„ä¸­|å¹¼å„¿å›­))', str(x)) else 0)\n",
    "    %time data['d1_contain_floor'] = data['d1'].apply(lambda x: 1 if re.match(r'(([\\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+(å·?)[æ¥¼|å±‚])|([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\\d]+æ ‹))', str(x)) else 0)\n",
    "    %time data['d2_contain_floor'] = data['d2'].apply(lambda x: 1 if re.match(r'(([\\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+(å·?)[æ¥¼|å±‚])|([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\\d]+æ ‹))', str(x)) else 0)\n",
    "    %time data['d1_contain_percentage'] = data['d1'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+%', str(x)) else 0)\n",
    "    %time data['d2_contain_percentage'] = data['d2'].apply(lambda x: 1 if re.match(r'(\\d+\\.?)\\d+%', str(x)) else 0)\n",
    "    %time data['d1_contain_unit'] = data['d1'].apply(lambda x: 1 if re.match(r'[ABCDEFä¸œå—è¥¿åŒ—ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\\d]+([è¾¹æ ‹]?)å•å…ƒ', str(x)) else 0)\n",
    "    %time data['d2_contain_unit'] = data['d2'].apply(lambda x: 1 if re.match(r'[ABCDEFä¸œå—è¥¿åŒ—ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\\d]+([è¾¹æ ‹]?)å•å…ƒ', str(x)) else 0)\n",
    "    %time data['d1_contain_area'] = data['d1'].apply(lambda x: 1 if re.match(r'((\\d+\\.?)[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åä¸¤ç™¾\\d]+(å¹³|å¹³æ–¹|å¹³æ–¹ç±³|å¹³ç±³)|é¢ç§¯\\d+)', str(x)) else 0)\n",
    "    %time data['d2_contain_area'] = data['d2'].apply(lambda x: 1 if re.match(r'((\\d+\\.?)[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åä¸¤ç™¾\\d]+(å¹³|å¹³æ–¹|å¹³æ–¹ç±³|å¹³ç±³)|é¢ç§¯\\d+)', str(x)) else 0)\n",
    "    %time data['d1_contain_year'] = data['d1'].apply(lambda x: 1 if re.match(r'[ä¸€ä¸¤äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹ååŠ\\d]+å¹´', str(x)) else 0)\n",
    "    %time data['d2_contain_year'] = data['d2'].apply(lambda x: 1 if re.match(r'[ä¸€ä¸¤äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹ååŠ\\d]+å¹´', str(x)) else 0)\n",
    "    \n",
    "    # æ–‡æœ¬ç›¸ä¼¼åº¦ç‰¹å¾ï¼šè€ƒè™‘åˆ°æœ¬æ¬¡ä»»åŠ¡æ˜¯è¯­ä¹‰ä¸Šçš„åŒ¹é…ï¼Œä¸ä¸€å®šè¦é—®å¥å’Œç­”å¥ç›¸ä¼¼ï¼Œä½†æ˜¯å¤§å¤šæ•°é—®é¢˜é—®å¥å’Œç­”å¥éƒ½æ¯”è¾ƒç›¸ä¼¼ï¼Œåœ¨é‡å¤ä¸»é¢˜å’Œå…³é”®å­—\n",
    "    # å¯ä»¥æŸ¥çœ‹å…±ç°è¯ã€ç¼–è¾‘è·ç¦»ã€æˆ–è€…å…¶ä»–è·ç¦»å¦‚Jaccardç›¸ä¼¼åº¦\n",
    "    %time data['shared_word_proportion'] = data.apply(shared_word_proportion, axis=1)\n",
    "    %time data['shared_word_num'] = data['shared_words'].apply(lambda x: len(x))\n",
    "    %time data['jaccard_similarity'] = data.apply(lambda x: Jaccard(x['d1_word_cut'], x['d2_word_cut']), axis=1)\n",
    "    %time data['jaccard_similarity_bigram'] = data.apply(lambda x: Jaccard(n_gram(x['d1_word_cut']), n_gram(x['d2_word_cut'])), axis=1)\n",
    "    %time data['jaccard_similarity_trigram'] = data.apply(lambda x: Jaccard(n_gram(x['d1_word_cut'], 3), n_gram(x['d2_word_cut'], 3)), axis=1)\n",
    "    %time data['edit_distance'] = data.apply(lambda x: edit_distance(str(x['d1']), str(x['d2'])), axis=1)\n",
    "    %time data['dice_distance'] = data.apply(lambda x: 2.0 * (len(set(x['d1_word_cut']).intersection(set(x['d2_word_cut']))) / (len(set(x['d1_word_cut']))+len(set(x['d2_word_cut'])))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.8 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "# æ‹¿åŸå§‹ç‰ˆæœ¬åšè®­ç»ƒ\n",
    "# df_raw = pd.read_csv(\"df_raw.tsv\", sep='\\t')\n",
    "df_raw = df_cleaned\n",
    "fetch_feature(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 64 ms\n",
      "Wall time: 63 ms\n",
      "Wall time: 54 ms\n",
      "Wall time: 53 ms\n",
      "Wall time: 173 ms\n",
      "Wall time: 143 ms\n",
      "Wall time: 146 ms\n",
      "Wall time: 124 ms\n",
      "Wall time: 1.36 s\n",
      "Wall time: 1.4 s\n",
      "Wall time: 67 ms\n",
      "Wall time: 51 ms\n",
      "Wall time: 53 ms\n",
      "Wall time: 157 ms\n",
      "Wall time: 170 ms\n",
      "Wall time: 78 ms\n",
      "Wall time: 76 ms\n",
      "Wall time: 141 ms\n",
      "Wall time: 147 ms\n",
      "Wall time: 161 ms\n",
      "Wall time: 156 ms\n",
      "Wall time: 156 ms\n",
      "Wall time: 149 ms\n",
      "Wall time: 68 ms\n",
      "Wall time: 172 ms\n",
      "Wall time: 57.1 ms\n",
      "Wall time: 126 ms\n",
      "Wall time: 48 ms\n",
      "Wall time: 138 ms\n",
      "Wall time: 142 ms\n",
      "Wall time: 151 ms\n",
      "Wall time: 154 ms\n",
      "Wall time: 165 ms\n",
      "Wall time: 200 ms\n",
      "Wall time: 141 ms\n",
      "Wall time: 158 ms\n",
      "Wall time: 204 ms\n",
      "Wall time: 154 ms\n",
      "Wall time: 154 ms\n",
      "Wall time: 168 ms\n",
      "Wall time: 161 ms\n",
      "Wall time: 156 ms\n",
      "Wall time: 190 ms\n",
      "Wall time: 146 ms\n",
      "Wall time: 184 ms\n",
      "Wall time: 151 ms\n",
      "Wall time: 171 ms\n",
      "Wall time: 179 ms\n",
      "Wall time: 2.62 s\n",
      "Wall time: 37 ms\n",
      "Wall time: 1.88 s\n",
      "Wall time: 2.95 s\n",
      "Wall time: 2.74 s\n",
      "Wall time: 11.1 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "statistical_feature(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_csv(\"raw_tmp.tsv\", index=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—æ–‡æœ¬çš„count vectorã€tfidf vectorã€word2vecã€doc2vecã€LDAã€kmeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import word2vec, doc2vec\n",
    "from LAC import LAC\n",
    "\n",
    "lac = LAC(mode='seg')\n",
    "\n",
    "# è®­ç»ƒword2vecï¼Œè¾“å…¥æ˜¯List(List(str))\n",
    "def train_word2vec(data):\n",
    "    sentences = []\n",
    "    for i, row in data.iterrows():\n",
    "        print(\"\\r è¯»å–è¯­æ–™ä¸­ï¼š{}\".format(i), end=\"\")\n",
    "        sentences.append(lac.run(str(row['d1'])))\n",
    "        sentences.append(lac.run(str(row['d2'])))\n",
    "    w2v = word2vec.Word2Vec(\n",
    "        sentences,\n",
    "        size=300,\n",
    "        iter=30,\n",
    "        window = 5,\n",
    "        min_count = 0,\n",
    "        workers = 4,\n",
    "        sample = 1e-4)\n",
    "    return w2v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " è¯»å–è¯­æ–™ä¸­ï¼š53681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 48553 words, keeping 4014 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " è¯»å–è¯­æ–™ä¸­ï¼š53756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 96801 words, keeping 6132 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 145414 words, keeping 7878 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 195362 words, keeping 9373 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 243708 words, keeping 10750 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 292432 words, keeping 11987 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 341237 words, keeping 13142 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 390430 words, keeping 14325 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 439933 words, keeping 15385 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 489066 words, keeping 16417 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 539021 words, keeping 17445 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 588636 words, keeping 18392 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 638880 words, keeping 19338 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 687610 words, keeping 20141 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 737713 words, keeping 21139 word types\n",
      "INFO:gensim.models.word2vec:collected 21196 word types from a corpus of 741040 raw words and 150684 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=0 retains 21196 unique words (100% of original 21196, drops 0)\n",
      "INFO:gensim.models.word2vec:effective_min_count=0 leaves 741040 word corpus (100% of original 741040, drops 0)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 21196 items\n",
      "INFO:gensim.models.word2vec:sample=0.0001 downsamples 425 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 286006 word corpus (38.6% of prior 741040)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 21196 words and 300 dimensions: 61468400 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 4 workers on 21196 vocabulary and 300 features, using sg=0 hs=0 sample=0.0001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 86.46% examples, 234917 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 741040 raw words (286020 effective words) took 1.2s, 242362 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 741040 raw words (285821 effective words) took 0.8s, 341970 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 741040 raw words (285859 effective words) took 0.8s, 349357 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 82.41% examples, 230500 words/s, in_qsize 5, out_qsize 2\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 741040 raw words (285849 effective words) took 1.1s, 257781 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 741040 raw words (286352 effective words) took 0.8s, 342988 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 87.76% examples, 246209 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 6 : training on 741040 raw words (285612 effective words) took 1.1s, 264228 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 98.64% examples, 282428 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 7 : training on 741040 raw words (286399 effective words) took 1.0s, 283683 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 90.52% examples, 253171 words/s, in_qsize 7, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 8 : training on 741040 raw words (286298 effective words) took 1.1s, 264865 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 9 : training on 741040 raw words (286242 effective words) took 0.8s, 339697 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 91.88% examples, 257843 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 10 : training on 741040 raw words (286094 effective words) took 1.1s, 263156 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 11 : training on 741040 raw words (286371 effective words) took 1.0s, 293498 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 12 : training on 741040 raw words (286096 effective words) took 0.9s, 317160 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 13 : training on 741040 raw words (285607 effective words) took 0.9s, 331199 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 14 : training on 741040 raw words (285776 effective words) took 0.9s, 303164 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 15 : training on 741040 raw words (286282 effective words) took 0.9s, 324863 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 87.72% examples, 245514 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 16 : training on 741040 raw words (286247 effective words) took 1.1s, 265215 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 17 : training on 741040 raw words (286134 effective words) took 0.8s, 354125 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 18 : training on 741040 raw words (286055 effective words) took 0.9s, 318032 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 74.41% examples, 202947 words/s, in_qsize 7, out_qsize 2\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 19 : training on 741040 raw words (285802 effective words) took 1.2s, 242637 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 20 : training on 741040 raw words (285999 effective words) took 0.8s, 341758 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 21 : training on 741040 raw words (285649 effective words) took 1.0s, 297525 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 22 - PROGRESS: at 98.64% examples, 281435 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 22 : training on 741040 raw words (285940 effective words) took 1.0s, 282848 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 23 - PROGRESS: at 98.64% examples, 280814 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 23 : training on 741040 raw words (285839 effective words) took 1.0s, 282817 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 24 : training on 741040 raw words (285665 effective words) took 0.8s, 347281 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 25 - PROGRESS: at 77.04% examples, 215008 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 25 : training on 741040 raw words (285623 effective words) took 1.2s, 239286 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 26 : training on 741040 raw words (286514 effective words) took 0.8s, 354165 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 27 : training on 741040 raw words (286042 effective words) took 1.0s, 299249 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 28 : training on 741040 raw words (285746 effective words) took 0.9s, 313538 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 29 - PROGRESS: at 85.08% examples, 237456 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 29 : training on 741040 raw words (286135 effective words) took 1.3s, 227935 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 30 - PROGRESS: at 87.72% examples, 243286 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 30 : training on 741040 raw words (286536 effective words) took 1.1s, 259821 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 22231200 raw words (8580604 effective words) took 29.8s, 288414 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "w2v = train_word2vec(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Word2Vec object under w2v.pkt, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "INFO:gensim.utils:saved w2v.pkt\n"
     ]
    }
   ],
   "source": [
    "w2v.save(\"w2v.pkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†åˆ«æå–å…³é”®è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å›¾ç‰¹å¾ï¼Œè¿™é‡Œä½¿ç”¨å…±ç°çŸ©é˜µå’Œç›¸ä¼¼åº¦çŸ©é˜µæ¥æ„é€ å›¾\n",
    "# å…ˆæå–å…³é”®è¯ï¼Œæå–å…³é”®è¯é‡‡ç”¨æ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œé‡‡ç”¨ï¼šè¯é¢‘ç»Ÿè®¡ã€tfidfã€hitsç®—æ³•å’Œsgrank\n",
    "from time import time\n",
    "\n",
    "def key_words_union(k1, k2):\n",
    "    s1 = set([_[0] for _ in k1])\n",
    "    s2 = set([_[0] for _ in k2])\n",
    "    return s1.union(s2)\n",
    "\n",
    "def key_words_intersection(k1, k2):\n",
    "    s1 = set([_[0] for _ in k1])\n",
    "    s2 = set([_[0] for _ in k2])\n",
    "    return s1.intersection(s2)\n",
    "\n",
    "# æå–å…³é”®å­—æ—¶æ²¡æœ‰æ³¨æ„è¾ƒçŸ­æ–‡æœ¬å’ŒçŸ­æ–‡æœ¬çš„å…³é”®å­—æå–çš„æ•ˆæœä¸åŒï¼Œé—®é¢˜å’Œå›ç­”ä½“æ‚Ÿå…³é”®å­—ä¹Ÿä¸åŒï¼Œæ‰€ä»¥è¿™é‡Œå¯¹é•¿çŸ­æ–‡æœ¬åˆ†å¼€å¤„ç†\n",
    "# çŸ­æ–‡æœ¬ä¸€èˆ¬åªæœ‰ä¸€ä¸ªæ ¸å¿ƒè¯ï¼Œè€Œé•¿ä¸€ç‚¹çš„æ–‡æœ¬åˆ™æœ‰å¤šä¸ª\n",
    "def extract_key_words(text, text_rank = False):\n",
    "    allow_flag=['a', 'ad', 'ag', 'an', 'b', 'd',\n",
    "                'df', 'dg', 'eng', 'f', 'g', 'h',\n",
    "                'i', 'j', 'k', 'l', 'n',\n",
    "                'ns', 'nt', 'nz',\n",
    "                's', 't', 'tg','v', 'vd', 'vg', 'vi',\n",
    "                'vn', 'vq']\n",
    "    extractor = jieba.analyse.extract_tags if not text_rank else jieba.analyse.textrank\n",
    "    if len(text) <= 6:\n",
    "        return extractor(text, topK=1, withWeight=True)\n",
    "    else:\n",
    "        return extractor(text, topK=3, withWeight=True, allowPOS=allow_flag)\n",
    "        \n",
    "\n",
    "def key_words(data):\n",
    "    # ä¸¤ç§ç®—æ³•çš„å¹¶é›†ä½œä¸ºå…³é”®è¯\n",
    "    # åˆ©ç”¨tfidfå’Œtextrankæ¥è·å–å…³é”®è¯\n",
    "    # æœ‰æ—¶å€™ä¸¤ç§ç®—æ³•éƒ½ä¸èƒ½è¦†ç›–åˆ°å…³é”®å­—ï¼Œå¤§çº¦æœ‰1800å¤šæ¡å°±äººå·¥æå–æŠŠ\n",
    "\n",
    "    start = time()\n",
    "    data['key_words_tfidf'] = data.apply(lambda x: extract_key_words(str(x['d1'])+\" \"+str(x['d2'])), axis=1)\n",
    "    print(\"åˆå¹¶é—®ç­”å¯¹TFIDFæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))\n",
    "    data['key_words_textrank'] = data.apply(lambda x: extract_key_words(str(x['d1'])+\" \"+str(x['d2']), text_rank=True), axis=1)\n",
    "    print(\"åˆå¹¶é—®ç­”å¯¹TextRankæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))\n",
    "    data['d1_key_words_tfidf'] = data['d1'].apply(lambda x: extract_key_words(str(x)))\n",
    "    print(\"d1 TFIDFæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))\n",
    "    data['d2_key_words_tfidf'] = data['d2'].apply(lambda x: extract_key_words(str(x)))\n",
    "    print(\"d2 TFIDFæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))\n",
    "    data['d1_key_words_textrank'] = data['d1'].apply(lambda x: extract_key_words(str(x), text_rank=True))\n",
    "    print(\"d1 TextRankæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))\n",
    "    data['d2_key_words_textrank'] = data['d2'].apply(lambda x: extract_key_words(str(x), text_rank=True))\n",
    "    print(\"d2 TextRankæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))\n",
    "    data['key_words'] = data.apply(lambda x: key_words_union(x['key_words_tfidf'], x['key_words_textrank']), axis=1)\n",
    "    print(\"å–ä¸¤ç§ç®—æ³•ç»“æœå¹¶é›†æå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))\n",
    "    data['key_words_i'] = data.apply(lambda x: key_words_intersection(x['key_words_tfidf'], x['key_words_textrank']), axis=1)\n",
    "    print(\"å–ä¸¤ç§ç®—æ³•ç»“æœäº¤é›†æå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:{:.2f}\".format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå¹¶é—®ç­”å¯¹TFIDFæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:141.10\n",
      "åˆå¹¶é—®ç­”å¯¹TextRankæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:297.72\n",
      "d1 TFIDFæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:341.87\n",
      "d2 TFIDFæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:408.70\n",
      "d1 TextRankæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:474.30\n",
      "d2 TextRankæå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:562.05\n",
      "å–ä¸¤ç§ç®—æ³•ç»“æœå¹¶é›†æå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:564.04\n",
      "å–ä¸¤ç§ç®—æ³•ç»“æœäº¤é›†æå–å…³é”®è¯ç´¯ç§¯è€—æ—¶:566.00\n"
     ]
    }
   ],
   "source": [
    "key_words(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "      <th>d1_word_cut</th>\n",
       "      <th>d2_word_cut</th>\n",
       "      <th>key_words_tfidf</th>\n",
       "      <th>key_words_textrank</th>\n",
       "      <th>d1_key_words_tfidf</th>\n",
       "      <th>d2_key_words_tfidf</th>\n",
       "      <th>d1_key_words_textrank</th>\n",
       "      <th>d2_key_words_textrank</th>\n",
       "      <th>key_words</th>\n",
       "      <th>key_words_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>0</td>\n",
       "      <td>æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºï¼Œæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡ã€‚</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[é‡‡è·, ä¸€, å°, æ˜¯, åˆ†æ ¡, å§]</td>\n",
       "      <td>[æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦, é’±æ±Ÿè‹‘æ ¡åŒº, ï¼Œ, æ­å·å¸‚, é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡, ã€‚]</td>\n",
       "      <td>[(æ­å·å¸‚, 2.3164871659375), (å®éªŒå­¦æ ¡, 1.462931634325...</td>\n",
       "      <td>[(æ­å·å¸‚, 1.0), (æ–°åŸ, 0.504449124178066), (æ ¡åŒº, 0.4...</td>\n",
       "      <td>[(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]</td>\n",
       "      <td>[(æ­å·å¸‚, 3.0886495545833337), (å®éªŒå­¦æ ¡, 1.950575512...</td>\n",
       "      <td>[(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]</td>\n",
       "      <td>[(æ­å·å¸‚, 1.0), (æ–°åŸ, 0.6213251057675828), (æ ¡åŒº, 0....</td>\n",
       "      <td>{æ­å·å¸‚, æ ¡åŒº}</td>\n",
       "      <td>{æ­å·å¸‚, æ ¡åŒº}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯çš„</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[é‡‡è·, ä¸€, å°, æ˜¯, åˆ†æ ¡, å§]</td>\n",
       "      <td>[æ˜¯, çš„]</td>\n",
       "      <td>[(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]</td>\n",
       "      <td>[(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]</td>\n",
       "      <td>[(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{ä¸€å°, åˆ†æ ¡}</td>\n",
       "      <td>{ä¸€å°, åˆ†æ ¡}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>2</td>\n",
       "      <td>è¿™æ˜¯5æ¥¼</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[é‡‡è·, ä¸€, å°, æ˜¯, åˆ†æ ¡, å§]</td>\n",
       "      <td>[è¿™, æ˜¯, 5, æ¥¼]</td>\n",
       "      <td>[(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]</td>\n",
       "      <td>[(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]</td>\n",
       "      <td>[(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]</td>\n",
       "      <td>[(è¿™æ˜¯, 4.29162827639)]</td>\n",
       "      <td>[(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{ä¸€å°, åˆ†æ ¡}</td>\n",
       "      <td>{ä¸€å°, åˆ†æ ¡}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·çš„å°‘</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[æ¯›å¯, å—, ï¼Ÿ]</td>\n",
       "      <td>[å› ä¸º, å…¬ç§¯é‡‘, è´·æ¬¾, è´·, çš„, å°‘]</td>\n",
       "      <td>[(æ¯›å¯, 3.7308758169666665), (å…¬ç§¯é‡‘, 2.78778112832...</td>\n",
       "      <td>[(è´·æ¬¾, 1.0), (å…¬ç§¯é‡‘, 0.9961264494011037)]</td>\n",
       "      <td>[(æ¯›å¯, 11.1926274509)]</td>\n",
       "      <td>[(å…¬ç§¯é‡‘, 4.18167169248), (è´·æ¬¾, 2.836784708815)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(è´·æ¬¾, 1.0), (å…¬ç§¯é‡‘, 0.9961264494011037)]</td>\n",
       "      <td>{è´·æ¬¾, å…¬ç§¯é‡‘}</td>\n",
       "      <td>{è´·æ¬¾, å…¬ç§¯é‡‘}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯å‘¢</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[æ¯›å¯, å—, ï¼Ÿ]</td>\n",
       "      <td>[æ˜¯, å‘¢]</td>\n",
       "      <td>[(æ¯›å¯, 11.1926274509)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(æ¯›å¯, 11.1926274509)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53752</th>\n",
       "      <td>13998</td>\n",
       "      <td>è¿™å¥—æˆ¿å­æœ‰å•¥é—®é¢˜å—  æˆ‘çœ‹ä»·æ ¼ä¸é«˜</td>\n",
       "      <td>3</td>\n",
       "      <td>ç§Ÿçº¦è¿˜æœ‰ä¸¤å¹´</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[è¿™, å¥—, æˆ¿å­, æœ‰, å•¥, é—®é¢˜, å—,  ,  , æˆ‘, çœ‹, ä»·æ ¼, ä¸, é«˜]</td>\n",
       "      <td>[ç§Ÿçº¦, è¿˜æœ‰, ä¸¤å¹´]</td>\n",
       "      <td>[(ç§Ÿçº¦, 2.1066763644), (æˆ¿å­, 1.2631809148720001),...</td>\n",
       "      <td>[(ç§Ÿçº¦, 1.0), (é—®é¢˜, 0.6703672480838158), (æˆ¿å­, 0.6...</td>\n",
       "      <td>[(æˆ¿å­, 2.105301524786667), (ä»·æ ¼, 1.5155855171733...</td>\n",
       "      <td>[(ç§Ÿçº¦, 3.511127274)]</td>\n",
       "      <td>[(é—®é¢˜, 1.0), (æˆ¿å­, 0.9961264494011037)]</td>\n",
       "      <td>[(è¿˜æœ‰, 1.0)]</td>\n",
       "      <td>{æˆ¿å­, ç§Ÿçº¦}</td>\n",
       "      <td>{æˆ¿å­, ç§Ÿçº¦}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53753</th>\n",
       "      <td>13998</td>\n",
       "      <td>è¿™å¥—æˆ¿å­æœ‰å•¥é—®é¢˜å—  æˆ‘çœ‹ä»·æ ¼ä¸é«˜</td>\n",
       "      <td>4</td>\n",
       "      <td>éƒ½æœ‰å­¦ä½çš„</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[è¿™, å¥—, æˆ¿å­, æœ‰, å•¥, é—®é¢˜, å—,  ,  , æˆ‘, çœ‹, ä»·æ ¼, ä¸, é«˜]</td>\n",
       "      <td>[éƒ½, æœ‰, å­¦ä½, çš„]</td>\n",
       "      <td>[(å­¦ä½, 2.08790039177), (æˆ¿å­, 1.57897614359), (ä»·æ ¼...</td>\n",
       "      <td>[(é—®é¢˜, 1.0), (æˆ¿å­, 0.9961264494011037)]</td>\n",
       "      <td>[(æˆ¿å­, 2.105301524786667), (ä»·æ ¼, 1.5155855171733...</td>\n",
       "      <td>[(å­¦ä½, 8.35160156708)]</td>\n",
       "      <td>[(é—®é¢˜, 1.0), (æˆ¿å­, 0.9961264494011037)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{æˆ¿å­}</td>\n",
       "      <td>{æˆ¿å­}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53754</th>\n",
       "      <td>13999</td>\n",
       "      <td>æˆ‘çœ‹çœ‹æ—¶é—´å§</td>\n",
       "      <td>0</td>\n",
       "      <td>æ²¡æœ‰å‘¢</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[æˆ‘, çœ‹çœ‹, æ—¶é—´, å§]</td>\n",
       "      <td>[æ²¡æœ‰, å‘¢]</td>\n",
       "      <td>[(çœ‹çœ‹, 1.8034815473799999), (æ—¶é—´, 1.359846544153...</td>\n",
       "      <td>[(çœ‹çœ‹, 1.0), (æ²¡æœ‰, 0.9966849915940917), (æ—¶é—´, 0.9...</td>\n",
       "      <td>[(çœ‹çœ‹, 2.70522232107)]</td>\n",
       "      <td>[(æ²¡æœ‰, 3.11282356515)]</td>\n",
       "      <td>[(çœ‹çœ‹, 1.0)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{çœ‹çœ‹, æ—¶é—´, æ²¡æœ‰}</td>\n",
       "      <td>{çœ‹çœ‹, æ—¶é—´, æ²¡æœ‰}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53755</th>\n",
       "      <td>13999</td>\n",
       "      <td>æˆ‘çœ‹çœ‹æ—¶é—´å§</td>\n",
       "      <td>1</td>\n",
       "      <td>ä»Šå¤©æ–°ä¸Šçš„</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[æˆ‘, çœ‹çœ‹, æ—¶é—´, å§]</td>\n",
       "      <td>[ä»Šå¤©, æ–°, ä¸Š, çš„]</td>\n",
       "      <td>[(çœ‹çœ‹, 1.8034815473799999), (ä»Šå¤©, 1.664039425610...</td>\n",
       "      <td>[(çœ‹çœ‹, 1.0), (æ—¶é—´, 0.9966849915940917), (ä»Šå¤©, 0.9...</td>\n",
       "      <td>[(çœ‹çœ‹, 2.70522232107)]</td>\n",
       "      <td>[(æ–°ä¸Š, 5.97738375145)]</td>\n",
       "      <td>[(çœ‹çœ‹, 1.0)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{çœ‹çœ‹, æ—¶é—´, ä»Šå¤©}</td>\n",
       "      <td>{çœ‹çœ‹, æ—¶é—´, ä»Šå¤©}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53756</th>\n",
       "      <td>13999</td>\n",
       "      <td>æˆ‘çœ‹çœ‹æ—¶é—´å§</td>\n",
       "      <td>2</td>\n",
       "      <td>æˆ¿å­æˆ‘ä¹Ÿæ²¡çœ‹è¿‡å‘¢ï¼Œä¸çŸ¥é“æ˜¯å‡ å·æ¥¼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[æˆ‘, çœ‹çœ‹, æ—¶é—´, å§]</td>\n",
       "      <td>[æˆ¿å­, æˆ‘, ä¹Ÿ, æ²¡çœ‹è¿‡, å‘¢, ï¼Œ, ä¸çŸ¥é“, æ˜¯, å‡ å·, æ¥¼]</td>\n",
       "      <td>[(å‡ å·æ¥¼, 2.3167796086666668), (çœ‹è¿‡, 1.22000641911...</td>\n",
       "      <td>[(æˆ¿å­, 1.0), (çŸ¥é“, 0.8093986725331231), (çœ‹è¿‡, 0.7...</td>\n",
       "      <td>[(çœ‹çœ‹, 2.70522232107)]</td>\n",
       "      <td>[(å‡ å·æ¥¼, 3.475169413), (çœ‹è¿‡, 1.8300096286725), (æˆ¿...</td>\n",
       "      <td>[(çœ‹çœ‹, 1.0)]</td>\n",
       "      <td>[(çŸ¥é“, 1.0), (çœ‹è¿‡, 0.9942864157411772), (å‡ å·æ¥¼, 0....</td>\n",
       "      <td>{çœ‹è¿‡, æˆ¿å­}</td>\n",
       "      <td>{çœ‹è¿‡, æˆ¿å­}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75342 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cid                 d1  rid                           d2  label  \\\n",
       "0          0           é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    0  æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºï¼Œæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡ã€‚    1.0   \n",
       "1          0           é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    1                           æ˜¯çš„    0.0   \n",
       "2          0           é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    2                         è¿™æ˜¯5æ¥¼    0.0   \n",
       "3          1               æ¯›å¯å—ï¼Ÿ    0                   å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·çš„å°‘    0.0   \n",
       "4          1               æ¯›å¯å—ï¼Ÿ    1                           æ˜¯å‘¢    0.0   \n",
       "...      ...                ...  ...                          ...    ...   \n",
       "53752  13998  è¿™å¥—æˆ¿å­æœ‰å•¥é—®é¢˜å—  æˆ‘çœ‹ä»·æ ¼ä¸é«˜    3                       ç§Ÿçº¦è¿˜æœ‰ä¸¤å¹´    NaN   \n",
       "53753  13998  è¿™å¥—æˆ¿å­æœ‰å•¥é—®é¢˜å—  æˆ‘çœ‹ä»·æ ¼ä¸é«˜    4                        éƒ½æœ‰å­¦ä½çš„    NaN   \n",
       "53754  13999             æˆ‘çœ‹çœ‹æ—¶é—´å§    0                          æ²¡æœ‰å‘¢    NaN   \n",
       "53755  13999             æˆ‘çœ‹çœ‹æ—¶é—´å§    1                        ä»Šå¤©æ–°ä¸Šçš„    NaN   \n",
       "53756  13999             æˆ‘çœ‹çœ‹æ—¶é—´å§    2             æˆ¿å­æˆ‘ä¹Ÿæ²¡çœ‹è¿‡å‘¢ï¼Œä¸çŸ¥é“æ˜¯å‡ å·æ¥¼    NaN   \n",
       "\n",
       "                                         d1_word_cut  \\\n",
       "0                               [é‡‡è·, ä¸€, å°, æ˜¯, åˆ†æ ¡, å§]   \n",
       "1                               [é‡‡è·, ä¸€, å°, æ˜¯, åˆ†æ ¡, å§]   \n",
       "2                               [é‡‡è·, ä¸€, å°, æ˜¯, åˆ†æ ¡, å§]   \n",
       "3                                         [æ¯›å¯, å—, ï¼Ÿ]   \n",
       "4                                         [æ¯›å¯, å—, ï¼Ÿ]   \n",
       "...                                              ...   \n",
       "53752  [è¿™, å¥—, æˆ¿å­, æœ‰, å•¥, é—®é¢˜, å—,  ,  , æˆ‘, çœ‹, ä»·æ ¼, ä¸, é«˜]   \n",
       "53753  [è¿™, å¥—, æˆ¿å­, æœ‰, å•¥, é—®é¢˜, å—,  ,  , æˆ‘, çœ‹, ä»·æ ¼, ä¸, é«˜]   \n",
       "53754                                 [æˆ‘, çœ‹çœ‹, æ—¶é—´, å§]   \n",
       "53755                                 [æˆ‘, çœ‹çœ‹, æ—¶é—´, å§]   \n",
       "53756                                 [æˆ‘, çœ‹çœ‹, æ—¶é—´, å§]   \n",
       "\n",
       "                                   d2_word_cut  \\\n",
       "0      [æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦, é’±æ±Ÿè‹‘æ ¡åŒº, ï¼Œ, æ­å·å¸‚, é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡, ã€‚]   \n",
       "1                                       [æ˜¯, çš„]   \n",
       "2                                 [è¿™, æ˜¯, 5, æ¥¼]   \n",
       "3                       [å› ä¸º, å…¬ç§¯é‡‘, è´·æ¬¾, è´·, çš„, å°‘]   \n",
       "4                                       [æ˜¯, å‘¢]   \n",
       "...                                        ...   \n",
       "53752                             [ç§Ÿçº¦, è¿˜æœ‰, ä¸¤å¹´]   \n",
       "53753                            [éƒ½, æœ‰, å­¦ä½, çš„]   \n",
       "53754                                  [æ²¡æœ‰, å‘¢]   \n",
       "53755                            [ä»Šå¤©, æ–°, ä¸Š, çš„]   \n",
       "53756     [æˆ¿å­, æˆ‘, ä¹Ÿ, æ²¡çœ‹è¿‡, å‘¢, ï¼Œ, ä¸çŸ¥é“, æ˜¯, å‡ å·, æ¥¼]   \n",
       "\n",
       "                                         key_words_tfidf  \\\n",
       "0      [(æ­å·å¸‚, 2.3164871659375), (å®éªŒå­¦æ ¡, 1.462931634325...   \n",
       "1             [(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]   \n",
       "2             [(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]   \n",
       "3      [(æ¯›å¯, 3.7308758169666665), (å…¬ç§¯é‡‘, 2.78778112832...   \n",
       "4                                  [(æ¯›å¯, 11.1926274509)]   \n",
       "...                                                  ...   \n",
       "53752  [(ç§Ÿçº¦, 2.1066763644), (æˆ¿å­, 1.2631809148720001),...   \n",
       "53753  [(å­¦ä½, 2.08790039177), (æˆ¿å­, 1.57897614359), (ä»·æ ¼...   \n",
       "53754  [(çœ‹çœ‹, 1.8034815473799999), (æ—¶é—´, 1.359846544153...   \n",
       "53755  [(çœ‹çœ‹, 1.8034815473799999), (ä»Šå¤©, 1.664039425610...   \n",
       "53756  [(å‡ å·æ¥¼, 2.3167796086666668), (çœ‹è¿‡, 1.22000641911...   \n",
       "\n",
       "                                      key_words_textrank  \\\n",
       "0      [(æ­å·å¸‚, 1.0), (æ–°åŸ, 0.504449124178066), (æ ¡åŒº, 0.4...   \n",
       "1                  [(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]   \n",
       "2                  [(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]   \n",
       "3                 [(è´·æ¬¾, 1.0), (å…¬ç§¯é‡‘, 0.9961264494011037)]   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "53752  [(ç§Ÿçº¦, 1.0), (é—®é¢˜, 0.6703672480838158), (æˆ¿å­, 0.6...   \n",
       "53753              [(é—®é¢˜, 1.0), (æˆ¿å­, 0.9961264494011037)]   \n",
       "53754  [(çœ‹çœ‹, 1.0), (æ²¡æœ‰, 0.9966849915940917), (æ—¶é—´, 0.9...   \n",
       "53755  [(çœ‹çœ‹, 1.0), (æ—¶é—´, 0.9966849915940917), (ä»Šå¤©, 0.9...   \n",
       "53756  [(æˆ¿å­, 1.0), (çŸ¥é“, 0.8093986725331231), (çœ‹è¿‡, 0.7...   \n",
       "\n",
       "                                      d1_key_words_tfidf  \\\n",
       "0             [(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]   \n",
       "1             [(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]   \n",
       "2             [(åˆ†æ ¡, 4.60009864309), (ä¸€å°, 3.88909242123)]   \n",
       "3                                  [(æ¯›å¯, 11.1926274509)]   \n",
       "4                                  [(æ¯›å¯, 11.1926274509)]   \n",
       "...                                                  ...   \n",
       "53752  [(æˆ¿å­, 2.105301524786667), (ä»·æ ¼, 1.5155855171733...   \n",
       "53753  [(æˆ¿å­, 2.105301524786667), (ä»·æ ¼, 1.5155855171733...   \n",
       "53754                              [(çœ‹çœ‹, 2.70522232107)]   \n",
       "53755                              [(çœ‹çœ‹, 2.70522232107)]   \n",
       "53756                              [(çœ‹çœ‹, 2.70522232107)]   \n",
       "\n",
       "                                      d2_key_words_tfidf  \\\n",
       "0      [(æ­å·å¸‚, 3.0886495545833337), (å®éªŒå­¦æ ¡, 1.950575512...   \n",
       "1                                                     []   \n",
       "2                                  [(è¿™æ˜¯, 4.29162827639)]   \n",
       "3           [(å…¬ç§¯é‡‘, 4.18167169248), (è´·æ¬¾, 2.836784708815)]   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "53752                                [(ç§Ÿçº¦, 3.511127274)]   \n",
       "53753                              [(å­¦ä½, 8.35160156708)]   \n",
       "53754                              [(æ²¡æœ‰, 3.11282356515)]   \n",
       "53755                              [(æ–°ä¸Š, 5.97738375145)]   \n",
       "53756  [(å‡ å·æ¥¼, 3.475169413), (çœ‹è¿‡, 1.8300096286725), (æˆ¿...   \n",
       "\n",
       "                       d1_key_words_textrank  \\\n",
       "0      [(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]   \n",
       "1      [(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]   \n",
       "2      [(åˆ†æ ¡, 1.0), (ä¸€å°, 0.9961264494011037)]   \n",
       "3                                         []   \n",
       "4                                         []   \n",
       "...                                      ...   \n",
       "53752  [(é—®é¢˜, 1.0), (æˆ¿å­, 0.9961264494011037)]   \n",
       "53753  [(é—®é¢˜, 1.0), (æˆ¿å­, 0.9961264494011037)]   \n",
       "53754                            [(çœ‹çœ‹, 1.0)]   \n",
       "53755                            [(çœ‹çœ‹, 1.0)]   \n",
       "53756                            [(çœ‹çœ‹, 1.0)]   \n",
       "\n",
       "                                   d2_key_words_textrank     key_words  \\\n",
       "0      [(æ­å·å¸‚, 1.0), (æ–°åŸ, 0.6213251057675828), (æ ¡åŒº, 0....     {æ­å·å¸‚, æ ¡åŒº}   \n",
       "1                                                     []      {ä¸€å°, åˆ†æ ¡}   \n",
       "2                                                     []      {ä¸€å°, åˆ†æ ¡}   \n",
       "3                 [(è´·æ¬¾, 1.0), (å…¬ç§¯é‡‘, 0.9961264494011037)]     {è´·æ¬¾, å…¬ç§¯é‡‘}   \n",
       "4                                                     []            {}   \n",
       "...                                                  ...           ...   \n",
       "53752                                        [(è¿˜æœ‰, 1.0)]      {æˆ¿å­, ç§Ÿçº¦}   \n",
       "53753                                                 []          {æˆ¿å­}   \n",
       "53754                                                 []  {çœ‹çœ‹, æ—¶é—´, æ²¡æœ‰}   \n",
       "53755                                                 []  {çœ‹çœ‹, æ—¶é—´, ä»Šå¤©}   \n",
       "53756  [(çŸ¥é“, 1.0), (çœ‹è¿‡, 0.9942864157411772), (å‡ å·æ¥¼, 0....      {çœ‹è¿‡, æˆ¿å­}   \n",
       "\n",
       "        key_words_i  \n",
       "0         {æ­å·å¸‚, æ ¡åŒº}  \n",
       "1          {ä¸€å°, åˆ†æ ¡}  \n",
       "2          {ä¸€å°, åˆ†æ ¡}  \n",
       "3         {è´·æ¬¾, å…¬ç§¯é‡‘}  \n",
       "4                {}  \n",
       "...             ...  \n",
       "53752      {æˆ¿å­, ç§Ÿçº¦}  \n",
       "53753          {æˆ¿å­}  \n",
       "53754  {çœ‹çœ‹, æ—¶é—´, æ²¡æœ‰}  \n",
       "53755  {çœ‹çœ‹, æ—¶é—´, ä»Šå¤©}  \n",
       "53756      {çœ‹è¿‡, æˆ¿å­}  \n",
       "\n",
       "[75342 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75342it [00:10, 7016.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# ç»Ÿè®¡å…±ç°çŸ©é˜µï¼Œè¿™é‡Œç»Ÿè®¡çš„æ˜¯å…³é”®è¯åœ¨åœ¨ä¸€æ¡è®°å½•ä¸­å…±ç°çš„\n",
    "# è¿˜æœ‰ä¸€ç§åŸºäºç›¸ä¼¼åº¦çš„å›¾ï¼Œè¿™é‡Œå°†å…³é”®è¯çš„ç›¸ä¼¼åº¦æ¥æ„å»ºå‡ºå›¾ç‰¹å¾\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "graph = nx.Graph()\n",
    "\n",
    "def fetch_nodes(data):\n",
    "    key_words = set()\n",
    "    for i, row in data.iterrows():\n",
    "        res = row['key_words']\n",
    "        key_words.update(res)\n",
    "\n",
    "    # é¡¶ç‚¹ç”¨æ•°å­—è¡¨ç¤º==\n",
    "    nodes2words = [_ for _ in key_words]\n",
    "    words2nodes = {word:idx for idx, word in enumerate(nodes2words)}\n",
    "    return nodes2words, words2nodes\n",
    "\n",
    "\n",
    "def build_graph(graph, data):\n",
    "    # å°†é¡¶ç‚¹åŠ å…¥åˆ°å›¾ä¸­\n",
    "    graph.add_nodes_from([_ for _ in range(len(nodes2words))])\n",
    "\n",
    "    # ç»™å›¾å¢åŠ è¾¹ï¼Œä¸€æ¡è®°å½•çš„æ‰€æœ‰å…³é”®è¯ä¸¤ä¸¤ä¹‹é—´éƒ½æœ‰è¾¹\n",
    "    for i, row in tqdm(data.iterrows()):\n",
    "        res = list(row['key_words'])\n",
    "        if len(res) >= 2:\n",
    "            for i in range(len(res)-1):\n",
    "                for j in range(i, len(res)):\n",
    "                    graph.add_edge(words2nodes[res[i]], words2nodes[res[j]])\n",
    "\n",
    "nodes2words, words2nodes = fetch_nodes(df_raw)\n",
    "build_graph(graph, df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ä¸»è¦æå–çš„ç‰¹å¾æœ‰ï¼šæ¯ä¸ªå…³é”®å­—çš„è¿æ¥è¾¹æ•°ï¼ˆåº¦ï¼‰ï¼Œpagerrankå€¼ï¼Œ hitsç®—æ³•çš„Aå’ŒHå€¼ï¼Œæ¯ä¸ªå…³é”®è¯çš„é‚»å±…æ•°é‡\n",
    "\n",
    "# æ‰€æœ‰èŠ‚ç‚¹çš„è¿é€šåˆ†é‡\n",
    "def components(graph):\n",
    "    max_components = {}\n",
    "    components = nx.connected_components(graph)\n",
    "    for component in components:\n",
    "        for n in component:\n",
    "            max_components[n] = max(max_components.get(n, 0), len(component))\n",
    "    return max_components\n",
    "\n",
    "# hitsç®—æ³•\n",
    "def hits(graph):\n",
    "    hits_h, hits_a = nx.hits(graph, max_iter=500)\n",
    "    return hits_h, hits_a\n",
    "\n",
    "# æ‰€æœ‰å•è¯çš„åº¦çš„è®¡ç®—\n",
    "def degrees(graph):\n",
    "    max_degrees = {}\n",
    "    edges = graph.edges()\n",
    "    for edge in edges:\n",
    "        for n in edge:\n",
    "            max_degrees[n] = max_degrees.get(n, 0) + 1\n",
    "    return max_degrees\n",
    "\n",
    "# å…ˆæ±‚æ‰€æœ‰å…³é”®è¯çš„è¿é€šåˆ†é‡ã€hitsã€åº¦\n",
    "max_components = components(graph)\n",
    "hits_h, hits_a = hits(graph)\n",
    "max_degrees = degrees(graph)\n",
    "pagerank = nx.pagerank_scipy(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—å›¾ç‰¹å¾\n",
    "def graph_feature(data, graph):\n",
    "    data['neighbors_num_coo'] = data['key_words'].apply(lambda x: [len(set(graph.neighbors(words2nodes[_]))) for _ in x])\n",
    "    data['hits_a_coo'] = data['key_words'].apply(lambda x: [hits_a[words2nodes[_]] for _ in x])\n",
    "    data['hits_h_coo'] = data['key_words'].apply(lambda x: [hits_h[words2nodes[_]] for _ in x])\n",
    "    data['max_degrees_coo'] = data['key_words'].apply(lambda x: [max_degrees.get(words2nodes[_], 0) for _ in x])\n",
    "    data['pagerank_coo'] = data['key_words'].apply(lambda x: [pagerank[words2nodes[_]] for _ in x])\n",
    "    \n",
    "    # æ˜ å°„æˆæ•°å€¼\n",
    "    data['max_hits_a_coo'] = data['hits_a_coo'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_hits_a_coo'] = data['hits_a_coo'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_max_degrees_coo'] = data['max_degrees_coo'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_max_degrees_coo'] = data['max_degrees_coo'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_pagerank_coo'] = data['pagerank_coo'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_pagerank_coo'] = data['pagerank_coo'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    \n",
    "    data['max_tfidf_coo'] = data['key_words_tfidf'].apply(lambda x: max([_[1] for _ in x]) if len(x) > 0 else 0)\n",
    "    data['mean_tfidf_coo'] = data['key_words_tfidf'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "    data['max_textrank_coo'] = data['key_words_textrank'].apply(lambda x: max([_[1] for _ in x])  if len(x) > 0 else 0)\n",
    "    data['mean_textrank_coo'] = data['key_words_textrank'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "\n",
    "graph_feature(df_raw, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# å†åŸºäºç›¸ä¼¼åº¦æ¥æ„é€ å›¾æ¨¡å‹\n",
    "# æ ¹æ®å…³é”®å­—çš„ç›¸ä¼¼è¯å›¾æ„é€ å›¾ç‰¹å¾\n",
    "sim_graph = nx.Graph()\n",
    "\n",
    "def fetch_nodes():\n",
    "    # é¡¶ç‚¹ç”¨æ•°å­—è¡¨ç¤º==\n",
    "    nodes2words = w2v.wv.index2word\n",
    "    words2nodes = {word:idx for idx, word in enumerate(nodes2words)}\n",
    "    return nodes2words, words2nodes\n",
    "\n",
    "\n",
    "def build_graph(graph):\n",
    "    # å°†é¡¶ç‚¹åŠ å…¥åˆ°å›¾ä¸­\n",
    "    graph.add_nodes_from([_ for _ in range(len(nodes2words))])\n",
    "\n",
    "    # ç»™å›¾å¢åŠ è¾¹ï¼Œä¸€æ¡è®°å½•çš„æ‰€æœ‰å…³é”®è¯ä¸¤ä¸¤ä¹‹é—´éƒ½æœ‰è¾¹\n",
    "    for word in nodes2words:\n",
    "        similarities = w2v.wv.most_similar(word, topn=3)\n",
    "        for sim in similarities:\n",
    "            graph.add_edge(words2nodes[word], words2nodes[sim[0]])\n",
    "\n",
    "nodes2words, words2nodes = fetch_nodes()\n",
    "build_graph(sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_components = components(sim_graph)\n",
    "hits_h, hits_a = hits(sim_graph)\n",
    "max_degrees = degrees(sim_graph)\n",
    "pagerank = nx.pagerank_scipy(sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—å›¾ç‰¹å¾\n",
    "def graph_feature(data, graph):\n",
    "    data['neighbors_num_sim'] = data['key_words'].apply(lambda x: [len(set(graph.neighbors(words2nodes[_]))) if _ in words2nodes else 0. for _ in x])\n",
    "    data['hits_a_sim'] = data['key_words'].apply(lambda x: [hits_a[words2nodes[_]] if _ in words2nodes else 0.  for _ in x])\n",
    "    data['hits_h_sim'] = data['key_words'].apply(lambda x: [hits_h[words2nodes[_]] if _ in words2nodes else 0.  for _ in x])\n",
    "    data['max_degrees_sim'] = data['key_words'].apply(lambda x: [max_degrees.get(words2nodes[_], 0)  if _ in words2nodes else 0  for _ in x])\n",
    "    data['pagerank_sim'] = data['key_words'].apply(lambda x: [pagerank[words2nodes[_]] if _ in words2nodes else 0.  for _ in x])\n",
    "    \n",
    "    # æ˜ å°„æˆæ•°å€¼\n",
    "    data['max_hits_a_sim'] = data['hits_a_sim'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_hits_a_sim'] = data['hits_a_sim'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_max_degrees_sim'] = data['max_degrees_sim'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_max_degrees_sim'] = data['max_degrees_sim'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    data['max_pagerank_sim'] = data['pagerank_sim'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    data['mean_pagerank_sim'] = data['pagerank_sim'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else 0)\n",
    "    \n",
    "    data['max_tfidf_sim'] = data['key_words_tfidf'].apply(lambda x: max([_[1] for _ in x]) if len(x) > 0 else 0)\n",
    "    data['mean_tfidf_sim'] = data['key_words_tfidf'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "    data['max_textrank_sim'] = data['key_words_textrank'].apply(lambda x: max([_[1] for _ in x])  if len(x) > 0 else 0)\n",
    "    data['mean_textrank_sim'] = data['key_words_textrank'].apply(lambda x: sum([_[1] for _ in x])/len(x) if len(x) > 0 else 0)\n",
    "\n",
    "graph_feature(df_raw, sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MiniConda\\lib\\site-packages\\gensim\\models\\doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "INFO:gensim.models.doc2vec:collecting all words and their counts\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #10000, processed 65462 words (735556/s), 5813 word types, 10000 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #20000, processed 132114 words (789530/s), 8771 word types, 20000 tags\n",
      "INFO:gensim.models.doc2vec:collected 9196 word types and 21585 unique tags from a corpus of 21585 examples and 142375 words\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 retains 1764 unique words (19% of original 9196, drops 7432)\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 leaves 131564 word corpus (92% of original 142375, drops 10811)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 9196 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 68 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 87256 word corpus (66.3% of prior 131564)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 1764 words and 300 dimensions: 31017600 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 4 workers on 1764 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 35.06% examples, 25365 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 84.15% examples, 36355 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 142375 raw words (108609 effective words) took 2.9s, 37801 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 35.21% examples, 23459 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 92.90% examples, 37860 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 142375 raw words (109109 effective words) took 2.7s, 40513 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 35.06% examples, 29363 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 84.15% examples, 39855 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 142375 raw words (108704 effective words) took 2.5s, 42761 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 35.06% examples, 28816 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 100.00% examples, 46710 words/s, in_qsize 0, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 142375 raw words (108871 effective words) took 2.3s, 46662 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 35.06% examples, 28071 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 92.90% examples, 42733 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 142375 raw words (108882 effective words) took 2.4s, 45731 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 711875 raw words (544175 effective words) took 12.9s, 42173 effective words/s\n",
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
      "INFO:gensim.models.base_any2vec:training model with 4 workers on 1764 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 35.06% examples, 27243 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 92.90% examples, 39449 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 142375 raw words (108795 effective words) took 2.6s, 42241 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 35.06% examples, 22536 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 142375 raw words (108679 effective words) took 2.7s, 40786 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 35.06% examples, 26200 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 85.92% examples, 37799 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 142375 raw words (108896 effective words) took 2.7s, 40138 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 35.06% examples, 23627 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 85.92% examples, 35775 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 142375 raw words (108986 effective words) took 2.8s, 38364 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 35.06% examples, 29067 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 92.90% examples, 41526 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 142375 raw words (108934 effective words) took 2.5s, 44346 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 35.06% examples, 28869 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 92.90% examples, 41146 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 6 : training on 142375 raw words (108868 effective words) took 2.5s, 44104 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 35.06% examples, 26578 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 92.90% examples, 40626 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 7 : training on 142375 raw words (108889 effective words) took 2.5s, 43549 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 35.06% examples, 24053 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 92.90% examples, 36391 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 8 : training on 142375 raw words (108876 effective words) took 2.8s, 38999 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 35.21% examples, 26525 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 85.92% examples, 37320 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 9 : training on 142375 raw words (108618 effective words) took 2.7s, 40109 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 35.06% examples, 27938 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 70.12% examples, 32269 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 10 : training on 142375 raw words (108934 effective words) took 2.8s, 38353 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 7.00% examples, 7573 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 62.99% examples, 24851 words/s, in_qsize 6, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 11 : training on 142375 raw words (108839 effective words) took 3.2s, 34524 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 35.06% examples, 25714 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 85.92% examples, 35643 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 12 : training on 142375 raw words (109040 effective words) took 2.9s, 38001 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 35.06% examples, 25974 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 93.02% examples, 37768 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 13 : training on 142375 raw words (108789 effective words) took 2.7s, 40494 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 35.06% examples, 21944 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 92.90% examples, 35440 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 14 : training on 142375 raw words (108969 effective words) took 2.9s, 37911 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 35.06% examples, 27804 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 92.90% examples, 41558 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 15 : training on 142375 raw words (109070 effective words) took 2.5s, 44205 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 35.06% examples, 27065 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 92.90% examples, 40994 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 16 : training on 142375 raw words (108694 effective words) took 2.5s, 43869 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 35.21% examples, 23741 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 93.02% examples, 38207 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 17 : training on 142375 raw words (108748 effective words) took 2.6s, 41039 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 35.06% examples, 24273 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 92.90% examples, 37258 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 18 : training on 142375 raw words (108625 effective words) took 2.7s, 39947 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 35.06% examples, 26853 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 92.90% examples, 39753 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 19 : training on 142375 raw words (108741 effective words) took 2.6s, 42506 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 35.06% examples, 26979 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 92.90% examples, 41772 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 20 : training on 142375 raw words (108839 effective words) took 2.4s, 44795 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 21 - PROGRESS: at 35.06% examples, 28340 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 21 - PROGRESS: at 92.90% examples, 40367 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 21 : training on 142375 raw words (108814 effective words) took 2.5s, 43105 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 22 - PROGRESS: at 35.06% examples, 24881 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 22 - PROGRESS: at 92.90% examples, 38268 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 22 : training on 142375 raw words (108845 effective words) took 2.7s, 40905 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 23 - PROGRESS: at 35.06% examples, 28687 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 23 - PROGRESS: at 85.92% examples, 39941 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 23 : training on 142375 raw words (108878 effective words) took 2.6s, 42620 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 24 - PROGRESS: at 35.06% examples, 21537 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 24 - PROGRESS: at 85.92% examples, 33084 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 24 : training on 142375 raw words (108975 effective words) took 3.1s, 35585 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 25 - PROGRESS: at 35.06% examples, 22090 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 25 - PROGRESS: at 92.90% examples, 35530 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 25 : training on 142375 raw words (108695 effective words) took 2.9s, 38001 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 26 - PROGRESS: at 35.06% examples, 23459 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 26 - PROGRESS: at 92.90% examples, 38450 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 26 : training on 142375 raw words (108823 effective words) took 2.6s, 41072 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 27 - PROGRESS: at 35.06% examples, 25307 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 27 - PROGRESS: at 92.90% examples, 38358 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 27 : training on 142375 raw words (108700 effective words) took 2.6s, 41046 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 28 - PROGRESS: at 35.06% examples, 25095 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 28 - PROGRESS: at 85.92% examples, 36267 words/s, in_qsize 2, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 28 : training on 142375 raw words (108947 effective words) took 2.8s, 39237 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 29 - PROGRESS: at 35.06% examples, 30499 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 29 - PROGRESS: at 92.90% examples, 43428 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 29 : training on 142375 raw words (109024 effective words) took 2.4s, 46103 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 30 - PROGRESS: at 35.06% examples, 25240 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH 30 - PROGRESS: at 92.90% examples, 37670 words/s, in_qsize 1, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 30 : training on 142375 raw words (108749 effective words) took 2.7s, 40302 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 4271250 raw words (3265279 effective words) took 80.7s, 40460 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# è®­ç»ƒdoc2vecï¼Œå°†æ¯ä¸€ä¸ªå¥å­è¡¨ç¤ºæˆå¥å‘é‡ï¼Œç„¶åé€šè¿‡å¥å‘é‡å’Œå…³é”®è¯åŒ¹é…ç¨‹åº¦å¯»æ‰¾ç‰¹å¾\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from LAC import LAC\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "lac = LAC(mode='seg')\n",
    "\n",
    "# å°†å¥å­éƒ½åˆ†å¥½è¯ï¼Œç„¶ååŒ…è£…å¥½ï¼Œç”Ÿæˆå¥å­å‘é‡\n",
    "def wrap_sentence(data):\n",
    "    sentences = []\n",
    "    # æŠŠå›ç­”åšå¥å­ç¼–ç å°±æˆ\n",
    "    for i, row in data.iterrows():\n",
    "        sentences.append(TaggedDocument(lac.run(row['d2']), tags=[i]))\n",
    "    return sentences\n",
    "\n",
    "sentences = wrap_sentence(df_cleaned)\n",
    "d2v = Doc2Vec(sentences, window=5, size=300, sample=1e-3, workers=4, negative=5)\n",
    "d2v.train(sentences, total_examples=d2v.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦', 'é’±æ±Ÿè‹‘æ ¡åŒº', 'ï¼Œ', 'æ­å·å¸‚', 'é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡', 'ã€‚'], tags=[0]),\n",
       " TaggedDocument(words=['æ˜¯', 'çš„'], tags=[1]),\n",
       " TaggedDocument(words=['è¿™', 'æ˜¯', '5', 'æ¥¼'], tags=[2]),\n",
       " TaggedDocument(words=['å› ä¸º', 'å…¬ç§¯é‡‘', 'è´·æ¬¾', 'è´·', 'çš„', 'å°‘'], tags=[3]),\n",
       " TaggedDocument(words=['æ˜¯', 'å‘¢'], tags=[4]),\n",
       " TaggedDocument(words=['è¿™', 'å¥—', 'ä¸€', 'æ¥¼', 'å¸¦', 'é™¢', 'çš„', 'ï¼Œ', 'æ‚¨', 'çœ‹çœ‹'], tags=[5]),\n",
       " TaggedDocument(words=['æˆ¿æœ¬', 'éƒ½æ˜¯', 'äº”å¹´', 'å¤–', 'çš„'], tags=[6]),\n",
       " TaggedDocument(words=['å¥½', 'çš„', '?', '?', 'ï¼Œ', 'æ‚¨', 'å…ˆ', 'çœ‹', 'ä¸‹'], tags=[7]),\n",
       " TaggedDocument(words=['æ‚¨', 'æ˜¯', 'é¦–å¥—', 'è¿˜æ˜¯', 'äºŒå¥—', 'å‘¢', 'ï¼Ÿ'], tags=[8]),\n",
       " TaggedDocument(words=['æ‰€æœ‰', 'è´¹ç”¨', 'ä¸‹æ¥', '654ä¸‡'], tags=[9])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Doc2Vec object under d2v.pkt, separately None\n",
      "INFO:gensim.utils:saved d2v.pkt\n"
     ]
    }
   ],
   "source": [
    "# ä¿å­˜å¥½æ¨¡å‹\n",
    "d2v.save(\"d2v.pkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ©ç”¨è¯å‘é‡å’Œå¥å­å‘é‡ä¹‹é—´æ¥åº¦é‡\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def distance_calc(data):\n",
    "    \n",
    "    def union(l1, l2):\n",
    "        s1 = set(_[0] for _ in l1)\n",
    "        s2 = set(_[0] for _ in l2)\n",
    "        return s1.union(s2)\n",
    "    \n",
    "    def extractor(x):\n",
    "        res = union(x['d1_key_words_tfidf'], x['d1_key_words_textrank'])\n",
    "        if res == set():\n",
    "            ans = list(psg.cut(str(x['d1'])))\n",
    "            key_words = set([_.word for _ in ans if 'n' in _.flag or 'v' in _.flag or 'm' in _.flag or 'r' in _.flag])\n",
    "            if key_words == set() and len(str(x['d1']))<=2:\n",
    "                key_words.add(str(x['d1']))\n",
    "            return key_words\n",
    "        else:\n",
    "            return res\n",
    "        \n",
    "    def cosine(w1, w2):\n",
    "        return w1.dot(w2) / (math.sqrt((w1**2).sum()) * math.sqrt((w2**2).sum()))\n",
    "    \n",
    "    def euclidean(w1, w2):\n",
    "        return math.sqrt(((w1-w2)**2).sum())\n",
    "    \n",
    "    def inner_product(w1, w2):\n",
    "        return np.dot(w1, w2)\n",
    "        \n",
    "    # å•è¯ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "    def ww_(x, method=\"cosine\"):\n",
    "        if method == \"cosine\":\n",
    "            distance = cosine\n",
    "        elif method == \"euclidean\":\n",
    "            distance = euclidean\n",
    "        elif \"pearson\" in method:\n",
    "            distance = stats.pearsonr\n",
    "        else:\n",
    "            distance = inner_product\n",
    "        cos = 0.\n",
    "        num = 0\n",
    "        if x['key_words'] == []:\n",
    "            return 0.\n",
    "        else:\n",
    "            for i in range(len(x['key_words'])-1):\n",
    "                for j in range(i+1, len(x['key_words'])):\n",
    "                    w1, w2 = list(x['key_words'])[i], list(x['key_words'])[j]\n",
    "                    if w1 not in w2v.wv.vocab or w2 not in w2v.wv.vocab:\n",
    "                        break\n",
    "                    w1, w2 = w2v.wv[w1], w2v.wv[w2]\n",
    "                    dist = distance(w1, w2)\n",
    "                    if method == \"pearson_cor\":\n",
    "                        dist = dist[0]\n",
    "                    elif method == \"pearson_pvalue\":\n",
    "                        dist = dist[1]\n",
    "                    cos += dist\n",
    "                    num += 1\n",
    "        return cos/num if num > 0 else 0\n",
    "    \n",
    "    def ww_(x, method=\"cosine\"):\n",
    "        if method == \"cosine\":\n",
    "            distance = cosine\n",
    "        elif method == \"euclidean\":\n",
    "            distance = euclidean\n",
    "        elif \"pearson\" in method:\n",
    "            distance = stats.pearsonr\n",
    "        else:\n",
    "            distance = inner_product\n",
    "        cos = 0.\n",
    "        num = 0\n",
    "        if x['key_words'] == []:\n",
    "            return 0.\n",
    "        else:\n",
    "            for i in range(len(x['key_words'])-1):\n",
    "                w1, w2 = list(x['key_words'])[i], x['d1']\n",
    "                if w1 not in w2v.wv.vocab or w2 not in w2v.wv.vocab:\n",
    "                    return 0\n",
    "                w1, w2 = w2v.wv[w1], w2v.wv[w2]\n",
    "                dist = distance(w1, w2)\n",
    "                if method == \"pearson_cor\":\n",
    "                    dist = dist[0]\n",
    "                elif method == \"pearson_pvalue\":\n",
    "                    dist = dist[1]\n",
    "                cos += dist\n",
    "                num += 1\n",
    "        return cos/num if num > 0 else 0\n",
    "        \n",
    "    data['d1_key_words'] = data.apply(lambda x: extractor(x), axis=1)\n",
    "    # è·ç¦»åº¦é‡ç³»åˆ—ï¼šä½™å¼¦ç›¸ä¼¼åº¦ã€æ¬§æ°è·ç¦»ã€çš®å°”é€Šç›¸å…³ç³»æ•°\n",
    "    data['ww_cosine'] =  data.apply(lambda x: ww_(x, method=\"cosine\"), axis=1)\n",
    "    data['ww_euclidean'] = data.apply(lambda x: ww_(x, method=\"euclidean\"), axis=1)\n",
    "    data['ww_inner_product'] = data.apply(lambda x: ww_(x, method=\"\"), axis=1)\n",
    "    data['ww_pearson_cor'] = data.apply(lambda x: ww_(x, method=\"pearson_cor\"), axis=1)\n",
    "    data['ww_pearson_pvalue'] = data.apply(lambda x: ww_(x, method=\"pearson_pvalue\"), axis=1)\n",
    "    \n",
    "    # è®¡ç®—å…³é”®è¯ä¸æ–‡æ¡£å‘é‡çš„è·ç¦»\n",
    "\n",
    "distance_calc(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…±ç°çŸ©é˜µå’Œç›¸ä¼¼çŸ©é˜µçš„æ„å»º\n",
    "coocurance = np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>d1</th>\n",
       "      <th>rid</th>\n",
       "      <th>d2</th>\n",
       "      <th>label</th>\n",
       "      <th>d1_word_cut</th>\n",
       "      <th>d2_word_cut</th>\n",
       "      <th>d1_pos_tag</th>\n",
       "      <th>d2_pos_tag</th>\n",
       "      <th>shared_words</th>\n",
       "      <th>...</th>\n",
       "      <th>max_tfidf_sim</th>\n",
       "      <th>mean_tfidf_sim</th>\n",
       "      <th>max_textrank_sim</th>\n",
       "      <th>mean_textrank_sim</th>\n",
       "      <th>d1_key_words</th>\n",
       "      <th>ww_cosine</th>\n",
       "      <th>ww_euclidean</th>\n",
       "      <th>ww_inner_product</th>\n",
       "      <th>ww_pearson_cor</th>\n",
       "      <th>ww_pearson_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>0</td>\n",
       "      <td>æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºï¼Œæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡ã€‚</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[é‡‡è·, ä¸€å°, æ˜¯, åˆ†æ ¡, å§]</td>\n",
       "      <td>[æ­å·å¸‚, é‡‡è·, ç¬¬ä¸€, å°å­¦, é’±æ±Ÿè‹‘, æ ¡åŒº, ï¼Œ, æ­å·å¸‚, é’±æ±Ÿ, æ–°åŸ, å®éªŒå­¦...</td>\n",
       "      <td>[nr, d, v, n, y]</td>\n",
       "      <td>[ns, nr, m, n, nr, n, x, ns, nr, ns, n, x]</td>\n",
       "      <td>[é‡‡è·]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.316487</td>\n",
       "      <td>1.666371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667346</td>\n",
       "      <td>{ä¸€å°, åˆ†æ ¡}</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>6.525649</td>\n",
       "      <td>35.439222</td>\n",
       "      <td>0.721577</td>\n",
       "      <td>1.503320e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯çš„</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[é‡‡è·, ä¸€å°, æ˜¯, åˆ†æ ¡, å§]</td>\n",
       "      <td>[æ˜¯, çš„]</td>\n",
       "      <td>[nr, d, v, n, y]</td>\n",
       "      <td>[v, uj]</td>\n",
       "      <td>[æ˜¯]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600099</td>\n",
       "      <td>4.244596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{ä¸€å°, åˆ†æ ¡}</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>6.326831</td>\n",
       "      <td>72.129395</td>\n",
       "      <td>0.814207</td>\n",
       "      <td>2.414553e-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§</td>\n",
       "      <td>2</td>\n",
       "      <td>è¿™æ˜¯5æ¥¼</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[é‡‡è·, ä¸€å°, æ˜¯, åˆ†æ ¡, å§]</td>\n",
       "      <td>[è¿™æ˜¯, 5, æ¥¼]</td>\n",
       "      <td>[nr, d, v, n, y]</td>\n",
       "      <td>[r, v, m, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600099</td>\n",
       "      <td>4.244596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{ä¸€å°, åˆ†æ ¡}</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>6.326831</td>\n",
       "      <td>72.129395</td>\n",
       "      <td>0.814207</td>\n",
       "      <td>2.414553e-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·çš„å°‘</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[æ¯›å¯, å—, ï¼Ÿ]</td>\n",
       "      <td>[å› ä¸º, å…¬ç§¯é‡‘, è´·æ¬¾, è´·, çš„, å°‘]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[c, n, n, v, uj, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.730876</td>\n",
       "      <td>2.803282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{æ¯›å¯}</td>\n",
       "      <td>0.358034</td>\n",
       "      <td>9.279583</td>\n",
       "      <td>28.669621</td>\n",
       "      <td>0.357980</td>\n",
       "      <td>1.464102e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>æ˜¯å‘¢</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[æ¯›å¯, å—, ï¼Ÿ]</td>\n",
       "      <td>[æ˜¯, å‘¢]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[v, y]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>11.192627</td>\n",
       "      <td>11.192627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{æ¯›å¯}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>2</td>\n",
       "      <td>è¿™å¥—ä¸€æ¥¼å¸¦é™¢çš„ï¼Œæ‚¨çœ‹çœ‹</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[æ¯›å¯, å—, ï¼Ÿ]</td>\n",
       "      <td>[è¿™å¥—, ä¸€æ¥¼, å¸¦é™¢, çš„, ï¼Œ, æ‚¨, çœ‹çœ‹]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[r, q, n, n, uj, x, zg, v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.988692</td>\n",
       "      <td>2.705259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{æ¯›å¯}</td>\n",
       "      <td>0.261414</td>\n",
       "      <td>8.436319</td>\n",
       "      <td>9.165813</td>\n",
       "      <td>0.264155</td>\n",
       "      <td>2.499604e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>3</td>\n",
       "      <td>æˆ¿æœ¬éƒ½æ˜¯äº”å¹´å¤–çš„</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[æ¯›å¯, å—, ï¼Ÿ]</td>\n",
       "      <td>[æˆ¿æœ¬, éƒ½, æ˜¯, äº”å¹´, å¤–, çš„]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[n, d, v, t, f, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984923</td>\n",
       "      <td>3.291877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{æ¯›å¯}</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>11.473662</td>\n",
       "      <td>14.102968</td>\n",
       "      <td>0.188384</td>\n",
       "      <td>1.006249e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>æ¯›å¯å—ï¼Ÿ</td>\n",
       "      <td>4</td>\n",
       "      <td>å¥½çš„??ï¼Œæ‚¨å…ˆçœ‹ä¸‹</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[æ¯›å¯, å—, ï¼Ÿ]</td>\n",
       "      <td>[å¥½, çš„, ?, ?, ï¼Œ, æ‚¨, å…ˆ, çœ‹, ä¸‹]</td>\n",
       "      <td>[n, y, x]</td>\n",
       "      <td>[a, uj, x, x, x, r, d, v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>5.596314</td>\n",
       "      <td>5.580179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{æ¯›å¯}</td>\n",
       "      <td>0.068315</td>\n",
       "      <td>9.121356</td>\n",
       "      <td>3.014279</td>\n",
       "      <td>0.068243</td>\n",
       "      <td>2.386186e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚</td>\n",
       "      <td>0</td>\n",
       "      <td>æ‚¨æ˜¯é¦–å¥—è¿˜æ˜¯äºŒå¥—å‘¢ï¼Ÿ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]</td>\n",
       "      <td>[æ‚¨, æ˜¯, é¦–å¥—, è¿˜æ˜¯, äºŒå¥—, å‘¢, ï¼Ÿ]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[r, v, m, c, m, y, x]</td>\n",
       "      <td>[æ˜¯]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.263268</td>\n",
       "      <td>2.675451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{å¤§çº¦, ä½£é‡‘, å¥‘ç¨}</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>8.677430</td>\n",
       "      <td>25.828073</td>\n",
       "      <td>0.451183</td>\n",
       "      <td>3.532106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚</td>\n",
       "      <td>1</td>\n",
       "      <td>æ‰€æœ‰è´¹ç”¨ä¸‹æ¥654ä¸‡</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]</td>\n",
       "      <td>[æ‰€æœ‰, è´¹ç”¨, ä¸‹æ¥, 654, ä¸‡]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[b, n, t, m, m]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631634</td>\n",
       "      <td>1.358860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.779548</td>\n",
       "      <td>{å¤§çº¦, ä½£é‡‘, å¥‘ç¨}</td>\n",
       "      <td>0.399413</td>\n",
       "      <td>10.100416</td>\n",
       "      <td>31.169064</td>\n",
       "      <td>0.399436</td>\n",
       "      <td>4.351321e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚</td>\n",
       "      <td>2</td>\n",
       "      <td>åŒ…å«ç€ç¨è´¹å’Œæˆ‘ä»¬çš„æœåŠ¡è´¹å’Œæˆ¿æ¬¾</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]</td>\n",
       "      <td>[åŒ…å«, ç€, ç¨è´¹, å’Œ, æˆ‘ä»¬, çš„, æœåŠ¡è´¹, å’Œ, æˆ¿æ¬¾]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[v, uz, n, c, r, uj, n, c, n]</td>\n",
       "      <td>[å’Œ]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.514977</td>\n",
       "      <td>1.448768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923581</td>\n",
       "      <td>{å¤§çº¦, ä½£é‡‘, å¥‘ç¨}</td>\n",
       "      <td>0.443351</td>\n",
       "      <td>8.748080</td>\n",
       "      <td>30.491407</td>\n",
       "      <td>0.443521</td>\n",
       "      <td>1.142209e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚</td>\n",
       "      <td>3</td>\n",
       "      <td>å¥½çš„</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]</td>\n",
       "      <td>[å¥½, çš„]</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[a, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.263268</td>\n",
       "      <td>2.675451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{å¤§çº¦, ä½£é‡‘, å¥‘ç¨}</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>8.677430</td>\n",
       "      <td>25.828073</td>\n",
       "      <td>0.451183</td>\n",
       "      <td>3.532106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚</td>\n",
       "      <td>4</td>\n",
       "      <td>é“¾å®¶å¤©é¸¿ç¾åŸŸåº—NAMEï¼Œç”µè¯æ˜¯PHONEï¼ˆåŒå¾®ä¿¡å·ï¼‰ï¼Œéšæ—¶è”ç³»?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]</td>\n",
       "      <td>[é“¾å®¶, å¤©é¸¿ç¾åŸŸ, åº—, NAME, ï¼Œ, ç”µè¯, æ˜¯, PHONE, ï¼ˆ, åŒå¾®, ä¿¡å·...</td>\n",
       "      <td>[r, uj, n, v, d, v, m, c, n, v, m, x]</td>\n",
       "      <td>[n, nr, ns, n, eng, x, n, v, eng, x, d, n, x, ...</td>\n",
       "      <td>[æ˜¯]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864473</td>\n",
       "      <td>{å¤§çº¦, ä½£é‡‘, å¥‘ç¨}</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>12.927756</td>\n",
       "      <td>28.974901</td>\n",
       "      <td>0.167511</td>\n",
       "      <td>1.158997e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>é è¿‘å·æ²™è·¯å˜›ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>æ­£å¸¸é“¶è¡Œè´·æ¬¾ï¼Œå¯ä»¥è‡ªå·±è¿˜çš„</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[é è¿‘, å·æ²™, è·¯, å˜›, ï¼Ÿ]</td>\n",
       "      <td>[æ­£å¸¸, é“¶è¡Œè´·æ¬¾, ï¼Œ, å¯ä»¥, è‡ªå·±, è¿˜, çš„]</td>\n",
       "      <td>[v, ns, n, y, x]</td>\n",
       "      <td>[d, n, x, c, r, d, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.304637</td>\n",
       "      <td>2.081506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998044</td>\n",
       "      <td>{é è¿‘, å·æ²™}</td>\n",
       "      <td>0.399596</td>\n",
       "      <td>7.959680</td>\n",
       "      <td>6.335780</td>\n",
       "      <td>0.399047</td>\n",
       "      <td>5.580720e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>é è¿‘å·æ²™è·¯å˜›ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>æœ‰ä¸€ç‚¹é è¿‘å·æ²™è·¯</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[é è¿‘, å·æ²™, è·¯, å˜›, ï¼Ÿ]</td>\n",
       "      <td>[æœ‰, ä¸€ç‚¹, é è¿‘, å·æ²™, è·¯]</td>\n",
       "      <td>[v, ns, n, y, x]</td>\n",
       "      <td>[v, m, v, ns, n]</td>\n",
       "      <td>[é è¿‘, å·æ²™, è·¯]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.609273</td>\n",
       "      <td>4.165221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{é è¿‘, å·æ²™}</td>\n",
       "      <td>0.633462</td>\n",
       "      <td>10.497736</td>\n",
       "      <td>13.216286</td>\n",
       "      <td>0.632798</td>\n",
       "      <td>5.739747e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>é è¿‘å·æ²™è·¯å˜›ï¼Ÿ</td>\n",
       "      <td>2</td>\n",
       "      <td>åªæœ‰é‚£ä¸€å¥—æ¯›å¯çš„ä¸é è¿‘å·æ²™è·¯</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[é è¿‘, å·æ²™, è·¯, å˜›, ï¼Ÿ]</td>\n",
       "      <td>[åªæœ‰, é‚£, ä¸€å¥—, æ¯›å¯, çš„, ä¸, é è¿‘, å·æ²™, è·¯]</td>\n",
       "      <td>[v, ns, n, y, x]</td>\n",
       "      <td>[c, r, m, n, uj, a, v, ns, n]</td>\n",
       "      <td>[é è¿‘, å·æ²™, è·¯]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.687419</td>\n",
       "      <td>2.967627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.890709</td>\n",
       "      <td>{é è¿‘, å·æ²™}</td>\n",
       "      <td>0.270723</td>\n",
       "      <td>10.317979</td>\n",
       "      <td>6.199821</td>\n",
       "      <td>0.270414</td>\n",
       "      <td>1.561286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´å—ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>æœ‰</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, å—, ï¼Ÿ]</td>\n",
       "      <td>[æœ‰]</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609121</td>\n",
       "      <td>1.337969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994260</td>\n",
       "      <td>{ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}</td>\n",
       "      <td>0.419433</td>\n",
       "      <td>8.040307</td>\n",
       "      <td>24.576616</td>\n",
       "      <td>0.416502</td>\n",
       "      <td>4.217419e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´å—ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>æ²³è¥¿åŒºæµ·æ²³æ²¿çº¿çš„æ–°æˆ¿ï¼Œå‡ä»·30000ï¼Œå¸¦è£…ä¿®ï¼Œçœ‹çœ‹å»å—ï¼Œä¼˜æƒ ç‚¹ä½å¾ˆå¤§ï¼Œäº”ä¸€ç‰¹æƒ </td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, å—, ï¼Ÿ]</td>\n",
       "      <td>[æ²³è¥¿åŒº, æµ·æ²³, æ²¿çº¿, çš„, æ–°æˆ¿, ï¼Œ, å‡ä»·, 30000, ï¼Œ, å¸¦, è£…ä¿®, ï¼Œ...</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[ns, ns, f, uj, n, x, n, m, x, v, v, x, v, v, ...</td>\n",
       "      <td>[ä¼˜æƒ ]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899475</td>\n",
       "      <td>0.778574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715349</td>\n",
       "      <td>{ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}</td>\n",
       "      <td>0.264608</td>\n",
       "      <td>6.754923</td>\n",
       "      <td>1.012900</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>2.011383e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´å—ï¼Ÿ</td>\n",
       "      <td>2</td>\n",
       "      <td>å®¾æ°´é‡Œï¼Œè‚¿ç˜¤åŒ»é™¢åœ°é“5-6å·çº¿æ—ï¼Œç§äº§è¿‡äº”å¹´å”¯ä¸€ï¼Œ3æ¥¼ï¼Œå—åŒ—é€šé€åç‹¬ï¼Œä¸šä¸»ç€æ€¥å–ï¼Œçœ‹æˆ¿æœ‰é’¥åŒ™</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, å—, ï¼Ÿ]</td>\n",
       "      <td>[å®¾æ°´é‡Œ, ï¼Œ, è‚¿ç˜¤åŒ»é™¢, åœ°é“, 5, -, 6, å·çº¿, æ—, ï¼Œ, ç§äº§, è¿‡, äº”...</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[n, f, x, n, n, x, x, m, n, f, x, n, ug, t, b,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664154</td>\n",
       "      <td>0.664154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936278</td>\n",
       "      <td>{ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>9.966531</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.040875</td>\n",
       "      <td>1.540320e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>è¿™ä¸ªç¨å¤šå°‘é’±</td>\n",
       "      <td>0</td>\n",
       "      <td>æ‚¨çœ‹çœ‹è¿™ä¸ª</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™ä¸ª, ç¨, å¤šå°‘, é’±]</td>\n",
       "      <td>[æ‚¨, çœ‹çœ‹, è¿™ä¸ª]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[zg, v, r]</td>\n",
       "      <td>[è¿™ä¸ª]</td>\n",
       "      <td>...</td>\n",
       "      <td>5.410445</td>\n",
       "      <td>5.410445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{å¤šå°‘}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>è¿™ä¸ªç¨å¤šå°‘é’±</td>\n",
       "      <td>1</td>\n",
       "      <td>13æ¥¼ï¼Œç²¾è£…ä¿®çš„/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™ä¸ª, ç¨, å¤šå°‘, é’±]</td>\n",
       "      <td>[13, æ¥¼, ï¼Œ, ç²¾è£…ä¿®, çš„, /,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[m, n, x, l, uj, x, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>11.261620</td>\n",
       "      <td>11.261620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{å¤šå°‘}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>è¿™ä¸ªç¨å¤šå°‘é’±</td>\n",
       "      <td>2</td>\n",
       "      <td>æ‚¨ç°åœ¨æ–¹ä¾¿å—</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™ä¸ª, ç¨, å¤šå°‘, é’±]</td>\n",
       "      <td>[æ‚¨, ç°åœ¨, æ–¹ä¾¿, å—,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[zg, t, a, y, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.150388</td>\n",
       "      <td>2.563631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{å¤šå°‘}</td>\n",
       "      <td>0.103222</td>\n",
       "      <td>9.581085</td>\n",
       "      <td>4.513747</td>\n",
       "      <td>0.101286</td>\n",
       "      <td>7.985726e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>è¿™ä¸ªç¨å¤šå°‘é’±</td>\n",
       "      <td>3</td>\n",
       "      <td>å¯ä»¥å…ˆçº¿ä¸Šå¸¦æ‚¨çœ‹ä¸€ä¸‹</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™ä¸ª, ç¨, å¤šå°‘, é’±]</td>\n",
       "      <td>[å¯ä»¥, å…ˆçº¿, ä¸Š, å¸¦, æ‚¨, çœ‹, ä¸€ä¸‹,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[c, n, f, v, r, v, m, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>11.954768</td>\n",
       "      <td>11.954768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{å¤šå°‘}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>è¿™ä¸ªç¨å¤šå°‘é’±</td>\n",
       "      <td>4</td>\n",
       "      <td>æ‚¨ç¨ç­‰ä¸€ä¸‹ï¼Œç»™æ‚¨å‘é“¾æ¥æ‚¨ç‚¹è¿›æ¥å°±è¡Œ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™ä¸ª, ç¨, å¤šå°‘, é’±]</td>\n",
       "      <td>[æ‚¨, ç¨ç­‰ä¸€ä¸‹, ï¼Œ, ç»™, æ‚¨, å‘, é“¾æ¥, æ‚¨, ç‚¹, è¿›æ¥, å°±è¡Œ,  ]</td>\n",
       "      <td>[r, n, m, n]</td>\n",
       "      <td>[zg, l, x, p, r, v, n, r, q, v, d, v, x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984923</td>\n",
       "      <td>2.933870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{å¤šå°‘}</td>\n",
       "      <td>0.669373</td>\n",
       "      <td>4.903178</td>\n",
       "      <td>21.826728</td>\n",
       "      <td>0.670483</td>\n",
       "      <td>6.181808e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´ä¹ˆï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>ä»·æ ¼å‘¨æœŸå¯è°ˆ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, ä¹ˆ, ï¼Ÿ]</td>\n",
       "      <td>[ä»·æ ¼, å‘¨æœŸ, å¯è°ˆ]</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[n, t, v]</td>\n",
       "      <td>[ä»·æ ¼]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.494346</td>\n",
       "      <td>1.212245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.709042</td>\n",
       "      <td>{ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}</td>\n",
       "      <td>0.364859</td>\n",
       "      <td>8.025300</td>\n",
       "      <td>18.749713</td>\n",
       "      <td>0.361521</td>\n",
       "      <td>4.323876e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´ä¹ˆï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>æ‚¨å¥½</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, ä¹ˆ, ï¼Ÿ]</td>\n",
       "      <td>[æ‚¨å¥½]</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[l]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455032</td>\n",
       "      <td>1.306770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>{ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}</td>\n",
       "      <td>0.299576</td>\n",
       "      <td>10.032229</td>\n",
       "      <td>18.581886</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>1.127904e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´ä¹ˆï¼Ÿ</td>\n",
       "      <td>2</td>\n",
       "      <td>æ‚¨å¥½ï¼Œæ‚¨ä¹‹å‰å’¨è¯¢çš„æˆ¿æºæˆ·å‹å¾ˆä¼˜è´¨ï¼Œæ‚¨æœ‰æ—¶é—´å»çœ‹çœ‹å—ï¼Ÿ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, ä¹ˆ, ï¼Ÿ]</td>\n",
       "      <td>[æ‚¨å¥½, ï¼Œ, æ‚¨, ä¹‹å‰, å’¨è¯¢, çš„, æˆ¿æº, æˆ·å‹, å¾ˆ, ä¼˜è´¨, ï¼Œ, æ‚¨, æœ‰, ...</td>\n",
       "      <td>[r, n, ng, n, v, vn, n, y, x]</td>\n",
       "      <td>[l, x, zg, f, vn, uj, n, n, zg, n, x, r, v, n,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722294</td>\n",
       "      <td>0.691560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>{ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>11.781522</td>\n",
       "      <td>45.625881</td>\n",
       "      <td>0.374266</td>\n",
       "      <td>1.298957e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>æœ‰æˆ¿å­å¯ä»¥å¸¦æˆ‘çœ‹çœ‹å—ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>å®¾è‡³è·¯æœ‰å¥—82å¹³æ–¹çš„</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[æœ‰, æˆ¿å­, å¯ä»¥, å¸¦, æˆ‘, çœ‹çœ‹, å—, ï¼Ÿ]</td>\n",
       "      <td>[å®¾è‡³è·¯, æœ‰, å¥—, 82, å¹³æ–¹, çš„]</td>\n",
       "      <td>[v, n, c, v, r, v, y, x]</td>\n",
       "      <td>[nr, v, q, m, q, uj]</td>\n",
       "      <td>[æœ‰]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.157952</td>\n",
       "      <td>2.931587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{æˆ¿å­, çœ‹çœ‹}</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>8.254086</td>\n",
       "      <td>12.487435</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>5.332867e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>æœ‰æˆ¿å­å¯ä»¥å¸¦æˆ‘çœ‹çœ‹å—ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>ç¬‹ç›˜</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[æœ‰, æˆ¿å­, å¯ä»¥, å¸¦, æˆ‘, çœ‹çœ‹, å—, ï¼Ÿ]</td>\n",
       "      <td>[ç¬‹ç›˜]</td>\n",
       "      <td>[v, n, c, v, r, v, y, x]</td>\n",
       "      <td>[n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984923</td>\n",
       "      <td>2.631235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>{æˆ¿å­, çœ‹çœ‹}</td>\n",
       "      <td>0.164922</td>\n",
       "      <td>7.227518</td>\n",
       "      <td>4.869229</td>\n",
       "      <td>0.158570</td>\n",
       "      <td>1.033444e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>æœ‰æˆ¿å­å¯ä»¥å¸¦æˆ‘çœ‹çœ‹å—ï¼Ÿ</td>\n",
       "      <td>2</td>\n",
       "      <td>å¯ä»¥å¸¦æ‚¨çœ‹ä¸€ä¸‹</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[æœ‰, æˆ¿å­, å¯ä»¥, å¸¦, æˆ‘, çœ‹çœ‹, å—, ï¼Ÿ]</td>\n",
       "      <td>[å¯ä»¥, å¸¦, æ‚¨, çœ‹, ä¸€ä¸‹]</td>\n",
       "      <td>[v, n, c, v, r, v, y, x]</td>\n",
       "      <td>[c, v, r, v, m]</td>\n",
       "      <td>[å¸¦, å¯ä»¥]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.157952</td>\n",
       "      <td>2.931587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{æˆ¿å­, çœ‹çœ‹}</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>8.254086</td>\n",
       "      <td>12.487435</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>5.332867e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>å…‰çº¿ä¸å¥½ï¼Œæ˜¯å—</td>\n",
       "      <td>0</td>\n",
       "      <td>å…‰çº¿éå¸¸å¥½ï¼Œå‹è”èŠ±å›­éƒ½æ˜¯å¯ä»¥</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[å…‰çº¿, ä¸å¥½, ï¼Œ, æ˜¯, å—]</td>\n",
       "      <td>[å…‰çº¿, éå¸¸, å¥½, ï¼Œ, å‹è”, èŠ±å›­, éƒ½, æ˜¯, å¯ä»¥]</td>\n",
       "      <td>[n, d, x, v, y]</td>\n",
       "      <td>[n, d, a, x, ns, n, d, v, c]</td>\n",
       "      <td>[å…‰çº¿, æ˜¯]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.549591</td>\n",
       "      <td>2.027951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968942</td>\n",
       "      <td>{å…‰çº¿, ä¸å¥½}</td>\n",
       "      <td>0.264109</td>\n",
       "      <td>10.832539</td>\n",
       "      <td>5.235958</td>\n",
       "      <td>0.265234</td>\n",
       "      <td>1.719930e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>å…‰çº¿ä¸å¥½ï¼Œæ˜¯å—</td>\n",
       "      <td>1</td>\n",
       "      <td>ä½ ç‚¹å¼€å›¾ç‰‡ï¼Œé€ä¸€çœ‹çœ‹</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[å…‰çº¿, ä¸å¥½, ï¼Œ, æ˜¯, å—]</td>\n",
       "      <td>[ä½ , ç‚¹å¼€, å›¾ç‰‡, ï¼Œ, é€ä¸€, çœ‹çœ‹]</td>\n",
       "      <td>[n, d, x, v, y]</td>\n",
       "      <td>[r, q, v, n, x, d, v]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.742658</td>\n",
       "      <td>1.515771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998585</td>\n",
       "      <td>{å…‰çº¿, ä¸å¥½}</td>\n",
       "      <td>0.235205</td>\n",
       "      <td>9.215364</td>\n",
       "      <td>8.099103</td>\n",
       "      <td>0.234985</td>\n",
       "      <td>2.627015e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>å…‰çº¿ä¸å¥½ï¼Œæ˜¯å—</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[å…‰çº¿, ä¸å¥½, ï¼Œ, æ˜¯, å—]</td>\n",
       "      <td>[?]</td>\n",
       "      <td>[n, d, x, v, y]</td>\n",
       "      <td>[x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.824387</td>\n",
       "      <td>3.329985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{å…‰çº¿, ä¸å¥½}</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>13.357806</td>\n",
       "      <td>10.065587</td>\n",
       "      <td>0.096629</td>\n",
       "      <td>9.480238e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>å‡ æœŸçš„ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>æ˜¯çš„</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[å‡ æœŸ, çš„, ï¼Ÿ]</td>\n",
       "      <td>[æ˜¯, çš„]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[v, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>10.904945</td>\n",
       "      <td>10.904945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{å‡ æœŸ}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9</td>\n",
       "      <td>å‡ æœŸçš„ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>è¿™ä¸ªæ˜¯äºŒæœŸçš„è€å¸ˆ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[å‡ æœŸ, çš„, ï¼Ÿ]</td>\n",
       "      <td>[è¿™ä¸ª, æ˜¯, äºŒæœŸ, çš„, è€å¸ˆ]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[r, v, b, uj, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.634982</td>\n",
       "      <td>2.866061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{å‡ æœŸ}</td>\n",
       "      <td>0.163893</td>\n",
       "      <td>8.705774</td>\n",
       "      <td>8.883473</td>\n",
       "      <td>0.165021</td>\n",
       "      <td>3.949651e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9</td>\n",
       "      <td>å‡ æœŸçš„ï¼Ÿ</td>\n",
       "      <td>2</td>\n",
       "      <td>è¿˜æœ‰çš„</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[å‡ æœŸ, çš„, ï¼Ÿ]</td>\n",
       "      <td>[è¿˜æœ‰, çš„]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[v, uj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>5.452473</td>\n",
       "      <td>3.733149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>{å‡ æœŸ}</td>\n",
       "      <td>-0.012560</td>\n",
       "      <td>9.763052</td>\n",
       "      <td>-0.586899</td>\n",
       "      <td>-0.011621</td>\n",
       "      <td>8.411273e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>å‡ æœŸçš„ï¼Ÿ</td>\n",
       "      <td>3</td>\n",
       "      <td>äºŒæœŸéƒ½åˆšä¸‹è¯ä»Šå¹´</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[å‡ æœŸ, çš„, ï¼Ÿ]</td>\n",
       "      <td>[äºŒæœŸ, éƒ½, åˆš, ä¸‹è¯, ä»Šå¹´]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[b, d, d, v, t]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.988692</td>\n",
       "      <td>2.614658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771492</td>\n",
       "      <td>{å‡ æœŸ}</td>\n",
       "      <td>0.268873</td>\n",
       "      <td>8.727287</td>\n",
       "      <td>12.534684</td>\n",
       "      <td>0.269065</td>\n",
       "      <td>1.042334e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>å‡ æœŸçš„ï¼Ÿ</td>\n",
       "      <td>4</td>\n",
       "      <td>ä¸€æœŸçš„æœ‰å…ç¨çš„äº†</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[å‡ æœŸ, çš„, ï¼Ÿ]</td>\n",
       "      <td>[ä¸€æœŸ, çš„, æœ‰, å…ç¨, çš„, äº†]</td>\n",
       "      <td>[d, uj, x]</td>\n",
       "      <td>[d, uj, v, v, uj, ul]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>3.634982</td>\n",
       "      <td>3.029338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.669574</td>\n",
       "      <td>{å‡ æœŸ}</td>\n",
       "      <td>0.233220</td>\n",
       "      <td>7.210079</td>\n",
       "      <td>9.234592</td>\n",
       "      <td>0.232988</td>\n",
       "      <td>1.309377e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10</td>\n",
       "      <td>ä»€ä¹ˆæƒ…å†µå‘¢ï¼Ÿ</td>\n",
       "      <td>0</td>\n",
       "      <td>æˆ‘ä»¬ä¸‹ç­æ¯”è¾ƒæ™šï¼Œç°åœ¨ä¹Ÿèƒ½çœ‹æˆ¿</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ä»€ä¹ˆ, æƒ…å†µ, å‘¢, ï¼Ÿ]</td>\n",
       "      <td>[æˆ‘ä»¬, ä¸‹ç­, æ¯”è¾ƒ, æ™š, ï¼Œ, ç°åœ¨, ä¹Ÿ, èƒ½, çœ‹æˆ¿]</td>\n",
       "      <td>[r, n, y, x]</td>\n",
       "      <td>[r, v, d, tg, x, t, d, v, v, n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>2.087900</td>\n",
       "      <td>1.427551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996560</td>\n",
       "      <td>{æƒ…å†µ}</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>9.733622</td>\n",
       "      <td>6.152428</td>\n",
       "      <td>0.133468</td>\n",
       "      <td>1.429926e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>ä»€ä¹ˆæƒ…å†µå‘¢ï¼Ÿ</td>\n",
       "      <td>1</td>\n",
       "      <td>å“¦</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ä»€ä¹ˆ, æƒ…å†µ, å‘¢, ï¼Ÿ]</td>\n",
       "      <td>[å“¦]</td>\n",
       "      <td>[r, n, y, x]</td>\n",
       "      <td>[zg]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>4.007240</td>\n",
       "      <td>4.007240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{æƒ…å†µ}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cid                  d1  rid  \\\n",
       "0     0            é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    0   \n",
       "1     0            é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    1   \n",
       "2     0            é‡‡è·ä¸€å°æ˜¯åˆ†æ ¡å§    2   \n",
       "3     1                æ¯›å¯å—ï¼Ÿ    0   \n",
       "4     1                æ¯›å¯å—ï¼Ÿ    1   \n",
       "5     1                æ¯›å¯å—ï¼Ÿ    2   \n",
       "6     1                æ¯›å¯å—ï¼Ÿ    3   \n",
       "7     1                æ¯›å¯å—ï¼Ÿ    4   \n",
       "8     2  ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚    0   \n",
       "9     2  ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚    1   \n",
       "10    2  ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚    2   \n",
       "11    2  ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚    3   \n",
       "12    2  ä½ ä»¬çš„ä½£é‡‘è´¹å¤§çº¦æ˜¯å¤šå°‘å’Œå¥‘ç¨æ˜¯å¤šå°‘ã€‚    4   \n",
       "13    3             é è¿‘å·æ²™è·¯å˜›ï¼Ÿ    0   \n",
       "14    3             é è¿‘å·æ²™è·¯å˜›ï¼Ÿ    1   \n",
       "15    3             é è¿‘å·æ²™è·¯å˜›ï¼Ÿ    2   \n",
       "16    4      è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´å—ï¼Ÿ    0   \n",
       "17    4      è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´å—ï¼Ÿ    1   \n",
       "18    4      è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´å—ï¼Ÿ    2   \n",
       "19    5              è¿™ä¸ªç¨å¤šå°‘é’±    0   \n",
       "20    5              è¿™ä¸ªç¨å¤šå°‘é’±    1   \n",
       "21    5              è¿™ä¸ªç¨å¤šå°‘é’±    2   \n",
       "22    5              è¿™ä¸ªç¨å¤šå°‘é’±    3   \n",
       "23    5              è¿™ä¸ªç¨å¤šå°‘é’±    4   \n",
       "24    6      è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´ä¹ˆï¼Ÿ    0   \n",
       "25    6      è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´ä¹ˆï¼Ÿ    1   \n",
       "26    6      è¿™å¥—æˆ¿æºä»·æ ¼è¿˜æœ‰ä¼˜æƒ ç©ºé—´ä¹ˆï¼Ÿ    2   \n",
       "27    7         æœ‰æˆ¿å­å¯ä»¥å¸¦æˆ‘çœ‹çœ‹å—ï¼Ÿ    0   \n",
       "28    7         æœ‰æˆ¿å­å¯ä»¥å¸¦æˆ‘çœ‹çœ‹å—ï¼Ÿ    1   \n",
       "29    7         æœ‰æˆ¿å­å¯ä»¥å¸¦æˆ‘çœ‹çœ‹å—ï¼Ÿ    2   \n",
       "30    8             å…‰çº¿ä¸å¥½ï¼Œæ˜¯å—    0   \n",
       "31    8             å…‰çº¿ä¸å¥½ï¼Œæ˜¯å—    1   \n",
       "32    8             å…‰çº¿ä¸å¥½ï¼Œæ˜¯å—    2   \n",
       "33    9                å‡ æœŸçš„ï¼Ÿ    0   \n",
       "34    9                å‡ æœŸçš„ï¼Ÿ    1   \n",
       "35    9                å‡ æœŸçš„ï¼Ÿ    2   \n",
       "36    9                å‡ æœŸçš„ï¼Ÿ    3   \n",
       "37    9                å‡ æœŸçš„ï¼Ÿ    4   \n",
       "38   10              ä»€ä¹ˆæƒ…å†µå‘¢ï¼Ÿ    0   \n",
       "39   10              ä»€ä¹ˆæƒ…å†µå‘¢ï¼Ÿ    1   \n",
       "\n",
       "                                                d2  label  \\\n",
       "0                      æ­å·å¸‚é‡‡è·ç¬¬ä¸€å°å­¦é’±æ±Ÿè‹‘æ ¡åŒºï¼Œæ­å·å¸‚é’±æ±Ÿæ–°åŸå®éªŒå­¦æ ¡ã€‚    1.0   \n",
       "1                                               æ˜¯çš„    0.0   \n",
       "2                                             è¿™æ˜¯5æ¥¼    0.0   \n",
       "3                                       å› ä¸ºå…¬ç§¯é‡‘è´·æ¬¾è´·çš„å°‘    0.0   \n",
       "4                                               æ˜¯å‘¢    0.0   \n",
       "5                                      è¿™å¥—ä¸€æ¥¼å¸¦é™¢çš„ï¼Œæ‚¨çœ‹çœ‹    0.0   \n",
       "6                                         æˆ¿æœ¬éƒ½æ˜¯äº”å¹´å¤–çš„    0.0   \n",
       "7                                        å¥½çš„??ï¼Œæ‚¨å…ˆçœ‹ä¸‹    0.0   \n",
       "8                                       æ‚¨æ˜¯é¦–å¥—è¿˜æ˜¯äºŒå¥—å‘¢ï¼Ÿ    0.0   \n",
       "9                                       æ‰€æœ‰è´¹ç”¨ä¸‹æ¥654ä¸‡    1.0   \n",
       "10                                 åŒ…å«ç€ç¨è´¹å’Œæˆ‘ä»¬çš„æœåŠ¡è´¹å’Œæˆ¿æ¬¾    1.0   \n",
       "11                                              å¥½çš„    0.0   \n",
       "12                é“¾å®¶å¤©é¸¿ç¾åŸŸåº—NAMEï¼Œç”µè¯æ˜¯PHONEï¼ˆåŒå¾®ä¿¡å·ï¼‰ï¼Œéšæ—¶è”ç³»?    0.0   \n",
       "13                                   æ­£å¸¸é“¶è¡Œè´·æ¬¾ï¼Œå¯ä»¥è‡ªå·±è¿˜çš„    0.0   \n",
       "14                                        æœ‰ä¸€ç‚¹é è¿‘å·æ²™è·¯    1.0   \n",
       "15                                  åªæœ‰é‚£ä¸€å¥—æ¯›å¯çš„ä¸é è¿‘å·æ²™è·¯    0.0   \n",
       "16                                               æœ‰    1.0   \n",
       "17         æ²³è¥¿åŒºæµ·æ²³æ²¿çº¿çš„æ–°æˆ¿ï¼Œå‡ä»·30000ï¼Œå¸¦è£…ä¿®ï¼Œçœ‹çœ‹å»å—ï¼Œä¼˜æƒ ç‚¹ä½å¾ˆå¤§ï¼Œäº”ä¸€ç‰¹æƒ     0.0   \n",
       "18  å®¾æ°´é‡Œï¼Œè‚¿ç˜¤åŒ»é™¢åœ°é“5-6å·çº¿æ—ï¼Œç§äº§è¿‡äº”å¹´å”¯ä¸€ï¼Œ3æ¥¼ï¼Œå—åŒ—é€šé€åç‹¬ï¼Œä¸šä¸»ç€æ€¥å–ï¼Œçœ‹æˆ¿æœ‰é’¥åŒ™    0.0   \n",
       "19                                           æ‚¨çœ‹çœ‹è¿™ä¸ª    0.0   \n",
       "20                                      13æ¥¼ï¼Œç²¾è£…ä¿®çš„/     0.0   \n",
       "21                                         æ‚¨ç°åœ¨æ–¹ä¾¿å—     0.0   \n",
       "22                                     å¯ä»¥å…ˆçº¿ä¸Šå¸¦æ‚¨çœ‹ä¸€ä¸‹     0.0   \n",
       "23                              æ‚¨ç¨ç­‰ä¸€ä¸‹ï¼Œç»™æ‚¨å‘é“¾æ¥æ‚¨ç‚¹è¿›æ¥å°±è¡Œ     0.0   \n",
       "24                                          ä»·æ ¼å‘¨æœŸå¯è°ˆ    1.0   \n",
       "25                                              æ‚¨å¥½    0.0   \n",
       "26                      æ‚¨å¥½ï¼Œæ‚¨ä¹‹å‰å’¨è¯¢çš„æˆ¿æºæˆ·å‹å¾ˆä¼˜è´¨ï¼Œæ‚¨æœ‰æ—¶é—´å»çœ‹çœ‹å—ï¼Ÿ    0.0   \n",
       "27                                      å®¾è‡³è·¯æœ‰å¥—82å¹³æ–¹çš„    1.0   \n",
       "28                                              ç¬‹ç›˜    1.0   \n",
       "29                                         å¯ä»¥å¸¦æ‚¨çœ‹ä¸€ä¸‹    1.0   \n",
       "30                                  å…‰çº¿éå¸¸å¥½ï¼Œå‹è”èŠ±å›­éƒ½æ˜¯å¯ä»¥    1.0   \n",
       "31                                      ä½ ç‚¹å¼€å›¾ç‰‡ï¼Œé€ä¸€çœ‹çœ‹    0.0   \n",
       "32                                               ?    0.0   \n",
       "33                                              æ˜¯çš„    0.0   \n",
       "34                                        è¿™ä¸ªæ˜¯äºŒæœŸçš„è€å¸ˆ    1.0   \n",
       "35                                             è¿˜æœ‰çš„    0.0   \n",
       "36                                        äºŒæœŸéƒ½åˆšä¸‹è¯ä»Šå¹´    0.0   \n",
       "37                                        ä¸€æœŸçš„æœ‰å…ç¨çš„äº†    0.0   \n",
       "38                                  æˆ‘ä»¬ä¸‹ç­æ¯”è¾ƒæ™šï¼Œç°åœ¨ä¹Ÿèƒ½çœ‹æˆ¿    0.0   \n",
       "39                                               å“¦    0.0   \n",
       "\n",
       "                                   d1_word_cut  \\\n",
       "0                           [é‡‡è·, ä¸€å°, æ˜¯, åˆ†æ ¡, å§]   \n",
       "1                           [é‡‡è·, ä¸€å°, æ˜¯, åˆ†æ ¡, å§]   \n",
       "2                           [é‡‡è·, ä¸€å°, æ˜¯, åˆ†æ ¡, å§]   \n",
       "3                                   [æ¯›å¯, å—, ï¼Ÿ]   \n",
       "4                                   [æ¯›å¯, å—, ï¼Ÿ]   \n",
       "5                                   [æ¯›å¯, å—, ï¼Ÿ]   \n",
       "6                                   [æ¯›å¯, å—, ï¼Ÿ]   \n",
       "7                                   [æ¯›å¯, å—, ï¼Ÿ]   \n",
       "8   [ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]   \n",
       "9   [ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]   \n",
       "10  [ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]   \n",
       "11  [ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]   \n",
       "12  [ä½ ä»¬, çš„, ä½£é‡‘, è´¹, å¤§çº¦, æ˜¯, å¤šå°‘, å’Œ, å¥‘ç¨, æ˜¯, å¤šå°‘, ã€‚]   \n",
       "13                           [é è¿‘, å·æ²™, è·¯, å˜›, ï¼Ÿ]   \n",
       "14                           [é è¿‘, å·æ²™, è·¯, å˜›, ï¼Ÿ]   \n",
       "15                           [é è¿‘, å·æ²™, è·¯, å˜›, ï¼Ÿ]   \n",
       "16            [è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, å—, ï¼Ÿ]   \n",
       "17            [è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, å—, ï¼Ÿ]   \n",
       "18            [è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, å—, ï¼Ÿ]   \n",
       "19                              [è¿™ä¸ª, ç¨, å¤šå°‘, é’±]   \n",
       "20                              [è¿™ä¸ª, ç¨, å¤šå°‘, é’±]   \n",
       "21                              [è¿™ä¸ª, ç¨, å¤šå°‘, é’±]   \n",
       "22                              [è¿™ä¸ª, ç¨, å¤šå°‘, é’±]   \n",
       "23                              [è¿™ä¸ª, ç¨, å¤šå°‘, é’±]   \n",
       "24            [è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, ä¹ˆ, ï¼Ÿ]   \n",
       "25            [è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, ä¹ˆ, ï¼Ÿ]   \n",
       "26            [è¿™, å¥—æˆ¿, æº, ä»·æ ¼, è¿˜æœ‰, ä¼˜æƒ , ç©ºé—´, ä¹ˆ, ï¼Ÿ]   \n",
       "27                 [æœ‰, æˆ¿å­, å¯ä»¥, å¸¦, æˆ‘, çœ‹çœ‹, å—, ï¼Ÿ]   \n",
       "28                 [æœ‰, æˆ¿å­, å¯ä»¥, å¸¦, æˆ‘, çœ‹çœ‹, å—, ï¼Ÿ]   \n",
       "29                 [æœ‰, æˆ¿å­, å¯ä»¥, å¸¦, æˆ‘, çœ‹çœ‹, å—, ï¼Ÿ]   \n",
       "30                           [å…‰çº¿, ä¸å¥½, ï¼Œ, æ˜¯, å—]   \n",
       "31                           [å…‰çº¿, ä¸å¥½, ï¼Œ, æ˜¯, å—]   \n",
       "32                           [å…‰çº¿, ä¸å¥½, ï¼Œ, æ˜¯, å—]   \n",
       "33                                  [å‡ æœŸ, çš„, ï¼Ÿ]   \n",
       "34                                  [å‡ æœŸ, çš„, ï¼Ÿ]   \n",
       "35                                  [å‡ æœŸ, çš„, ï¼Ÿ]   \n",
       "36                                  [å‡ æœŸ, çš„, ï¼Ÿ]   \n",
       "37                                  [å‡ æœŸ, çš„, ï¼Ÿ]   \n",
       "38                              [ä»€ä¹ˆ, æƒ…å†µ, å‘¢, ï¼Ÿ]   \n",
       "39                              [ä»€ä¹ˆ, æƒ…å†µ, å‘¢, ï¼Ÿ]   \n",
       "\n",
       "                                          d2_word_cut  \\\n",
       "0   [æ­å·å¸‚, é‡‡è·, ç¬¬ä¸€, å°å­¦, é’±æ±Ÿè‹‘, æ ¡åŒº, ï¼Œ, æ­å·å¸‚, é’±æ±Ÿ, æ–°åŸ, å®éªŒå­¦...   \n",
       "1                                              [æ˜¯, çš„]   \n",
       "2                                          [è¿™æ˜¯, 5, æ¥¼]   \n",
       "3                              [å› ä¸º, å…¬ç§¯é‡‘, è´·æ¬¾, è´·, çš„, å°‘]   \n",
       "4                                              [æ˜¯, å‘¢]   \n",
       "5                           [è¿™å¥—, ä¸€æ¥¼, å¸¦é™¢, çš„, ï¼Œ, æ‚¨, çœ‹çœ‹]   \n",
       "6                                [æˆ¿æœ¬, éƒ½, æ˜¯, äº”å¹´, å¤–, çš„]   \n",
       "7                         [å¥½, çš„, ?, ?, ï¼Œ, æ‚¨, å…ˆ, çœ‹, ä¸‹]   \n",
       "8                            [æ‚¨, æ˜¯, é¦–å¥—, è¿˜æ˜¯, äºŒå¥—, å‘¢, ï¼Ÿ]   \n",
       "9                                [æ‰€æœ‰, è´¹ç”¨, ä¸‹æ¥, 654, ä¸‡]   \n",
       "10                  [åŒ…å«, ç€, ç¨è´¹, å’Œ, æˆ‘ä»¬, çš„, æœåŠ¡è´¹, å’Œ, æˆ¿æ¬¾]   \n",
       "11                                             [å¥½, çš„]   \n",
       "12  [é“¾å®¶, å¤©é¸¿ç¾åŸŸ, åº—, NAME, ï¼Œ, ç”µè¯, æ˜¯, PHONE, ï¼ˆ, åŒå¾®, ä¿¡å·...   \n",
       "13                        [æ­£å¸¸, é“¶è¡Œè´·æ¬¾, ï¼Œ, å¯ä»¥, è‡ªå·±, è¿˜, çš„]   \n",
       "14                                 [æœ‰, ä¸€ç‚¹, é è¿‘, å·æ²™, è·¯]   \n",
       "15                   [åªæœ‰, é‚£, ä¸€å¥—, æ¯›å¯, çš„, ä¸, é è¿‘, å·æ²™, è·¯]   \n",
       "16                                                [æœ‰]   \n",
       "17  [æ²³è¥¿åŒº, æµ·æ²³, æ²¿çº¿, çš„, æ–°æˆ¿, ï¼Œ, å‡ä»·, 30000, ï¼Œ, å¸¦, è£…ä¿®, ï¼Œ...   \n",
       "18  [å®¾æ°´é‡Œ, ï¼Œ, è‚¿ç˜¤åŒ»é™¢, åœ°é“, 5, -, 6, å·çº¿, æ—, ï¼Œ, ç§äº§, è¿‡, äº”...   \n",
       "19                                        [æ‚¨, çœ‹çœ‹, è¿™ä¸ª]   \n",
       "20                           [13, æ¥¼, ï¼Œ, ç²¾è£…ä¿®, çš„, /,  ]   \n",
       "21                                  [æ‚¨, ç°åœ¨, æ–¹ä¾¿, å—,  ]   \n",
       "22                        [å¯ä»¥, å…ˆçº¿, ä¸Š, å¸¦, æ‚¨, çœ‹, ä¸€ä¸‹,  ]   \n",
       "23         [æ‚¨, ç¨ç­‰ä¸€ä¸‹, ï¼Œ, ç»™, æ‚¨, å‘, é“¾æ¥, æ‚¨, ç‚¹, è¿›æ¥, å°±è¡Œ,  ]   \n",
       "24                                       [ä»·æ ¼, å‘¨æœŸ, å¯è°ˆ]   \n",
       "25                                               [æ‚¨å¥½]   \n",
       "26  [æ‚¨å¥½, ï¼Œ, æ‚¨, ä¹‹å‰, å’¨è¯¢, çš„, æˆ¿æº, æˆ·å‹, å¾ˆ, ä¼˜è´¨, ï¼Œ, æ‚¨, æœ‰, ...   \n",
       "27                             [å®¾è‡³è·¯, æœ‰, å¥—, 82, å¹³æ–¹, çš„]   \n",
       "28                                               [ç¬‹ç›˜]   \n",
       "29                                  [å¯ä»¥, å¸¦, æ‚¨, çœ‹, ä¸€ä¸‹]   \n",
       "30                   [å…‰çº¿, éå¸¸, å¥½, ï¼Œ, å‹è”, èŠ±å›­, éƒ½, æ˜¯, å¯ä»¥]   \n",
       "31                             [ä½ , ç‚¹å¼€, å›¾ç‰‡, ï¼Œ, é€ä¸€, çœ‹çœ‹]   \n",
       "32                                                [?]   \n",
       "33                                             [æ˜¯, çš„]   \n",
       "34                                 [è¿™ä¸ª, æ˜¯, äºŒæœŸ, çš„, è€å¸ˆ]   \n",
       "35                                            [è¿˜æœ‰, çš„]   \n",
       "36                                 [äºŒæœŸ, éƒ½, åˆš, ä¸‹è¯, ä»Šå¹´]   \n",
       "37                               [ä¸€æœŸ, çš„, æœ‰, å…ç¨, çš„, äº†]   \n",
       "38                   [æˆ‘ä»¬, ä¸‹ç­, æ¯”è¾ƒ, æ™š, ï¼Œ, ç°åœ¨, ä¹Ÿ, èƒ½, çœ‹æˆ¿]   \n",
       "39                                                [å“¦]   \n",
       "\n",
       "                               d1_pos_tag  \\\n",
       "0                        [nr, d, v, n, y]   \n",
       "1                        [nr, d, v, n, y]   \n",
       "2                        [nr, d, v, n, y]   \n",
       "3                               [n, y, x]   \n",
       "4                               [n, y, x]   \n",
       "5                               [n, y, x]   \n",
       "6                               [n, y, x]   \n",
       "7                               [n, y, x]   \n",
       "8   [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "9   [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "10  [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "11  [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "12  [r, uj, n, v, d, v, m, c, n, v, m, x]   \n",
       "13                       [v, ns, n, y, x]   \n",
       "14                       [v, ns, n, y, x]   \n",
       "15                       [v, ns, n, y, x]   \n",
       "16          [r, n, ng, n, v, vn, n, y, x]   \n",
       "17          [r, n, ng, n, v, vn, n, y, x]   \n",
       "18          [r, n, ng, n, v, vn, n, y, x]   \n",
       "19                           [r, n, m, n]   \n",
       "20                           [r, n, m, n]   \n",
       "21                           [r, n, m, n]   \n",
       "22                           [r, n, m, n]   \n",
       "23                           [r, n, m, n]   \n",
       "24          [r, n, ng, n, v, vn, n, y, x]   \n",
       "25          [r, n, ng, n, v, vn, n, y, x]   \n",
       "26          [r, n, ng, n, v, vn, n, y, x]   \n",
       "27               [v, n, c, v, r, v, y, x]   \n",
       "28               [v, n, c, v, r, v, y, x]   \n",
       "29               [v, n, c, v, r, v, y, x]   \n",
       "30                        [n, d, x, v, y]   \n",
       "31                        [n, d, x, v, y]   \n",
       "32                        [n, d, x, v, y]   \n",
       "33                             [d, uj, x]   \n",
       "34                             [d, uj, x]   \n",
       "35                             [d, uj, x]   \n",
       "36                             [d, uj, x]   \n",
       "37                             [d, uj, x]   \n",
       "38                           [r, n, y, x]   \n",
       "39                           [r, n, y, x]   \n",
       "\n",
       "                                           d2_pos_tag shared_words  ...  \\\n",
       "0          [ns, nr, m, n, nr, n, x, ns, nr, ns, n, x]         [é‡‡è·]  ...   \n",
       "1                                             [v, uj]          [æ˜¯]  ...   \n",
       "2                                        [r, v, m, n]           []  ...   \n",
       "3                                 [c, n, n, v, uj, n]           []  ...   \n",
       "4                                              [v, y]           []  ...   \n",
       "5                          [r, q, n, n, uj, x, zg, v]           []  ...   \n",
       "6                                 [n, d, v, t, f, uj]           []  ...   \n",
       "7                           [a, uj, x, x, x, r, d, v]           []  ...   \n",
       "8                               [r, v, m, c, m, y, x]          [æ˜¯]  ...   \n",
       "9                                     [b, n, t, m, m]           []  ...   \n",
       "10                      [v, uz, n, c, r, uj, n, c, n]          [å’Œ]  ...   \n",
       "11                                            [a, uj]           []  ...   \n",
       "12  [n, nr, ns, n, eng, x, n, v, eng, x, d, n, x, ...          [æ˜¯]  ...   \n",
       "13                             [d, n, x, c, r, d, uj]           []  ...   \n",
       "14                                   [v, m, v, ns, n]  [é è¿‘, å·æ²™, è·¯]  ...   \n",
       "15                      [c, r, m, n, uj, a, v, ns, n]  [é è¿‘, å·æ²™, è·¯]  ...   \n",
       "16                                                [v]           []  ...   \n",
       "17  [ns, ns, f, uj, n, x, n, m, x, v, v, x, v, v, ...         [ä¼˜æƒ ]  ...   \n",
       "18  [n, f, x, n, n, x, x, m, n, f, x, n, ug, t, b,...           []  ...   \n",
       "19                                         [zg, v, r]         [è¿™ä¸ª]  ...   \n",
       "20                             [m, n, x, l, uj, x, x]           []  ...   \n",
       "21                                   [zg, t, a, y, x]           []  ...   \n",
       "22                           [c, n, f, v, r, v, m, x]           []  ...   \n",
       "23           [zg, l, x, p, r, v, n, r, q, v, d, v, x]           []  ...   \n",
       "24                                          [n, t, v]         [ä»·æ ¼]  ...   \n",
       "25                                                [l]           []  ...   \n",
       "26  [l, x, zg, f, vn, uj, n, n, zg, n, x, r, v, n,...           []  ...   \n",
       "27                               [nr, v, q, m, q, uj]          [æœ‰]  ...   \n",
       "28                                                [n]           []  ...   \n",
       "29                                    [c, v, r, v, m]      [å¸¦, å¯ä»¥]  ...   \n",
       "30                       [n, d, a, x, ns, n, d, v, c]      [å…‰çº¿, æ˜¯]  ...   \n",
       "31                              [r, q, v, n, x, d, v]           []  ...   \n",
       "32                                                [x]           []  ...   \n",
       "33                                            [v, uj]           []  ...   \n",
       "34                                   [r, v, b, uj, n]           []  ...   \n",
       "35                                            [v, uj]           []  ...   \n",
       "36                                    [b, d, d, v, t]           []  ...   \n",
       "37                              [d, uj, v, v, uj, ul]           []  ...   \n",
       "38                    [r, v, d, tg, x, t, d, v, v, n]           []  ...   \n",
       "39                                               [zg]           []  ...   \n",
       "\n",
       "    max_tfidf_sim  mean_tfidf_sim  max_textrank_sim  mean_textrank_sim  \\\n",
       "0        2.316487        1.666371               1.0           0.667346   \n",
       "1        4.600099        4.244596               1.0           0.998063   \n",
       "2        4.600099        4.244596               1.0           0.998063   \n",
       "3        3.730876        2.803282               1.0           0.998063   \n",
       "4       11.192627       11.192627               0.0           0.000000   \n",
       "5        2.988692        2.705259               1.0           0.668145   \n",
       "6        3.984923        3.291877               1.0           0.668145   \n",
       "7        5.596314        5.580179               0.0           0.000000   \n",
       "8        3.263268        2.675451               1.0           0.668145   \n",
       "9        1.631634        1.358860               1.0           0.779548   \n",
       "10       1.514977        1.448768               1.0           0.923581   \n",
       "11       3.263268        2.675451               1.0           0.668145   \n",
       "12       0.996231        0.996231               1.0           0.864473   \n",
       "13       2.304637        2.081506               1.0           0.998044   \n",
       "14       4.609273        4.165221               1.0           0.998063   \n",
       "15       3.687419        2.967627               1.0           0.890709   \n",
       "16       1.609121        1.337969               1.0           0.994260   \n",
       "17       0.899475        0.778574               1.0           0.715349   \n",
       "18       0.664154        0.664154               1.0           0.936278   \n",
       "19       5.410445        5.410445               0.0           0.000000   \n",
       "20      11.261620       11.261620               0.0           0.000000   \n",
       "21       3.150388        2.563631               1.0           0.998063   \n",
       "22      11.954768       11.954768               0.0           0.000000   \n",
       "23       3.984923        2.933870               1.0           0.998063   \n",
       "24       1.494346        1.212245               1.0           0.709042   \n",
       "25       1.455032        1.306770               1.0           0.952318   \n",
       "26       0.722294        0.691560               1.0           0.984411   \n",
       "27       3.157952        2.931587               1.0           0.998063   \n",
       "28       3.984923        2.631235               1.0           0.668145   \n",
       "29       3.157952        2.931587               1.0           0.998063   \n",
       "30       2.549591        2.027951               1.0           0.968942   \n",
       "31       1.742658        1.515771               1.0           0.998585   \n",
       "32       3.824387        3.329985               1.0           0.998063   \n",
       "33      10.904945       10.904945               0.0           0.000000   \n",
       "34       3.634982        2.866061               1.0           0.998063   \n",
       "35       5.452473        3.733149               1.0           0.998063   \n",
       "36       2.988692        2.614658               1.0           0.771492   \n",
       "37       3.634982        3.029338               1.0           0.669574   \n",
       "38       2.087900        1.427551               1.0           0.996560   \n",
       "39       4.007240        4.007240               0.0           0.000000   \n",
       "\n",
       "            d1_key_words  ww_cosine  ww_euclidean  ww_inner_product  \\\n",
       "0               {ä¸€å°, åˆ†æ ¡}   0.721863      6.525649         35.439222   \n",
       "1               {ä¸€å°, åˆ†æ ¡}   0.814446      6.326831         72.129395   \n",
       "2               {ä¸€å°, åˆ†æ ¡}   0.814446      6.326831         72.129395   \n",
       "3                   {æ¯›å¯}   0.358034      9.279583         28.669621   \n",
       "4                   {æ¯›å¯}   0.000000      0.000000          0.000000   \n",
       "5                   {æ¯›å¯}   0.261414      8.436319          9.165813   \n",
       "6                   {æ¯›å¯}   0.188383     11.473662         14.102968   \n",
       "7                   {æ¯›å¯}   0.068315      9.121356          3.014279   \n",
       "8           {å¤§çº¦, ä½£é‡‘, å¥‘ç¨}   0.450929      8.677430         25.828073   \n",
       "9           {å¤§çº¦, ä½£é‡‘, å¥‘ç¨}   0.399413     10.100416         31.169064   \n",
       "10          {å¤§çº¦, ä½£é‡‘, å¥‘ç¨}   0.443351      8.748080         30.491407   \n",
       "11          {å¤§çº¦, ä½£é‡‘, å¥‘ç¨}   0.450929      8.677430         25.828073   \n",
       "12          {å¤§çº¦, ä½£é‡‘, å¥‘ç¨}   0.169944     12.927756         28.974901   \n",
       "13              {é è¿‘, å·æ²™}   0.399596      7.959680          6.335780   \n",
       "14              {é è¿‘, å·æ²™}   0.633462     10.497736         13.216286   \n",
       "15              {é è¿‘, å·æ²™}   0.270723     10.317979          6.199821   \n",
       "16  {ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}   0.419433      8.040307         24.576616   \n",
       "17  {ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}   0.264608      6.754923          1.012900   \n",
       "18  {ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}   0.039830      9.966531          0.000573   \n",
       "19                  {å¤šå°‘}   0.000000      0.000000          0.000000   \n",
       "20                  {å¤šå°‘}   0.000000      0.000000          0.000000   \n",
       "21                  {å¤šå°‘}   0.103222      9.581085          4.513747   \n",
       "22                  {å¤šå°‘}   0.000000      0.000000          0.000000   \n",
       "23                  {å¤šå°‘}   0.669373      4.903178         21.826728   \n",
       "24  {ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}   0.364859      8.025300         18.749713   \n",
       "25  {ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}   0.299576     10.032229         18.581886   \n",
       "26  {ä»·æ ¼, ä¼˜æƒ , å¥—æˆ¿, ç©ºé—´, è¿˜æœ‰}   0.373016     11.781522         45.625881   \n",
       "27              {æˆ¿å­, çœ‹çœ‹}   0.288784      8.254086         12.487435   \n",
       "28              {æˆ¿å­, çœ‹çœ‹}   0.164922      7.227518          4.869229   \n",
       "29              {æˆ¿å­, çœ‹çœ‹}   0.288784      8.254086         12.487435   \n",
       "30              {å…‰çº¿, ä¸å¥½}   0.264109     10.832539          5.235958   \n",
       "31              {å…‰çº¿, ä¸å¥½}   0.235205      9.215364          8.099103   \n",
       "32              {å…‰çº¿, ä¸å¥½}   0.101477     13.357806         10.065587   \n",
       "33                  {å‡ æœŸ}   0.000000      0.000000          0.000000   \n",
       "34                  {å‡ æœŸ}   0.163893      8.705774          8.883473   \n",
       "35                  {å‡ æœŸ}  -0.012560      9.763052         -0.586899   \n",
       "36                  {å‡ æœŸ}   0.268873      8.727287         12.534684   \n",
       "37                  {å‡ æœŸ}   0.233220      7.210079          9.234592   \n",
       "38                  {æƒ…å†µ}   0.132563      9.733622          6.152428   \n",
       "39                  {æƒ…å†µ}   0.000000      0.000000          0.000000   \n",
       "\n",
       "    ww_pearson_cor  ww_pearson_pvalue  \n",
       "0         0.721577       1.503320e-21  \n",
       "1         0.814207       2.414553e-72  \n",
       "2         0.814207       2.414553e-72  \n",
       "3         0.357980       1.464102e-02  \n",
       "4         0.000000       0.000000e+00  \n",
       "5         0.264155       2.499604e-01  \n",
       "6         0.188384       1.006249e-01  \n",
       "7         0.068243       2.386186e-01  \n",
       "8         0.451183       3.532106e-09  \n",
       "9         0.399436       4.351321e-02  \n",
       "10        0.443521       1.142209e-06  \n",
       "11        0.451183       3.532106e-09  \n",
       "12        0.167511       1.158997e-02  \n",
       "13        0.399047       5.580720e-05  \n",
       "14        0.632798       5.739747e-35  \n",
       "15        0.270414       1.561286e-01  \n",
       "16        0.416502       4.217419e-05  \n",
       "17        0.265200       2.011383e-01  \n",
       "18        0.040875       1.540320e-01  \n",
       "19        0.000000       0.000000e+00  \n",
       "20        0.000000       0.000000e+00  \n",
       "21        0.101286       7.985726e-02  \n",
       "22        0.000000       0.000000e+00  \n",
       "23        0.670483       6.181808e-31  \n",
       "24        0.361521       4.323876e-05  \n",
       "25        0.297019       1.127904e-01  \n",
       "26        0.374266       1.298957e-02  \n",
       "27        0.284657       5.332867e-07  \n",
       "28        0.158570       1.033444e-01  \n",
       "29        0.284657       5.332867e-07  \n",
       "30        0.265234       1.719930e-01  \n",
       "31        0.234985       2.627015e-02  \n",
       "32        0.096629       9.480238e-02  \n",
       "33        0.000000       0.000000e+00  \n",
       "34        0.165021       3.949651e-01  \n",
       "35       -0.011621       8.411273e-01  \n",
       "36        0.269065       1.042334e-01  \n",
       "37        0.232988       1.309377e-01  \n",
       "38        0.133468       1.429926e-01  \n",
       "39        0.000000       0.000000e+00  \n",
       "\n",
       "[40 rows x 114 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "X = [w2v.wv[_] for k in df_raw.d1_key_words for _ in k if _ != set() and _ in w2v.wv]\n",
    "kmeans = KMeans(n_clusters=20)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length: 17268\n",
      "Test data length: 4317\n",
      "[1]\tvalid_0's auc: 0.750424\tvalid_0's binary_logloss: 0.56407\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's auc: 0.757913\tvalid_0's binary_logloss: 0.558262\n",
      "[3]\tvalid_0's auc: 0.767214\tvalid_0's binary_logloss: 0.552647\n",
      "[4]\tvalid_0's auc: 0.76969\tvalid_0's binary_logloss: 0.5477\n",
      "[5]\tvalid_0's auc: 0.773798\tvalid_0's binary_logloss: 0.542925\n",
      "[6]\tvalid_0's auc: 0.78068\tvalid_0's binary_logloss: 0.53828\n",
      "[7]\tvalid_0's auc: 0.780022\tvalid_0's binary_logloss: 0.53426\n",
      "[8]\tvalid_0's auc: 0.781914\tvalid_0's binary_logloss: 0.530246\n",
      "[9]\tvalid_0's auc: 0.782775\tvalid_0's binary_logloss: 0.52656\n",
      "[10]\tvalid_0's auc: 0.782727\tvalid_0's binary_logloss: 0.523058\n",
      "[11]\tvalid_0's auc: 0.782382\tvalid_0's binary_logloss: 0.519847\n",
      "[12]\tvalid_0's auc: 0.782734\tvalid_0's binary_logloss: 0.516732\n",
      "[13]\tvalid_0's auc: 0.782552\tvalid_0's binary_logloss: 0.513861\n",
      "[14]\tvalid_0's auc: 0.783923\tvalid_0's binary_logloss: 0.510812\n",
      "[15]\tvalid_0's auc: 0.78519\tvalid_0's binary_logloss: 0.508299\n",
      "[16]\tvalid_0's auc: 0.786882\tvalid_0's binary_logloss: 0.505492\n",
      "[17]\tvalid_0's auc: 0.787565\tvalid_0's binary_logloss: 0.502937\n",
      "[18]\tvalid_0's auc: 0.788135\tvalid_0's binary_logloss: 0.500718\n",
      "[19]\tvalid_0's auc: 0.78842\tvalid_0's binary_logloss: 0.498417\n",
      "[20]\tvalid_0's auc: 0.788669\tvalid_0's binary_logloss: 0.496321\n",
      "[21]\tvalid_0's auc: 0.788518\tvalid_0's binary_logloss: 0.494299\n",
      "[22]\tvalid_0's auc: 0.79017\tvalid_0's binary_logloss: 0.492146\n",
      "[23]\tvalid_0's auc: 0.790476\tvalid_0's binary_logloss: 0.49037\n",
      "[24]\tvalid_0's auc: 0.791079\tvalid_0's binary_logloss: 0.488741\n",
      "[25]\tvalid_0's auc: 0.791739\tvalid_0's binary_logloss: 0.486928\n",
      "[26]\tvalid_0's auc: 0.791656\tvalid_0's binary_logloss: 0.48553\n",
      "[27]\tvalid_0's auc: 0.793154\tvalid_0's binary_logloss: 0.483519\n",
      "[28]\tvalid_0's auc: 0.794234\tvalid_0's binary_logloss: 0.481799\n",
      "[29]\tvalid_0's auc: 0.794532\tvalid_0's binary_logloss: 0.480438\n",
      "[30]\tvalid_0's auc: 0.795244\tvalid_0's binary_logloss: 0.478931\n",
      "[31]\tvalid_0's auc: 0.795353\tvalid_0's binary_logloss: 0.477548\n",
      "[32]\tvalid_0's auc: 0.795103\tvalid_0's binary_logloss: 0.476401\n",
      "[33]\tvalid_0's auc: 0.795409\tvalid_0's binary_logloss: 0.475169\n",
      "[34]\tvalid_0's auc: 0.796214\tvalid_0's binary_logloss: 0.473857\n",
      "[35]\tvalid_0's auc: 0.797287\tvalid_0's binary_logloss: 0.472549\n",
      "[36]\tvalid_0's auc: 0.798169\tvalid_0's binary_logloss: 0.471304\n",
      "[37]\tvalid_0's auc: 0.798756\tvalid_0's binary_logloss: 0.470093\n",
      "[38]\tvalid_0's auc: 0.79913\tvalid_0's binary_logloss: 0.468919\n",
      "[39]\tvalid_0's auc: 0.799119\tvalid_0's binary_logloss: 0.467975\n",
      "[40]\tvalid_0's auc: 0.799663\tvalid_0's binary_logloss: 0.466934\n",
      "[41]\tvalid_0's auc: 0.800009\tvalid_0's binary_logloss: 0.466028\n",
      "[42]\tvalid_0's auc: 0.80041\tvalid_0's binary_logloss: 0.464989\n",
      "[43]\tvalid_0's auc: 0.800998\tvalid_0's binary_logloss: 0.463967\n",
      "[44]\tvalid_0's auc: 0.801182\tvalid_0's binary_logloss: 0.463202\n",
      "[45]\tvalid_0's auc: 0.801253\tvalid_0's binary_logloss: 0.462483\n",
      "[46]\tvalid_0's auc: 0.801567\tvalid_0's binary_logloss: 0.461658\n",
      "[47]\tvalid_0's auc: 0.802055\tvalid_0's binary_logloss: 0.460835\n",
      "[48]\tvalid_0's auc: 0.80207\tvalid_0's binary_logloss: 0.460067\n",
      "[49]\tvalid_0's auc: 0.802205\tvalid_0's binary_logloss: 0.459385\n",
      "[50]\tvalid_0's auc: 0.802943\tvalid_0's binary_logloss: 0.458522\n",
      "[51]\tvalid_0's auc: 0.803371\tvalid_0's binary_logloss: 0.457851\n",
      "[52]\tvalid_0's auc: 0.803535\tvalid_0's binary_logloss: 0.457327\n",
      "[53]\tvalid_0's auc: 0.804055\tvalid_0's binary_logloss: 0.456516\n",
      "[54]\tvalid_0's auc: 0.804181\tvalid_0's binary_logloss: 0.455973\n",
      "[55]\tvalid_0's auc: 0.804426\tvalid_0's binary_logloss: 0.455332\n",
      "[56]\tvalid_0's auc: 0.804875\tvalid_0's binary_logloss: 0.454606\n",
      "[57]\tvalid_0's auc: 0.804846\tvalid_0's binary_logloss: 0.454102\n",
      "[58]\tvalid_0's auc: 0.805214\tvalid_0's binary_logloss: 0.453497\n",
      "[59]\tvalid_0's auc: 0.805464\tvalid_0's binary_logloss: 0.452937\n",
      "[60]\tvalid_0's auc: 0.806023\tvalid_0's binary_logloss: 0.452293\n",
      "[61]\tvalid_0's auc: 0.806411\tvalid_0's binary_logloss: 0.4517\n",
      "[62]\tvalid_0's auc: 0.806519\tvalid_0's binary_logloss: 0.451268\n",
      "[63]\tvalid_0's auc: 0.806657\tvalid_0's binary_logloss: 0.450835\n",
      "[64]\tvalid_0's auc: 0.806926\tvalid_0's binary_logloss: 0.450377\n",
      "[65]\tvalid_0's auc: 0.807279\tvalid_0's binary_logloss: 0.449865\n",
      "[66]\tvalid_0's auc: 0.807301\tvalid_0's binary_logloss: 0.449434\n",
      "[67]\tvalid_0's auc: 0.807424\tvalid_0's binary_logloss: 0.449082\n",
      "[68]\tvalid_0's auc: 0.807872\tvalid_0's binary_logloss: 0.448563\n",
      "[69]\tvalid_0's auc: 0.808396\tvalid_0's binary_logloss: 0.447976\n",
      "[70]\tvalid_0's auc: 0.808995\tvalid_0's binary_logloss: 0.447447\n",
      "[71]\tvalid_0's auc: 0.809588\tvalid_0's binary_logloss: 0.446837\n",
      "[72]\tvalid_0's auc: 0.80994\tvalid_0's binary_logloss: 0.446317\n",
      "[73]\tvalid_0's auc: 0.810555\tvalid_0's binary_logloss: 0.445664\n",
      "[74]\tvalid_0's auc: 0.810541\tvalid_0's binary_logloss: 0.445354\n",
      "[75]\tvalid_0's auc: 0.810717\tvalid_0's binary_logloss: 0.445042\n",
      "[76]\tvalid_0's auc: 0.81105\tvalid_0's binary_logloss: 0.444603\n",
      "[77]\tvalid_0's auc: 0.811624\tvalid_0's binary_logloss: 0.444066\n",
      "[78]\tvalid_0's auc: 0.812125\tvalid_0's binary_logloss: 0.443593\n",
      "[79]\tvalid_0's auc: 0.812273\tvalid_0's binary_logloss: 0.443321\n",
      "[80]\tvalid_0's auc: 0.812485\tvalid_0's binary_logloss: 0.442925\n",
      "[81]\tvalid_0's auc: 0.81277\tvalid_0's binary_logloss: 0.442577\n",
      "[82]\tvalid_0's auc: 0.813168\tvalid_0's binary_logloss: 0.442079\n",
      "[83]\tvalid_0's auc: 0.813331\tvalid_0's binary_logloss: 0.441695\n",
      "[84]\tvalid_0's auc: 0.813381\tvalid_0's binary_logloss: 0.441412\n",
      "[85]\tvalid_0's auc: 0.813757\tvalid_0's binary_logloss: 0.440927\n",
      "[86]\tvalid_0's auc: 0.814276\tvalid_0's binary_logloss: 0.440443\n",
      "[87]\tvalid_0's auc: 0.814507\tvalid_0's binary_logloss: 0.440055\n",
      "[88]\tvalid_0's auc: 0.814861\tvalid_0's binary_logloss: 0.43963\n",
      "[89]\tvalid_0's auc: 0.815053\tvalid_0's binary_logloss: 0.439447\n",
      "[90]\tvalid_0's auc: 0.815281\tvalid_0's binary_logloss: 0.439149\n",
      "[91]\tvalid_0's auc: 0.815266\tvalid_0's binary_logloss: 0.439029\n",
      "[92]\tvalid_0's auc: 0.815439\tvalid_0's binary_logloss: 0.438782\n",
      "[93]\tvalid_0's auc: 0.815684\tvalid_0's binary_logloss: 0.438617\n",
      "[94]\tvalid_0's auc: 0.816159\tvalid_0's binary_logloss: 0.438201\n",
      "[95]\tvalid_0's auc: 0.816132\tvalid_0's binary_logloss: 0.438029\n",
      "[96]\tvalid_0's auc: 0.81644\tvalid_0's binary_logloss: 0.437686\n",
      "[97]\tvalid_0's auc: 0.816735\tvalid_0's binary_logloss: 0.437462\n",
      "[98]\tvalid_0's auc: 0.816779\tvalid_0's binary_logloss: 0.437304\n",
      "[99]\tvalid_0's auc: 0.817306\tvalid_0's binary_logloss: 0.436853\n",
      "[100]\tvalid_0's auc: 0.817481\tvalid_0's binary_logloss: 0.436564\n",
      "[101]\tvalid_0's auc: 0.817533\tvalid_0's binary_logloss: 0.436402\n",
      "[102]\tvalid_0's auc: 0.817746\tvalid_0's binary_logloss: 0.436175\n",
      "[103]\tvalid_0's auc: 0.81834\tvalid_0's binary_logloss: 0.435629\n",
      "[104]\tvalid_0's auc: 0.818661\tvalid_0's binary_logloss: 0.435239\n",
      "[105]\tvalid_0's auc: 0.818878\tvalid_0's binary_logloss: 0.434987\n",
      "[106]\tvalid_0's auc: 0.819102\tvalid_0's binary_logloss: 0.434737\n",
      "[107]\tvalid_0's auc: 0.819424\tvalid_0's binary_logloss: 0.434392\n",
      "[108]\tvalid_0's auc: 0.819502\tvalid_0's binary_logloss: 0.434181\n",
      "[109]\tvalid_0's auc: 0.819768\tvalid_0's binary_logloss: 0.433965\n",
      "[110]\tvalid_0's auc: 0.820138\tvalid_0's binary_logloss: 0.433557\n",
      "[111]\tvalid_0's auc: 0.820584\tvalid_0's binary_logloss: 0.433211\n",
      "[112]\tvalid_0's auc: 0.821013\tvalid_0's binary_logloss: 0.432846\n",
      "[113]\tvalid_0's auc: 0.821358\tvalid_0's binary_logloss: 0.432522\n",
      "[114]\tvalid_0's auc: 0.821641\tvalid_0's binary_logloss: 0.432297\n",
      "[115]\tvalid_0's auc: 0.821746\tvalid_0's binary_logloss: 0.43207\n",
      "[116]\tvalid_0's auc: 0.821878\tvalid_0's binary_logloss: 0.431929\n",
      "[117]\tvalid_0's auc: 0.821959\tvalid_0's binary_logloss: 0.431823\n",
      "[118]\tvalid_0's auc: 0.822171\tvalid_0's binary_logloss: 0.431603\n",
      "[119]\tvalid_0's auc: 0.822351\tvalid_0's binary_logloss: 0.431355\n",
      "[120]\tvalid_0's auc: 0.822342\tvalid_0's binary_logloss: 0.43119\n",
      "[121]\tvalid_0's auc: 0.822839\tvalid_0's binary_logloss: 0.430833\n",
      "[122]\tvalid_0's auc: 0.823029\tvalid_0's binary_logloss: 0.430654\n",
      "[123]\tvalid_0's auc: 0.823107\tvalid_0's binary_logloss: 0.430475\n",
      "[124]\tvalid_0's auc: 0.82316\tvalid_0's binary_logloss: 0.430367\n",
      "[125]\tvalid_0's auc: 0.8231\tvalid_0's binary_logloss: 0.430351\n",
      "[126]\tvalid_0's auc: 0.823435\tvalid_0's binary_logloss: 0.43007\n",
      "[127]\tvalid_0's auc: 0.82342\tvalid_0's binary_logloss: 0.430018\n",
      "[128]\tvalid_0's auc: 0.823524\tvalid_0's binary_logloss: 0.429977\n",
      "[129]\tvalid_0's auc: 0.823683\tvalid_0's binary_logloss: 0.429879\n",
      "[130]\tvalid_0's auc: 0.823847\tvalid_0's binary_logloss: 0.429733\n",
      "[131]\tvalid_0's auc: 0.824069\tvalid_0's binary_logloss: 0.429536\n",
      "[132]\tvalid_0's auc: 0.824298\tvalid_0's binary_logloss: 0.429286\n",
      "[133]\tvalid_0's auc: 0.824502\tvalid_0's binary_logloss: 0.429112\n",
      "[134]\tvalid_0's auc: 0.824722\tvalid_0's binary_logloss: 0.428909\n",
      "[135]\tvalid_0's auc: 0.824846\tvalid_0's binary_logloss: 0.428756\n",
      "[136]\tvalid_0's auc: 0.824786\tvalid_0's binary_logloss: 0.428736\n",
      "[137]\tvalid_0's auc: 0.824925\tvalid_0's binary_logloss: 0.428611\n",
      "[138]\tvalid_0's auc: 0.825092\tvalid_0's binary_logloss: 0.428444\n",
      "[139]\tvalid_0's auc: 0.825422\tvalid_0's binary_logloss: 0.428164\n",
      "[140]\tvalid_0's auc: 0.825594\tvalid_0's binary_logloss: 0.42795\n",
      "[141]\tvalid_0's auc: 0.825838\tvalid_0's binary_logloss: 0.427737\n",
      "[142]\tvalid_0's auc: 0.825925\tvalid_0's binary_logloss: 0.427688\n",
      "[143]\tvalid_0's auc: 0.82613\tvalid_0's binary_logloss: 0.427573\n",
      "[144]\tvalid_0's auc: 0.826314\tvalid_0's binary_logloss: 0.427364\n",
      "[145]\tvalid_0's auc: 0.826255\tvalid_0's binary_logloss: 0.427289\n",
      "[146]\tvalid_0's auc: 0.826288\tvalid_0's binary_logloss: 0.427262\n",
      "[147]\tvalid_0's auc: 0.826381\tvalid_0's binary_logloss: 0.427142\n",
      "[148]\tvalid_0's auc: 0.826236\tvalid_0's binary_logloss: 0.427148\n",
      "[149]\tvalid_0's auc: 0.826248\tvalid_0's binary_logloss: 0.427137\n",
      "[150]\tvalid_0's auc: 0.826374\tvalid_0's binary_logloss: 0.427014\n",
      "[151]\tvalid_0's auc: 0.826336\tvalid_0's binary_logloss: 0.426985\n",
      "[152]\tvalid_0's auc: 0.826462\tvalid_0's binary_logloss: 0.426832\n",
      "[153]\tvalid_0's auc: 0.82649\tvalid_0's binary_logloss: 0.426724\n",
      "[154]\tvalid_0's auc: 0.82661\tvalid_0's binary_logloss: 0.42661\n",
      "[155]\tvalid_0's auc: 0.826592\tvalid_0's binary_logloss: 0.426544\n",
      "[156]\tvalid_0's auc: 0.826631\tvalid_0's binary_logloss: 0.426488\n",
      "[157]\tvalid_0's auc: 0.826645\tvalid_0's binary_logloss: 0.426422\n",
      "[158]\tvalid_0's auc: 0.826762\tvalid_0's binary_logloss: 0.426341\n",
      "[159]\tvalid_0's auc: 0.826792\tvalid_0's binary_logloss: 0.426263\n",
      "[160]\tvalid_0's auc: 0.826929\tvalid_0's binary_logloss: 0.426121\n",
      "[161]\tvalid_0's auc: 0.82708\tvalid_0's binary_logloss: 0.426014\n",
      "[162]\tvalid_0's auc: 0.827225\tvalid_0's binary_logloss: 0.425812\n",
      "[163]\tvalid_0's auc: 0.827339\tvalid_0's binary_logloss: 0.425671\n",
      "[164]\tvalid_0's auc: 0.827322\tvalid_0's binary_logloss: 0.425663\n",
      "[165]\tvalid_0's auc: 0.827331\tvalid_0's binary_logloss: 0.4256\n",
      "[166]\tvalid_0's auc: 0.82737\tvalid_0's binary_logloss: 0.425574\n",
      "[167]\tvalid_0's auc: 0.827479\tvalid_0's binary_logloss: 0.425391\n",
      "[168]\tvalid_0's auc: 0.827534\tvalid_0's binary_logloss: 0.425293\n",
      "[169]\tvalid_0's auc: 0.827382\tvalid_0's binary_logloss: 0.42537\n",
      "[170]\tvalid_0's auc: 0.827321\tvalid_0's binary_logloss: 0.425376\n",
      "[171]\tvalid_0's auc: 0.827527\tvalid_0's binary_logloss: 0.425164\n",
      "[172]\tvalid_0's auc: 0.827483\tvalid_0's binary_logloss: 0.425105\n",
      "[173]\tvalid_0's auc: 0.827526\tvalid_0's binary_logloss: 0.425037\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.827534\tvalid_0's binary_logloss: 0.425293\n",
      "The f1 score of prediction is: 0.5334859759587864\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df_raw[:len(train_df)][features]\n",
    "target = df_raw[:len(train_df)]['label']\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    "print(\"Train data length:\", len(X_train))\n",
    "print(\"Test data length:\", len(X_test))\n",
    "\n",
    "# è½¬æ¢ä¸ºDatasetæ•°æ®æ ¼å¼\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# å‚æ•°\n",
    "params = {'num_leaves': 75, #ç»“æœå¯¹æœ€ç»ˆæ•ˆæœå½±å“è¾ƒå¤§ï¼Œè¶Šå¤§å€¼è¶Šå¥½ï¼Œå¤ªå¤§ä¼šå‡ºç°è¿‡æ‹Ÿåˆ\n",
    "          'min_data_in_leaf': 30,\n",
    "          'objective': 'binary', #å®šä¹‰çš„ç›®æ ‡å‡½æ•°\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.03,\n",
    "          \"min_sum_hessian_in_leaf\": 6,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"feature_fraction\": 0.9,#æå–çš„ç‰¹å¾æ¯”ç‡\n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.8,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"lambda_l1\": 0.1,#l1æ­£åˆ™\n",
    "          \"verbosity\": -1,\n",
    "          \"nthread\": -1,#çº¿ç¨‹æ•°é‡ï¼Œ-1è¡¨ç¤ºå…¨éƒ¨çº¿ç¨‹ï¼Œçº¿ç¨‹è¶Šå¤šï¼Œè¿è¡Œçš„é€Ÿåº¦è¶Šå¿«\n",
    "          'metric': {'binary_logloss', 'auc', 'f1'},##è¯„ä»·å‡½æ•°é€‰æ‹©\n",
    "          \"random_state\": 2019,#éšæœºæ•°ç§å­ï¼Œå¯ä»¥é˜²æ­¢æ¯æ¬¡è¿è¡Œçš„ç»“æœä¸ä¸€è‡´\n",
    "          # 'device': 'gpu' ##å¦‚æœå®‰è£…çš„äº‹gpuç‰ˆæœ¬çš„lightgbm,å¯ä»¥åŠ å¿«è¿ç®—\n",
    "          }\n",
    "\n",
    "\n",
    "# æ¨¡å‹è®­ç»ƒ\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=500, valid_sets=lgb_eval, early_stopping_rounds=5)\n",
    "\n",
    "# æ¨¡å‹ä¿å­˜\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "# æ¨¡å‹åŠ è½½\n",
    "gbm = lgb.Booster(model_file='model.txt')\n",
    "\n",
    "# æ¨¡å‹é¢„æµ‹\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "y_pred = (y_pred>=0.5).astype(float)\n",
    "\n",
    "# æ¨¡å‹è¯„ä¼°\n",
    "print('The f1 score of prediction is:', f1_score(y_test.values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlpç‰¹å¾ï¼šåŒ…æ‹¬ä¸»é¢˜æ¨¡å‹ã€LDAã€kmeansã€è¯è¡¨ç¤ºã€å¥å­è¡¨ç¤ºã€è¯å‘é‡çš„å„ç§è·ç¦»åº¦é‡ç­‰ç­‰\n",
    "def train_lda(all_df,  n_topics=15):\n",
    "    ## ä½¿ç”¨ä¸åŒ…å«åœæ­¢è¯çš„åˆ†è¯ç»“æœ\n",
    "    corpus = all_df['tokens']\n",
    "    cnt = CountVectorizer()\n",
    "    cntIf = cnt.fit_transform(corpus)\n",
    "\n",
    "    lda_path = os.path.join(model_path, 'lda.pkl')\n",
    "\n",
    "    ## ä½¿ç”¨LDAä¸»é¢˜æ¨¡å‹è¿›è¡Œåˆ†ç±»\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=150)\n",
    "    print(\"æ­£åœ¨è®­ç»ƒLDAä¸»é¢˜æ¨¡å‹...\")\n",
    "    lda_pred = lda.fit_transform(cntIf)\n",
    "    lda_classes = np.argmax(lda_pred, axis=1)\n",
    "    ## ä¿å­˜æ¨¡å‹\n",
    "    with open(lda_path, 'wb') as f:\n",
    "        pickle.dump(lda, f)\n",
    "    print(\"LDAä¸»é¢˜æ¨¡å‹å·²ä¿å­˜...\")\n",
    "\n",
    "    return lda_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åº·åº·å…³é”®è¯ï¼Œå¤§è‡´åˆ¤æ–­æœ‰å¤šå°‘ä¸»é¢˜å§\n",
    "df_raw.to_csv(\"tmp.tsv\", sep='\\t', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaf1cda7d109dc4e3ba3b4252742f6d994"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
